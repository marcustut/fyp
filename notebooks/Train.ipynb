{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Abstract2Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:20.031848Z",
     "iopub.status.busy": "2021-11-19T13:13:20.031498Z",
     "iopub.status.idle": "2021-11-19T13:13:23.357558Z",
     "shell.execute_reply": "2021-11-19T13:13:23.356948Z",
     "shell.execute_reply.started": "2021-11-19T13:13:20.031781Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "# import wandb\n",
    "from datasets import load_from_disk, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, \\\n",
    "                         DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/liana/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # replace with your weights and biases username otherwise comment this\n",
    "# wandb.init(project=\"abstract-to-title\", entity=\"nerdimite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:31.687885Z",
     "iopub.status.busy": "2021-11-19T13:13:31.687541Z",
     "iopub.status.idle": "2021-11-19T13:13:31.997391Z",
     "shell.execute_reply": "2021-11-19T13:13:31.996752Z",
     "shell.execute_reply.started": "2021-11-19T13:13:31.687860Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b5d5bb610043da9272e4f0dfaae2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442b330674ed499f859a43e91d7b13f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be10e111252466fb83b81b23765e699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize T5-base tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:33.471738Z",
     "iopub.status.busy": "2021-11-19T13:13:33.471420Z",
     "iopub.status.idle": "2021-11-19T13:13:33.482045Z",
     "shell.execute_reply": "2021-11-19T13:13:33.481524Z",
     "shell.execute_reply.started": "2021-11-19T13:13:33.471714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "dataset = load_from_disk('arxiv_AI_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:34.314993Z",
     "iopub.status.busy": "2021-11-19T13:13:34.314678Z",
     "iopub.status.idle": "2021-11-19T13:13:34.317945Z",
     "shell.execute_reply": "2021-11-19T13:13:34.317360Z",
     "shell.execute_reply.started": "2021-11-19T13:13:34.314969Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SOURCE_LEN = 512\n",
    "MAX_TARGET_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:34.969829Z",
     "iopub.status.busy": "2021-11-19T13:13:34.969512Z",
     "iopub.status.idle": "2021-11-19T13:13:34.974526Z",
     "shell.execute_reply": "2021-11-19T13:13:34.973868Z",
     "shell.execute_reply.started": "2021-11-19T13:13:34.969805Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(example):\n",
    "    \n",
    "    model_inputs = tokenizer(example['abstract'], max_length=MAX_SOURCE_LEN, padding=True, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example['title'], max_length=MAX_TARGET_LEN, padding=True, truncation=True)\n",
    "\n",
    "    # Replace all pad token ids in the labels by -100 to ignore padding in the loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs['labels'] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:36.373210Z",
     "iopub.status.busy": "2021-11-19T13:13:36.372893Z",
     "iopub.status.idle": "2021-11-19T13:13:37.342402Z",
     "shell.execute_reply": "2021-11-19T13:13:37.341857Z",
     "shell.execute_reply.started": "2021-11-19T13:13:36.373185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecf35467d71459bb2c126aa35ce9aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7add4ed7d1fb4da1be5d5cc42b54e821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b210339b904693a504d43f2101d78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 36074\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 2005\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 2004\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocess_data() to the whole dataset\n",
    "processed_dataset = dataset.map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    remove_columns=['abstract', 'title'],\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:53.967268Z",
     "iopub.status.busy": "2021-11-19T13:13:53.966933Z",
     "iopub.status.idle": "2021-11-19T13:13:53.970713Z",
     "shell.execute_reply": "2021-11-19T13:13:53.970086Z",
     "shell.execute_reply.started": "2021-11-19T13:13:53.967244Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "learning_rate = 5.6e-5\n",
    "weight_decay = 0.01\n",
    "log_every = 50\n",
    "eval_every = 1000\n",
    "lr_scheduler_type = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:00.354699Z",
     "iopub.status.busy": "2021-11-19T13:14:00.354389Z",
     "iopub.status.idle": "2021-11-19T13:14:00.451642Z",
     "shell.execute_reply": "2021-11-19T13:14:00.451017Z",
     "shell.execute_reply.started": "2021-11-19T13:14:00.354676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liana/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/cuda/__init__.py:143: UserWarning: \n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3050 Ti Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"model-t5-base\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_every,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=log_every,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"wandb\",\n",
    "    resume_from_checkpoint=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:04.988628Z",
     "iopub.status.busy": "2021-11-19T13:14:04.988287Z",
     "iopub.status.idle": "2021-11-19T13:14:13.093681Z",
     "shell.execute_reply": "2021-11-19T13:14:13.093052Z",
     "shell.execute_reply.started": "2021-11-19T13:14:04.988588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d83f9cb46564298baad9dfbd92f44bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize T5-base model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:13.095116Z",
     "iopub.status.busy": "2021-11-19T13:14:13.094858Z",
     "iopub.status.idle": "2021-11-19T13:14:13.252834Z",
     "shell.execute_reply": "2021-11-19T13:14:13.252320Z",
     "shell.execute_reply.started": "2021-11-19T13:14:13.095096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fcc734f86a405aba6dc1ef887d9d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define ROGUE metrics on evaluation data\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Compute ROUGE scores and get the median scores\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:13.253756Z",
     "iopub.status.busy": "2021-11-19T13:14:13.253563Z",
     "iopub.status.idle": "2021-11-19T13:14:13.256642Z",
     "shell.execute_reply": "2021-11-19T13:14:13.256048Z",
     "shell.execute_reply.started": "2021-11-19T13:14:13.253738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dynamic padding in batch using a data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:26:57.569948Z",
     "iopub.status.busy": "2021-11-19T13:26:57.569634Z",
     "iopub.status.idle": "2021-11-19T13:26:57.580471Z",
     "shell.execute_reply": "2021-11-19T13:26:57.579864Z",
     "shell.execute_reply.started": "2021-11-19T13:26:57.569925Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Define the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 36074\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22550\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlianaling\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/lianaling/huggingface/runs/2ay55dzf\" target=\"_blank\">model-t5-base</a></strong> to <a href=\"https://wandb.ai/lianaling/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py:1316\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1313'>1314</a>\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1314'>1315</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1315'>1316</a>\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1317'>1318</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1318'>1319</a>\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1319'>1320</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1320'>1321</a>\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1321'>1322</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1322'>1323</a>\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1323'>1324</a>\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py:1849\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1846'>1847</a>\u001b[0m         loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1847'>1848</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1848'>1849</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1850'>1851</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1851'>1852</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py:1881\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1878'>1879</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1879'>1880</a>\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1880'>1881</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1881'>1882</a>\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1882'>1883</a>\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/trainer.py?line=1883'>1884</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1571\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1567'>1568</a>\u001b[0m \u001b[39m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1568'>1569</a>\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1569'>1570</a>\u001b[0m     \u001b[39m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1570'>1571</a>\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1571'>1572</a>\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1572'>1573</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1573'>1574</a>\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1574'>1575</a>\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1575'>1576</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1576'>1577</a>\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1577'>1578</a>\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1578'>1579</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1579'>1580</a>\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1580'>1581</a>\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1581'>1582</a>\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1582'>1583</a>\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1583'>1584</a>\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=1584'>1585</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:904\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=901'>902</a>\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=902'>903</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=903'>904</a>\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_tokens(input_ids)\n\u001b[1;32m    <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=905'>906</a>\u001b[0m batch_size, seq_length \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m    <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py?line=907'>908</a>\u001b[0m \u001b[39m# required mask seq length can be calculated via length of past\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=156'>157</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=157'>158</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=158'>159</a>\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=159'>160</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py:2044\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py?line=2037'>2038</a>\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py?line=2038'>2039</a>\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py?line=2039'>2040</a>\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py?line=2040'>2041</a>\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py?line=2041'>2042</a>\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py?line=2042'>2043</a>\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> <a href='file:///~/projects/abstract-to-title-generator/venv/lib/python3.9/site-packages/torch/nn/functional.py?line=2043'>2044</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('model-t5-base/checkpoint-6000/').to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained('model-t5-base/checkpoint-6000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:27:03.756757Z",
     "iopub.status.busy": "2021-11-19T13:27:03.756436Z",
     "iopub.status.idle": "2021-11-19T13:30:44.492437Z",
     "shell.execute_reply": "2021-11-19T13:30:44.491895Z",
     "shell.execute_reply.started": "2021-11-19T13:27:03.756734Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2005\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/251 03:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 40s, sys: 194 ms, total: 3min 40s\n",
      "Wall time: 3min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6707532405853271,\n",
       " 'eval_rouge1': 47.1746,\n",
       " 'eval_rouge2': 26.8231,\n",
       " 'eval_rougeL': 41.7727,\n",
       " 'eval_rougeLsum': 41.8263,\n",
       " 'eval_runtime': 220.717,\n",
       " 'eval_samples_per_second': 9.084,\n",
       " 'eval_steps_per_second': 1.137}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.evaluate(eval_dataset=processed_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:40:10.661400Z",
     "iopub.status.busy": "2021-11-19T13:40:10.661056Z",
     "iopub.status.idle": "2021-11-19T13:40:10.665897Z",
     "shell.execute_reply": "2021-11-19T13:40:10.665328Z",
     "shell.execute_reply.started": "2021-11-19T13:40:10.661377Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature = 0.9\n",
    "num_beams = 4\n",
    "max_gen_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:40:33.699612Z",
     "iopub.status.busy": "2021-11-19T13:40:33.699293Z",
     "iopub.status.idle": "2021-11-19T13:40:33.956567Z",
     "shell.execute_reply": "2021-11-19T13:40:33.955828Z",
     "shell.execute_reply.started": "2021-11-19T13:40:33.699588Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Supervised Learning of Vision Transformers\n"
     ]
    }
   ],
   "source": [
    "abstract = \"\"\"In this paper, we question if self-supervised learning provides\n",
    "new properties to Vision Transformer (ViT) [19] that\n",
    "stand out compared to convolutional networks (convnets).\n",
    "Beyond the fact that adapting self-supervised methods to this\n",
    "architecture works particularly well, we make the following\n",
    "observations: first, self-supervised ViT features contain\n",
    "explicit information about the semantic segmentation of an\n",
    "image, which does not emerge as clearly with supervised\n",
    "ViTs, nor with convnets. Second, these features are also excellent\n",
    "k-NN classifiers, reaching 78.3% top-1 on ImageNet\n",
    "with a small ViT. Our study also underlines the importance of\n",
    "momentum encoder [33], multi-crop training [10], and the\n",
    "use of small patches with ViTs. We implement our findings\n",
    "into a simple self-supervised method, called DINO, which\n",
    "we interpret as a form of self-distillation with no labels.\n",
    "We show the synergy between DINO and ViTs by achieving\n",
    "80.1% top-1 on ImageNet in linear evaluation with ViT-Base\"\"\"\n",
    "# abstract = dataset['test'][0]['abstract']\n",
    "inputs = tokenizer([abstract], max_length=512, return_tensors='pt')\n",
    "\n",
    "title_ids = model.generate(\n",
    "    inputs['input_ids'].to('cuda'), \n",
    "    num_beams=num_beams, \n",
    "    temperature=temperature, \n",
    "    max_length=max_gen_length, \n",
    "    early_stopping=True\n",
    ")\n",
    "title = tokenizer.decode(title_ids[0].tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60fbf1aecf0122793952a73a80d27bc8732eff9e143c13520ca117508929b1c7"
  },
  "kernelspec": {
   "display_name": "PyTorch 1.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0011af7c2a1a44b2b86abd139850f8f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "00168cc339ab4d37bbf040239346f903": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_defd01d3f3ce4fd3acfacdbdbcdd8f9d",
       "max": 3,
       "style": "IPY_MODEL_34cbfddb6b144f3ea35715463b35bd66",
       "value": 3
      }
     },
     "081ac6d06e7e4919809f7e82727bc225": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0ec3e0d84bd34eafb11c47988ab761e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "27e916e2e74f4290842a5366fb2c90ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "294259e3f56a4734a38a217a643a3b7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "34cbfddb6b144f3ea35715463b35bd66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "46e8db13110847b09b31493bf1aef00f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_aa058a5707324fd69649260c3fa49354",
       "style": "IPY_MODEL_081ac6d06e7e4919809f7e82727bc225",
       "value": "Running tokenizer on dataset: 100%"
      }
     },
     "599b4af1fcf4439e97ba4eef14b0f308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_bdb7c24b9d4e468a966ce332f01cacdd",
       "style": "IPY_MODEL_e872f51fbed0454e9f426a640e046d7a"
      }
     },
     "6077e6bc33064f14819ec0f99f3e0987": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_0ec3e0d84bd34eafb11c47988ab761e3",
       "max": 1,
       "style": "IPY_MODEL_294259e3f56a4734a38a217a643a3b7f"
      }
     },
     "71fec538988d4f5cb2bbc51a305dc559": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "98ba5b3a839a4d92ae7559367819272a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aa058a5707324fd69649260c3fa49354": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aef8e4636f5548918a4bbf164e7dfd50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_27e916e2e74f4290842a5366fb2c90ec",
       "style": "IPY_MODEL_71fec538988d4f5cb2bbc51a305dc559",
       "value": " 3/3 [00:00&lt;00:00,  2.22ba/s]"
      }
     },
     "bbf771efd9544a3dbb27dc46ed6e90ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_46e8db13110847b09b31493bf1aef00f",
        "IPY_MODEL_00168cc339ab4d37bbf040239346f903",
        "IPY_MODEL_aef8e4636f5548918a4bbf164e7dfd50"
       ],
       "layout": "IPY_MODEL_98ba5b3a839a4d92ae7559367819272a"
      }
     },
     "bdb7c24b9d4e468a966ce332f01cacdd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cc3ab1576d874b44837b3aa95e2f23d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_599b4af1fcf4439e97ba4eef14b0f308",
        "IPY_MODEL_6077e6bc33064f14819ec0f99f3e0987"
       ],
       "layout": "IPY_MODEL_0011af7c2a1a44b2b86abd139850f8f5"
      }
     },
     "defd01d3f3ce4fd3acfacdbdbcdd8f9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e872f51fbed0454e9f426a640e046d7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
