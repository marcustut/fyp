{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Summarisation With BERT\n",
    "_By: Ling Li Ya_\n",
    "\n",
    "References:\n",
    "1. [BERT Extractive Summarizer](https://github.com/dmmiller612/bert-extractive-summarizer)\n",
    "2. [How to train a new language model from scratch using Transformers and Tokenizers](https://huggingface.co/blog/how-to-train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "body =[\n",
    "    'In church construction, especially in the southern German-Austrian region, gigantic spatial creations are sometimes created for practical reasons alone, which, however, do not appear monumental, but are characterized by a unique fusion of architecture, painting, stucco, etc., often completely eliminating the boundaries between the art genres, and are characterized by a light-filled weightlessness, festive cheerfulness and movement. The Rococo decorative style reached its summit in southern Germany and Austria from the 1730s until the 1770s. There it dominates the church landscape to this day and is deeply anchored there in popular culture. It was first introduced from France through the publications and works of French architects and decorators, including the sculptor Claude III Audran, the interior designer Gilles-Marie Oppenordt, the architect Germain Boffrand, the sculptor Jean Mondon, and the draftsman and engraver Pierre Lepautre. Their work had an important influence on the German Rococo style, but does not reach the level of buildings in southern Germany.[25]',\n",
    "\n",
    "'German architects adapted the Rococo style but made it far more asymmetric and loaded with more ornate decoration than the French original. The German style was characterized by an explosion of forms that cascaded down the walls. It featured molding formed into curves and counter-curves, twisting and turning patterns, ceilings and walls with no right angles, and stucco foliage which seemed to be creeping up the walls and across the ceiling. The decoration was often gilded or silvered to give it contrast with the white or pale pastel walls.[26]',\n",
    "\n",
    "'The Belgian-born architect and designer François de Cuvilliés was one of the first to create a Rococo building in Germany, with the pavilion of Amalienburg in Munich, (1734-1739), inspired by the pavilions of the Trianon and Marly in France. It was built as a hunting lodge, with a platform on the roof for shooting pheasants. The Hall of Mirrors in the interior, by the painter and stucco sculptor Johann Baptist Zimmermann, was far more exuberant than any French Rococo.[27]',\n",
    "\n",
    "'Another notable example of the early German Rococo is Würzburg Residence (1737–1744) constructed for the Prince-Bishop of Würzburg by Balthasar Neumann. Neumann had traveled to Paris and consulted with the French rocaille decorative artists Germain Boffrand and Robert de Cotte. While the exterior was in more sober Baroque style, the interior, particularly the stairways and ceilings, was much lighter and decorative. The Prince-Bishop imported the Italian Rococo painter Giovanni Battista Tiepolo in 1750–53 to create a mural over the top of the three-level ceremonial stairway.[28][29] Neumann described the interior of the residence as \"a theater of light\". The stairway was also the central element in a residence Neumann built at the Augustusburg Palace in Brühl (1743–1748). In that building the stairway led the visitors up through a stucco fantasy of paintings, sculpture, ironwork and decoration, with surprising views at every turn.[28]',\n",
    "\n",
    "'In the 1740s and 1750s, a number of notable pilgrimage churches were constructed in Bavaria, with interiors decorated in a distinctive variant of the rococo style. One of the most notable examples is the Wieskirche (1745–1754) designed by Dominikus Zimmermann. Like most of the Bavarian pilgrimage churches, the exterior is very simple, with pastel walls, and little ornament. Entering the church the visitor encounters an astonishing theater of movement and light. It features an oval-shaped sanctuary, and a deambulatory in the same form, filling in the church with light from all sides. The white walls contrasted with columns of blue and pink stucco in the choir, and the domed ceiling surrounded by plaster angels below a dome representing the heavens crowded with colorful Biblical figures. Other notable pilgrimage churches include the Basilica of the Fourteen Holy Helpers by Balthasar Neumann (1743–1772).[30][31]'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = '../models/bert-ext.pkl'\n",
    "\n",
    "pickle.dump(model, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'In church construction, especially in the southern German-Austrian region, gigantic spatial creations are sometimes created for practical reasons alone, which, however, do not appear monumental, but are characterized by a unique fusion of architecture, painting, stucco, etc., It was first introduced from France through the publications and works of French architects and decorators, including the sculptor Claude III Audran, the interior designer Gilles-Marie Oppenordt, the architect Germain Boffrand, the sculptor Jean Mondon, and the draftsman and engraver Pierre Lepautre.'},\n",
       " {'summary_text': 'German architects adapted the Rococo style but made it far more asymmetric and loaded with more ornate decoration than the French original. The German style was characterized by an explosion of forms that cascaded down the walls.'},\n",
       " {'summary_text': 'The Belgian-born architect and designer François de Cuvilliés was one of the first to create a Rococo building in Germany, with the pavilion of Amalienburg in Munich, (1734-1739), inspired by the pavilions of the Trianon and Marly in France. It was built as a hunting lodge, with a platform on the roof for shooting pheasants.'},\n",
       " {'summary_text': 'Another notable example of the early German Rococo is Würzburg Residence (1737–1744) constructed for the Prince-Bishop of Würzburg by Balthasar Neumann. The Prince-Bishop imported the Italian Rococo painter Giovanni Battista Tiepolo in 1750–53 to create a mural over the top of the three-level ceremonial stairway.[28][29] Neumann described the interior of the residence as \"a theater of light\".'},\n",
       " {'summary_text': 'In the 1740s and 1750s, a number of notable pilgrimage churches were constructed in Bavaria, with interiors decorated in a distinctive variant of the rococo style. Like most of the Bavarian pilgrimage churches, the exterior is very simple, with pastel walls, and little ornament.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for chunk in body:\n",
    "    dict_ = {'summary_text': model(chunk, ratio=0.05)}\n",
    "    res.append(dict_)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In church construction, especially in the southern German-Austrian region, gigantic spatial creations are sometimes created for practical reasons alone, which, however, do not appear monumental, but are characterized by a unique fusion of architecture, painting, stucco, etc., The German style was characterized by an explosion of forms that cascaded down the walls. The decoration was often gilded or silvered to give it contrast with the white or pale pastel walls.[26]\\n\\nThe Belgian-born architect and designer François de Cuvilliés was one of the first to create a Rococo building in Germany, with the pavilion of Amalienburg in Munich, (1734-1739), inspired by the pavilions of the Trianon and Marly in France. It was built as a hunting lodge, with a platform on the roof for shooting pheasants. While the exterior was in more sober Baroque style, the interior, particularly the stairways and ceilings, was much lighter and decorative.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>source_labels</th>\n",
       "      <th>rouge_scores</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Due to the success of deep learning to solvin...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.30188678746885, 0.37209301838831804, 0.6037...</td>\n",
       "      <td>SysEexbRb</td>\n",
       "      <td>[We provide necessary and sufficient analytica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The backpropagation (BP) algorithm is often t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.130434779206049, 0.14285713922902...</td>\n",
       "      <td>SygvZ209F7</td>\n",
       "      <td>[Biologically plausible learning algorithms, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[We introduce the 2-simplicial Transformer, an...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.333333328395061, 0.8888888839111111, 0.1142...</td>\n",
       "      <td>rkecJ6VFvr</td>\n",
       "      <td>[We introduce the 2-simplicial Transformer and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We present Tensor-Train RNN (TT-RNN), a novel...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.066666662222222, 0.06451612466181, 0.060606...</td>\n",
       "      <td>HJJ0w--0W</td>\n",
       "      <td>[Accurate forecasting over very long time hori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Recent efforts on combining deep models with ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.27777777279320903, 0.571428566658163, 0.095...</td>\n",
       "      <td>HyH9lbZAW</td>\n",
       "      <td>[We propose a variational message-passing algo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  [Due to the success of deep learning to solvin...   \n",
       "1  [The backpropagation (BP) algorithm is often t...   \n",
       "2  [We introduce the 2-simplicial Transformer, an...   \n",
       "3  [We present Tensor-Train RNN (TT-RNN), a novel...   \n",
       "4  [Recent efforts on combining deep models with ...   \n",
       "\n",
       "                                       source_labels  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        rouge_scores    paper_id  \\\n",
       "0  [0.30188678746885, 0.37209301838831804, 0.6037...   SysEexbRb   \n",
       "1  [0.0, 0.0, 0.130434779206049, 0.14285713922902...  SygvZ209F7   \n",
       "2  [0.333333328395061, 0.8888888839111111, 0.1142...  rkecJ6VFvr   \n",
       "3  [0.066666662222222, 0.06451612466181, 0.060606...   HJJ0w--0W   \n",
       "4  [0.27777777279320903, 0.571428566658163, 0.095...   HyH9lbZAW   \n",
       "\n",
       "                                              target  \n",
       "0  [We provide necessary and sufficient analytica...  \n",
       "1  [Biologically plausible learning algorithms, p...  \n",
       "2  [We introduce the 2-simplicial Transformer and...  \n",
       "3  [Accurate forecasting over very long time hori...  \n",
       "4  [We propose a variational message-passing algo...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_json = pd.read_json('C:/Users/liana/Documents/Projects/fyp/dataset/train.jsonl', lines=True)\n",
    "train_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>source_labels</th>\n",
       "      <th>rouge_scores</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Incremental class learning involves sequentia...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.28571428104489804, 0.18181817681818102, 0.2...</td>\n",
       "      <td>SJ1Xmf-Rb</td>\n",
       "      <td>[FearNet is a memory efficient neural-network,...</td>\n",
       "      <td>FearNet: Brain-Inspired Model for Incremental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Multi-view learning can provide self-supervis...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.19999999580000002, 0.0, 0.15789473418282501...</td>\n",
       "      <td>S1xzyhR9Y7</td>\n",
       "      <td>[Multi-view learning improves unsupervised sen...</td>\n",
       "      <td>Improving Sentence Representations with Multi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[We show how discrete objects can be learnt in...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.9787233992575821, 0.33333332860555503, 0.41...</td>\n",
       "      <td>HJDUjKeA-</td>\n",
       "      <td>[We show how discrete objects can be learnt in...</td>\n",
       "      <td>Learning objects from pixels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Most recent gains in visual recognition have ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0.11764705384083, 0.146341458655562, 0.199999...</td>\n",
       "      <td>BJgLg3R9KQ</td>\n",
       "      <td>[A large-scale dataset for training attention ...</td>\n",
       "      <td>Learning what and where to attend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In recent years, deep neural networks have de...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.05882352484429101, 0.270270265887509, ...</td>\n",
       "      <td>BklpOo09tQ</td>\n",
       "      <td>[We proposed a time-efficient defense method a...</td>\n",
       "      <td>EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  [Incremental class learning involves sequentia...   \n",
       "1  [Multi-view learning can provide self-supervis...   \n",
       "2  [We show how discrete objects can be learnt in...   \n",
       "3  [Most recent gains in visual recognition have ...   \n",
       "4  [In recent years, deep neural networks have de...   \n",
       "\n",
       "                 source_labels  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "1           [1, 0, 0, 0, 0, 0]   \n",
       "2              [1, 0, 0, 0, 0]   \n",
       "3           [0, 0, 1, 0, 0, 0]   \n",
       "4     [0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                        rouge_scores    paper_id  \\\n",
       "0  [0.28571428104489804, 0.18181817681818102, 0.2...   SJ1Xmf-Rb   \n",
       "1  [0.19999999580000002, 0.0, 0.15789473418282501...  S1xzyhR9Y7   \n",
       "2  [0.9787233992575821, 0.33333332860555503, 0.41...   HJDUjKeA-   \n",
       "3  [0.11764705384083, 0.146341458655562, 0.199999...  BJgLg3R9KQ   \n",
       "4  [0.0, 0.05882352484429101, 0.270270265887509, ...  BklpOo09tQ   \n",
       "\n",
       "                                              target  \\\n",
       "0  [FearNet is a memory efficient neural-network,...   \n",
       "1  [Multi-view learning improves unsupervised sen...   \n",
       "2  [We show how discrete objects can be learnt in...   \n",
       "3  [A large-scale dataset for training attention ...   \n",
       "4  [We proposed a time-efficient defense method a...   \n",
       "\n",
       "                                               title  \n",
       "0  FearNet: Brain-Inspired Model for Incremental ...  \n",
       "1  Improving Sentence Representations with Multi-...  \n",
       "2                       Learning objects from pixels  \n",
       "3                  Learning what and where to attend  \n",
       "4  EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEE...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_json = pd.read_json('C:/Users/liana/Documents/Projects/fyp/dataset/test.jsonl', lines=True)\n",
    "test_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>source_labels</th>\n",
       "      <th>rouge_scores</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Mixed precision training (MPT) is becoming a ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0.23999999580000003, 0.260869560822306, 0.199...</td>\n",
       "      <td>rJlnfaNYvB</td>\n",
       "      <td>[We devise adaptive loss scaling to improve mi...</td>\n",
       "      <td>Adaptive Loss Scaling for Mixed Precision Trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Many real-world problems, e.g. object detecti...</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>[0.054054049086925, 0.29268292183224204, 0.974...</td>\n",
       "      <td>rJVoEiCqKQ</td>\n",
       "      <td>[We present a novel approach for learning to p...</td>\n",
       "      <td>Deep Perm-Set Net: Learn to predict sets with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Foveation is an important part of human visio...</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>[0.11764705382352901, 0.11764705382352901, 0.3...</td>\n",
       "      <td>rkldVXKU8H</td>\n",
       "      <td>[We compare object recognition performance on ...</td>\n",
       "      <td>Foveated Downsampling Techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We explore the concept of co-design in the co...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.12499999548828102, 0.488888883911111, 0.204...</td>\n",
       "      <td>BJfIVjAcKm</td>\n",
       "      <td>[We develop methods to train deep neural model...</td>\n",
       "      <td>Training for Faster Adversarial Robustness Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Batch Normalization (BatchNorm) has shown to ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0.1999999952, 0.239999995008, 0.3999999950080...</td>\n",
       "      <td>BJlEEaEFDS</td>\n",
       "      <td>[Investigation of how BatchNorm causes adversa...</td>\n",
       "      <td>Towards an Adversarially Robust Normalization ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source       source_labels  \\\n",
       "0  [Mixed precision training (MPT) is becoming a ...  [0, 0, 0, 1, 0, 0]   \n",
       "1  [Many real-world problems, e.g. object detecti...     [0, 0, 1, 0, 0]   \n",
       "2  [Foveation is an important part of human visio...     [0, 0, 1, 0, 0]   \n",
       "3  [We explore the concept of co-design in the co...  [0, 1, 0, 0, 0, 0]   \n",
       "4  [Batch Normalization (BatchNorm) has shown to ...  [0, 0, 1, 0, 0, 0]   \n",
       "\n",
       "                                        rouge_scores    paper_id  \\\n",
       "0  [0.23999999580000003, 0.260869560822306, 0.199...  rJlnfaNYvB   \n",
       "1  [0.054054049086925, 0.29268292183224204, 0.974...  rJVoEiCqKQ   \n",
       "2  [0.11764705382352901, 0.11764705382352901, 0.3...  rkldVXKU8H   \n",
       "3  [0.12499999548828102, 0.488888883911111, 0.204...  BJfIVjAcKm   \n",
       "4  [0.1999999952, 0.239999995008, 0.3999999950080...  BJlEEaEFDS   \n",
       "\n",
       "                                              target  \\\n",
       "0  [We devise adaptive loss scaling to improve mi...   \n",
       "1  [We present a novel approach for learning to p...   \n",
       "2  [We compare object recognition performance on ...   \n",
       "3  [We develop methods to train deep neural model...   \n",
       "4  [Investigation of how BatchNorm causes adversa...   \n",
       "\n",
       "                                               title  \n",
       "0  Adaptive Loss Scaling for Mixed Precision Trai...  \n",
       "1  Deep Perm-Set Net: Learn to predict sets with ...  \n",
       "2                   Foveated Downsampling Techniques  \n",
       "3  Training for Faster Adversarial Robustness Ver...  \n",
       "4  Towards an Adversarially Robust Normalization ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_json = pd.read_json('C:/Users/liana/Documents/Projects/fyp/dataset/dev.jsonl', lines=True)\n",
    "dev_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert json into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_csv = train_json.to_csv()\n",
    "# test_csv = test_json.to_csv()\n",
    "# dev_csv = dev_json.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1992 entries, 0 to 1991\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   source         1992 non-null   object\n",
      " 1   source_labels  1992 non-null   object\n",
      " 2   rouge_scores   1992 non-null   object\n",
      " 3   paper_id       1992 non-null   object\n",
      " 4   target         1992 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 77.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source           0\n",
       "source_labels    0\n",
       "rouge_scores     0\n",
       "paper_id         0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source           0\n",
       "source_labels    0\n",
       "rouge_scores     0\n",
       "paper_id         0\n",
       "target           0\n",
       "title            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_json.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source           0\n",
       "source_labels    0\n",
       "rouge_scores     0\n",
       "paper_id         0\n",
       "target           0\n",
       "title            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_json.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>source_labels</th>\n",
       "      <th>rouge_scores</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Due to the success of deep learning to solvin...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.30188678746885, 0.37209301838831804, 0.6037...</td>\n",
       "      <td>SysEexbRb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The backpropagation (BP) algorithm is often t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.130434779206049, 0.14285713922902...</td>\n",
       "      <td>SygvZ209F7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[We introduce the 2-simplicial Transformer, an...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.333333328395061, 0.8888888839111111, 0.1142...</td>\n",
       "      <td>rkecJ6VFvr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We present Tensor-Train RNN (TT-RNN), a novel...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.066666662222222, 0.06451612466181, 0.060606...</td>\n",
       "      <td>HJJ0w--0W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Recent efforts on combining deep models with ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.27777777279320903, 0.571428566658163, 0.095...</td>\n",
       "      <td>HyH9lbZAW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  [Due to the success of deep learning to solvin...   \n",
       "1  [The backpropagation (BP) algorithm is often t...   \n",
       "2  [We introduce the 2-simplicial Transformer, an...   \n",
       "3  [We present Tensor-Train RNN (TT-RNN), a novel...   \n",
       "4  [Recent efforts on combining deep models with ...   \n",
       "\n",
       "                                       source_labels  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        rouge_scores    paper_id  \n",
       "0  [0.30188678746885, 0.37209301838831804, 0.6037...   SysEexbRb  \n",
       "1  [0.0, 0.0, 0.130434779206049, 0.14285713922902...  SygvZ209F7  \n",
       "2  [0.333333328395061, 0.8888888839111111, 0.1142...  rkecJ6VFvr  \n",
       "3  [0.066666662222222, 0.06451612466181, 0.060606...   HJJ0w--0W  \n",
       "4  [0.27777777279320903, 0.571428566658163, 0.095...   HyH9lbZAW  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_full = train_json.drop('target', axis=1)\n",
    "Xtrain = Xtrain_full[:100]\n",
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [We provide necessary and sufficient analytica...\n",
       "1    [Biologically plausible learning algorithms, p...\n",
       "2    [We introduce the 2-simplicial Transformer and...\n",
       "3    [Accurate forecasting over very long time hori...\n",
       "4    [We propose a variational message-passing algo...\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_full = train_json['target']\n",
    "ytrain = ytrain_full[:100]\n",
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [FearNet is a memory efficient neural-network,...\n",
       "1    [Multi-view learning improves unsupervised sen...\n",
       "2    [We show how discrete objects can be learnt in...\n",
       "3    [A large-scale dataset for training attention ...\n",
       "4    [We proposed a time-efficient defense method a...\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = test_json.drop('target', axis=1)\n",
    "Xtest.head()\n",
    "ytest = test_json['target']\n",
    "ytest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning BERT using Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning BERT using Pytorch Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect.',\n",
       " 'Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms.',\n",
       " 'In this paper, we provide a necessary and sufficient characterization of the analytical forms for the critical points (as well as global minimizers) of the square loss functions for linear neural networks.',\n",
       " 'We show that the analytical forms of the critical points characterize the values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum.',\n",
       " 'Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks.',\n",
       " 'One particular conclusion is that: While the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global minimum.',\n",
       " 'In the past decade, deep neural networks BID8 have become a popular tool that has successfully solved many challenging tasks in a variety of areas such as machine learning, artificial intelligence, computer vision, and natural language processing, etc.',\n",
       " 'As the understandings of deep neural networks from different aspects are mostly based on empirical studies, there is a rising need and interest to develop understandings of neural networks from theoretical aspects such as generalization error, representation power, and landscape (also referred to as geometry) properties, etc.',\n",
       " 'In particular, the landscape properties of loss functions (that are typically nonconex for neural networks) play a central role to determine the iteration path and convergence performance of optimization algorithms.',\n",
       " 'One major landscape property is the nature of critical points, which can possibly be global minima, local minima, saddle points.',\n",
       " 'There have been intensive efforts in the past into understanding such an issue for various neural networks.',\n",
       " 'For example, it has been shown that every local minimum of the loss function is also a global minimum for shallow linear networks under the autoencoder setting and invertibility assumptions BID1 and for deep linear networks BID11 ; BID14 ; Yun et al. (2017) respectively under different assumptions.',\n",
       " 'The conditions on the equivalence between local minimum or critical point and global minimum has also been established for various nonlinear neural networks Yu & Chen (1995) ; BID9 ; BID15 ; BID17 ; BID6 under respective assumptions.',\n",
       " 'However, most previous studies did not provide characterization of analytical forms for critical points of loss functions for neural networks with only very few exceptions.',\n",
       " 'In BID1 , the authors provided an analytical form for the critical points of the square loss function of shallow linear networks under certain conditions.',\n",
       " 'Such an analytical form further helps to establish the landscape properties around the critical points.',\n",
       " 'Further in BID13 , the authors characterized certain sufficient form of critical points for the square loss function of matrix factorization problems and deep linear networks.',\n",
       " 'The focus of this paper is on characterizing the sufficient and necessary forms of critical points for broader scenarios, i.e., shallow and deep linear networks with no assumptions on data matrices and network dimensions, and shallow ReLU networks over certain parameter space.',\n",
       " 'In particular, such analytical forms of critical points capture the corresponding loss function values and the necessary and sufficient conditions to achieve global minimum.',\n",
       " 'This further enables us to establish new landscape properties around these critical points for the loss function of these networks under general settings, and provides alternative (yet simpler and more intuitive) proofs for existing understanding of the landscape properties.',\n",
       " 'OUR CONTRIBUTION 1) For the square loss function of linear networks with one hidden layer, we provide a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.',\n",
       " 'These results generalize the characterization in BID1 to arbitrary network parameter dimensions and any data matrices.',\n",
       " 'Such a generalization further enables us to establish the landscape property, i.e., every local minimum is also a global minimum and all other critical points are saddle points, under no assumptions on parameter dimensions and data matrices.',\n",
       " 'From a technical standpoint, we exploit the analytical forms of critical points to provide a new proof for characterizing the landscape around the critical points under full relaxation of assumptions, where the corresponding approaches in BID1 are not applicable.',\n",
       " 'As a special case of linear networks, the matrix factorization problem satisfies all these landscape properties.2) For the square loss function of deep linear networks, we establish a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.',\n",
       " 'Such characterizations are new and have not been established in the existing art.',\n",
       " 'Furthermore, such analytical form divides the set of non-global-minimum critical points into different categories.',\n",
       " 'We identify the directions along which the loss function value decreases for two categories of the critical points, for which our result directly implies the equivalence between the local minimum and the global minimum.',\n",
       " 'For these cases, our proof generalizes the result in BID11 under no assumptions on the network parameter dimensions and data matrices.3) For the square loss function of one-hidden-layer nonlinear neural networks with ReLU activation function, we provide a full characterization of both the existence and the analytical forms of the critical points in certain types of regions in the parameter space.',\n",
       " 'Particularly, in the case where there is one hidden unit, our results fully characterize the existence and the analytical forms of the critical points in the entire parameter space.',\n",
       " 'Such characterization were not provided in previous work on nonlinear neural networks.',\n",
       " 'Moreover, we apply our results to a concrete example to demonstrate that both local minimum that is not a global minimum and local maximum do exist in such a case.',\n",
       " 'Analytical forms of critical points: Characterizing the analytical form of critical points for loss functions of neural networks dates back to BID1 , where the authors provided an analytical form of the critical points for the square loss function of linear networks with one hidden layer.',\n",
       " 'In BID13 , the authors provided a sufficient condition of critical points of a generic function, i.e., the fixed point of invariant groups.',\n",
       " 'They then characterized certain sufficient forms of critical points for the square loss function of matrix factorization problems and deep linear networks, whereas our results provide sufficient and necessary forms of critical points for deep linear networks via a different approach.',\n",
       " 'Properties of critical points: BID1 ; BID0 studied the linear autoencoder with one hidden layer and showed the equivalence between the local minimum and the global minimum.',\n",
       " 'Moreover, BID2 generalized these results to the complex-valued autoencoder setting.',\n",
       " 'The deep linear networks were studied by some recent work BID11 ; BID14 Yun et al. (2018) , in which the equivalence between the local minimum and the global minimum was established respectively under different assumptions.',\n",
       " 'Particularly, Yun et al. (2017) established a necessary and sufficient condition for a critical point of the deep linear network to be a global minimum.',\n",
       " 'A similar result was established in BID7 for deep linear networks under the setting that the widths of intermediate layers are larger than those of the input and output layers.',\n",
       " 'The effect of regularization on the critical points for a two-layer linear network was studied in Taghvaei et al. (2017) .For nonlinear neural networks, Yu & Chen (1995) studied a nonlinear neural network with one hidden layer and sigmoid activation function, and showed that every local minimum is also a global minimum provided that the number of input units equals the number of data samples.',\n",
       " 'BID9 considered a class of multi-layer nonlinear networks with a pyramidal structure, and showed that all critical points of full column rank achieve the zero loss when the sample size is less than the input dimension.',\n",
       " 'These results were further generalized to a larger class of nonlinear networks in BID15 , in which they also showed that critical points with non-degenerate Hessian are global minimum.',\n",
       " 'BID3 b) connected the loss surface of deep nonlinear networks with the Hamiltonian of the spin-glass model under certain assumptions and characterized the distribution of the local minimum.',\n",
       " 'BID11 further eliminated some of the assumptions in BID3 , and established the equivalence between the local minimum and the global minimum by reducing the loss function of the deep nonlinear network to that of the deep linear network.',\n",
       " 'BID17 showed that a two-layer nonlinear network has no bad differentiable local minimum.',\n",
       " 'BID6 studied a one-hidden-layer nonlinear neural network with the parameters restricted in a set of directions of lines, and showed that most local minima are global minima.',\n",
       " 'Tian (2017) considered a two-layer ReLU network with Gaussian input data, and showed that critical points in certain region are non-isolated and characterized the critical-point-free regions.',\n",
       " 'Geometric curvature BID10 established the gradient dominance condition of deep linear residual networks, and Zhou & Liang (2017) further established the gradient dominance condition and regularity condition around the global minimizers for deep linear, deep linear residual and shallow nonlinear networks.',\n",
       " 'BID12 studied the property of the Hessian matrix for deep linear residual networks.',\n",
       " 'The local strong convexity property was established in BID16 for overparameterized nonlinear networks with one hidden layer and quadratic activation functions, and was established in Zhong et al. (2017) for a class of nonlinear networks with one hidden layer and Gaussian input data.',\n",
       " 'Zhong et al. (2017) further established the local linear convergence of gradient descent method with tensor initialization.',\n",
       " 'BID18 studied a one-hidden-layer nonlinear network with a single output, and showed that the volume of sub-optimal differentiable local minima is exponentially vanishing in comparison with the volume of global minima.',\n",
       " 'BID5 investigated the saddle points in deep neural networks using the results from statistical physics and random matrix theory.',\n",
       " 'Notation: The pseudoinverse, column space and null space of a matrix M are denoted by M † , col(M ) and ker(M ), respectively.',\n",
       " 'For any index sets I, J ⊂ N, M I,J denotes the submatrix of M formed by the entries with the row indices in I and the column indices in J. For positive integers i ≤ j, we define i : j = {i, i + 1, . . . , j − 1, j}. The projection operator onto a linear subspace V is denoted by P V .',\n",
       " 'In this section, we study linear neural networks with one hidden layer.',\n",
       " 'Suppose we have an input data matrix X ∈ R d0×m and a corresponding output data matrix Y ∈ R d2×m , where there are in total m data samples.',\n",
       " 'We are interested in learning a model that maps from X to Y via a linear network with one hidden layer.',\n",
       " 'Specifically, we denote the weight parameters between the output layer and the hidden layer of the network as A 2 ∈ R d2×d1 , and denote the weight parameters between the hidden layer and the input layer of the network as A 1 ∈ R d1×d0 .',\n",
       " 'We are interested in the square loss function of this linear network, which is given by DISPLAYFORM0 Note that in a special case where X = I, L reduces to a loss function for the matrix factorization problem, to which all our results apply.',\n",
       " 'The loss function L has been studied in BID1 under the assumptions that d 2 = d 0 ≥ d 1 and the matrices XX , Y X (XX ) −1 XY are invertible.',\n",
       " 'In our study, no assumption is made on either the parameter dimensions or the invertibility of the data matrices.',\n",
       " 'Such full generalization of the results in BID1 turns out to be critical for our study of nonlinear shallow neural networks in Section 4.We further define Σ := Y X † XY and denote its full singular value decomposition as U ΛU .',\n",
       " 'Suppose that Σ has r distinct positive singular values σ 1 > · · · > σ r > 0 with multiplicities m 1 , . . .',\n",
       " ', m r , respectively, and hasm zero singular values.',\n",
       " 'Recall that DISPLAYFORM1 Our first result provides a full characterization of all critical points of L. Theorem 1 (Characterization of critical points).',\n",
       " 'All critical points of L are necessarily and sufficiently characterized by a matrix L 1 ∈ R d1×d0 , a block matrix V ∈ R d2×d1 and an invertible matrix C ∈ R d1×d1 via DISPLAYFORM2 (2) DISPLAYFORM3 , where both V i ∈ R mi×pi and V ∈ Rm ×p consist of orthonormal columns with the number of columns DISPLAYFORM4 Theorem 1 characterizes the necessary and sufficient forms for all critical points of L. Intuitively, the matrix C captures the invariance of the product A 2 A 1 under an invertible transform, and L 1 captures the degree of freedom of the solution set for linear systems.',\n",
       " 'In general, the set of critical points is uncountable and cannot be fully listed out.',\n",
       " 'However, the analytical forms in eqs. (1) and (2) do allow one to construct some critical points of L by specifying choices of L 1 , V , C that fulfill the condition in eq. (3).',\n",
       " 'For example, choosing L 1 = 0 guarantees eq. (3), in which case eqs. (1) and (2) yield a critical point (C −1 V U Y X † , U V C) for any invertible matrix C and any block matrix V that takes the form specified in Theorem 1.',\n",
       " 'For nonzero L 1 , one can fix a proper V and solve the linear equation on C in eq. (3).',\n",
       " 'If a solution exists, we then obtain the form of a corresponding critical point.',\n",
       " 'We further note that the analytical structures of the critical points are more important, which have direct implications on the global optimality conditions and landscape properties as we show in the remaining part of the section.',\n",
       " 'Remark 1.',\n",
       " 'We note that the block pattern parameters {p i } r i=1 andp denote the number of columns of {V i } r i=1 and V , respectively, and their sum equals the rank of A 2 , i.e., DISPLAYFORM5 The parameters p i , i = 1, . . .',\n",
       " ', r,p of V contain all useful information of the critical points that determine the function value of L as presented in the following proposition.',\n",
       " 'DISPLAYFORM6 Proposition 1 evaluates the function value L at a critical point using the parameters {p i } r i=1 .',\n",
       " 'To explain further, recall that the data matrix Σ has each singular value σ i with multiplicity m i .',\n",
       " 'For each i, the critical point captures p i out of m i singular values σ i .',\n",
       " 'Hence, for a σ i with larger value (i.e., a smaller index i), it is desirable that a critical point captures a larger number p i of them.',\n",
       " 'In this way, the critical point captures more important principle components of the data so that the value of the loss function is further reduced as suggested by Proposition 1.',\n",
       " 'In summary, the parameters {p i } r i=1 characterize how well the learned model fits the data in terms of the value of the loss function.',\n",
       " 'Moreover, the parameters {p i } r i=1 also determine a full characterization of the global minimizers as given below.',\n",
       " 'Proposition 2 (Characterization of global minimizers).',\n",
       " 'A critical point (A 1 , A 2 ) of L is a global minimizer if and only if it falls into the following two cases.',\n",
       " 'DISPLAYFORM7 The analytical form of any global minimizer can be obtained from Theorem 1 with further specification to the above two cases.',\n",
       " 'Proposition 2 establishes the neccessary and sufficient conditions for any critical point to be a global minimizer.',\n",
       " 'If the data matrix Σ has a large number of nonzero singular values, i.e., the first case, one needs to exhaust the representation budget (i.e., rank) of A 2 and capture as many large singular values as the rank allows to achieve the global minimum; Otherwise, A 2 of a global minimizer can be non-full rank and still captures all nonzero singular values.',\n",
       " 'Note that A 2 must be full rank in the case 1, and so is A 1 if we further adopt the assumptions on the network size and data matrices in BID1 .',\n",
       " 'Furthermore, the parameters {p i } r i=1 naturally divide all non-global-minimum critical points (A 1 , A 2 ) of L into the following two categories.• (Non-optimal order): The matrix V specified in Theorem 1 satisfies that there exists 1 ≤ i < j ≤ r such that p i < m i and p j > 0.• (Optimal order): rank(A 2 ) < min{d 2 , d 1 } and the matrix V specified in Theorem 1 satisfies that DISPLAYFORM8 To understand the above two categories, note that a critical point of L with non-optimal order captures a smaller singular value σ j (since p j > 0) while skipping a larger singular value σ i with a lower index i < j (since p i < m i ), and hence cannot be a global minimizer.',\n",
       " 'On the other hand, although a critical point of L with optimal order captures the singular values in the optimal (i.e., decreasing) order, it does not fully utilize the representation budget of A 2 (because A 2 is non-full rank) to further capture nonzero singular values and reduce the function value, and hence cannot be a global minimizer either.',\n",
       " 'Next, we show that these two types of non-global-minimum critical points have different landscape properties around them.',\n",
       " 'Throughout, a matrix M is called the perturbation of M if it lies in an arbitrarily small neighborhood of M .Proposition 3 (Landscape around critical points).',\n",
       " 'The critical points of L have the following landscape properties.1.',\n",
       " 'A non-optimal-order critical point (A 1 , A 2 ) has a perturbation ( A 1 , A 2 ) with rank( A 2 ) = rank(A 2 ), which achieves a lower function value; 2.',\n",
       " 'An optimal-order critical point (A 1 , A 2 ) has a perturbation ( A 1 , A 2 ) with rank( A 2 ) = rank(A 2 ) + 1, which achieves a lower function value; 3.',\n",
       " 'Any point in X := {(A 1 , A 2 ) : A 2 A 1 X = 0} has a perturbation (A 1 , A 2 ), which achieves a higher function value;As a consequence, items 1 and 2 imply that any non-global-minimum critical point has a descent direction, and hence cannot be a local minimizer.',\n",
       " 'Thus, any local minimizer must be a global minimizer.',\n",
       " 'Item 3 implies that any point has an ascent direction whenever the output is nonzero.',\n",
       " 'Hence, there does not exist any local/global maximizer in X .',\n",
       " 'Furthermore, item 3 together with items 1 and 2 implies that any non-global-minimum critical point in X has both descent and ascent directions, and hence must be a saddle point.',\n",
       " 'We summarize these facts in the following theorem.',\n",
       " 'Theorem 2 (Landscape of L).',\n",
       " 'The loss function L satisfies: 1) every local minimum is also a global minimum; 2) every non-global-minimum critical point in X is a saddle point.',\n",
       " 'We note that the saddle points in Theorem 2 can be non-strict when the data matrices are singular.',\n",
       " 'As an illustrative example, consider the following loss function of a shallow linear network L(a 2 , a 1 ) = 1 2 (a 2 a 1 x − y) 2 , where a 1 , a 2 , x and y are all scalars.',\n",
       " 'Consider the case y = 0.',\n",
       " 'Then, the Hessian at the saddle point a 1 = 0, a 2 = 1 is [x 2 , 0; 0, 0], which does not have any negative eigenvalue.',\n",
       " 'From a technical point of view, the proof of item 1 of Proposition 3 applies that in BID0 and generalizes it to the setting where Σ can have repeated singular values and may not be invertible.',\n",
       " 'To further understand the perturbation scheme from a high level perspective, note that non-optimalorder critical points capture a smaller singular value σ j instead of a larger one σ i with i < j. Thus, one naturally perturbs the singular vector corresponding to σ j along the direction of the singular vector corresponding to σ i .',\n",
       " 'Such a perturbation scheme preserves the rank of A 2 and reduces the value of the loss function.',\n",
       " 'More importantly, the proof of item 2 of Proposition 3 introduces a new technique.',\n",
       " 'As a comparison, BID1 proves a similar result as item 2 using the strict convexity of the function, which requires the parameter dimensions to satisfy d 2 = d 0 ≥ d 1 and the data matrices to be invertible.',\n",
       " 'In contrast, our proof completely removes these restrictions by introducing a new perturbation direction and exploiting the analytical forms of critical points in eqs. (1) and (2) and the condition in eq. (3).',\n",
       " 'The accomplishment of the proof further requires careful choices of perturbation parameters as well as judicious manipulations of matrices.',\n",
       " 'We refer the reader to the supplemental materials for more details.',\n",
       " 'As a high level understanding, since optimal-order critical points capture the singular values in an optimal (i.e., decreasing) order, the previous perturbation scheme for non-optimal-order critical points does not apply.',\n",
       " 'Instead, we increase the rank of A 2 by one in a way that the perturbed matrix captures the next singular value beyond the ones that have already been captured so that the value of the loss function can be further reduced.',\n",
       " 'In this section, we study deep linear networks with ≥ 2 layers.',\n",
       " 'We denote the weight parameters between the layers as A k ∈ R d k ×d k−1 for k = 1, . . .',\n",
       " ', , respectively.',\n",
       " 'The input and output data are denoted by X ∈ R d0×m , Y ∈ R d ×m , respectively.',\n",
       " 'We are interested in the square loss function of deep linear networks, which is given by DISPLAYFORM0 , respectively, andm(k) zero singular values.',\n",
       " 'Our first result provides a full characterization of all critical points of L D , where we denote DISPLAYFORM1 Theorem 3 (Characterization of critical points).',\n",
       " 'All critical points of L D are necessarily and sufficiently characterized by matrices DISPLAYFORM2 . .',\n",
       " ', A can be individually expressed out recursively via the following two equations: DISPLAYFORM3 DISPLAYFORM4 Note that the forms of the individual parameters A 1 , . . .',\n",
       " ', A can be obtained as follows by recursively applying eqs. (4) and (5).',\n",
       " 'First, eq. (5) with k = 0 yields the form of A ( ,2) .',\n",
       " 'Then, eq. (4) with k = 0 and the form of A ( ,2) yield the form of A 1 .',\n",
       " 'Next, eq. (5) with k = 1 yields the form of A ( ,3) , and then, eq. (4) with k = 1 and the forms of A ( ,3) , A 1 further yield the form of A 2 .',\n",
       " 'Inductively, one obtains the expressions of all individual parameter matrices.',\n",
       " 'Furthermore, the first condition in eq. FORMULA13 is a consistency condition that guarantees that the analytical form for the entire product of parameter matrices factorizes into the forms of individual parameter matrices.',\n",
       " 'Similarly to shallow linear networks, while the set of critical points here is also uncountable, Theorem 3 suggests ways to obtain some critical points.',\n",
       " 'For example, if we set L k = 0 for all k (i.e., eq. (6) is satisfied), we can obtain the form of critical points for any invertible C k and proper V k with the structure specified in Theorem 3.',\n",
       " 'For nonzero L k , eq. (6) needs to be verified for given C k and V k to determine a critical point.',\n",
       " 'Similarly to shallow linear networks, the parameters {p i (0)} r (0) i=1 ,p(0) determine the value of the loss function at the critical points and further specify the analytical form for the global minimizers, as we present in the following two propositions.',\n",
       " 'DISPLAYFORM5 DISPLAYFORM6 In particular, A ( ,2) can be non-full rank with rank(A ( ,2) ) = DISPLAYFORM7 The analytical form of any global minimizer can be obtained from Theorem 3 with further specification to the above two cases.',\n",
       " 'In particular for case 1, if we further adopt the invertibility assumptions on data matrices as in BID1 and assume that all parameter matrices are square, then all global minima must correspond to full rank parameter matrices.',\n",
       " 'We next exploit the analytical forms of the critical points to further understand the landscape of the loss function L D .',\n",
       " 'It has been shown in BID11 that every local minimum of L D is also a global minimum, under certain conditions on the parameter dimensions and the invertibility of the data matrices.',\n",
       " 'Here, our characterization of the analytical forms for the critical points allow us to understand such a result from an alternative viewpoint.',\n",
       " 'The proofs for certain cases (that we discuss below) are simpler and more intuitive, and no assumption is made on the data matrices and dimensions of the network.',\n",
       " 'Similarly to shallow linear networks, we want to understand the local landscape around the critical points.',\n",
       " 'However, due to the effect of depth, the critical points of L D are more complicated than those of L. Among them, we identify the following subsets of the non-global-minimum critical DISPLAYFORM8 • (Deep-non-optimal order): There exist 0 ≤ k ≤ − 2 such that the matrix V k specified in Theorem 3 satisfies that there exist 1 ≤ i < j ≤ r(k) such that p i (k) < m i (k) and p j (k) > 0.• (Deep-optimal order): (A , A −1 ) is not a global minimizer of L D with A ( −2,1) being fixed, rank(A ) < min{d , d −1 }, and the matrix V −2 specified in Theorem 3 satisfies that DISPLAYFORM9 The following result summarizes the landscape of L D around the above two types of critical points.',\n",
       " 'The loss function L D has the following landscape properties.',\n",
       " 'deep-non-optimal-order critical point (A 1 , . . . , A ) has a perturbation (A 1 , . . .',\n",
       " ', A k+1 , . . .',\n",
       " ', A ) with rank( A ) = rank(A ), which achieves a lower function value.',\n",
       " '2.',\n",
       " 'A deep-optimal-order critical point (A 1 , . . . , A ) has a perturbation (A 1 , . . .',\n",
       " ', A −1 , A ) with rank( A ) = rank(A ) + 1, which achieves a lower function value.',\n",
       " '3.',\n",
       " 'Any point in X D := {(A 1 , . . .',\n",
       " ', A ) : A ( ,1) X = 0} has a perturbation (A 1 , . . .',\n",
       " ', A ) that achieves a higher function value.',\n",
       " 'Consequently, 1) every local minimum of L D is also a global minimum for the above two types of critical points; and 2) every critical point of these two types in X D is a saddle point.',\n",
       " 'Theorem 4 implies that the landscape of L D for deep linear networks is similar to that of L for shallow linear networks, i.e., the pattern of the parameters {p i (k)} r(k) i=1 implies different descent directions of the function value around the critical points.',\n",
       " 'Our approach does not handle the remaining set of non-global minimizers, i.e., there exists q ≤ −1 such that (A , . . .',\n",
       " ', A q ) is a global minimum point of L D with A (q−1,1) being fixed, and A ( ,q) is of optimal order.',\n",
       " 'It is unclear how to perturb the intermediate weight parameters using their analytical forms for deep networks , and we leave this as an open problem for the future work.',\n",
       " 'In this section, we study nonlinear neural networks with one hidden layer.',\n",
       " 'In particular, we consider nonlinear networks with ReLU activation function σ : R → R that is defined as σ(x) := max{x, 0}. Our study focuses on the set of differentiable critical points.',\n",
       " 'The weight parameters between the layers are denoted by A 2 ∈ R d2×d1 , A 1 ∈ R d1×d0 , respectively, and the input and output data are denoted by X ∈ R d0×m , Y ∈ R d2×m , respectively.',\n",
       " 'We are interested in the square loss function which is given by DISPLAYFORM0 where σ acts on A 1 X entrywise.',\n",
       " 'Existing studies on nonlinear networks characterized the sufficient conditions for critical points being global minimum BID9 Since the activation function σ is piecewise linear, the entire parameter space can be partitioned into disjoint cones.',\n",
       " 'In particular, we consider the set of cones K I×J where I ⊂ {1, . . .',\n",
       " ', d 1 }, J ⊂ {1, . . .',\n",
       " ', m} that satisfy DISPLAYFORM1 where \"≥\" and \"<\" represent entrywise comparisons.',\n",
       " 'Within K I×J , the term σ(A 1 X) activates only the entries σ(A 1 X) I:J , and the corresponding loss function L N is equivalent to DISPLAYFORM2 Hence, within K I×J , L N reduces to the loss of a shallow linear network with parameters ((A 2 ) :,I , (A 1 ) I,: ) and input & output data pair (X :,J , Y :,J ).',\n",
       " 'Note that our results on shallow linear networks in Section 2 are applicable to all parameter dimensions and data matrices.',\n",
       " 'Thus, Theorem 1 fully characterizes the forms of critical points of L N in K I×J .',\n",
       " 'Moreover, the existence of such critical points can be analytically examined by substituting their forms into eq. (8).',\n",
       " 'In summary, we obtain the following result, where we denote Σ J := Y :,J X † :,J X :,J Y :,J with the full singular value decomposition U J Λ J U J , and suppose that Σ J has r(J) distinct positive singular values σ 1 (J) > · · · > σ r(J) (J) with multiplicities m 1 , . . .',\n",
       " ', m r(J) , respectively, andm(J) zero singular values.',\n",
       " 'Proposition 6 (Characterization of critical points).',\n",
       " 'All critical points of L N in K I×J for any I ⊂ {1, . . .',\n",
       " ', d 1 }, J ⊂ {1, . . .',\n",
       " ', m} are necessarily and sufficiently characterized by an L 1 ∈ R |I|×d0 , a block matrix V ∈ R d2×|I| and an invertible matrix C ∈ R |I|×|I| such that DISPLAYFORM3 DISPLAYFORM4 ×p consist of orthonormal columns with p i ≤ m i for i = 1, . . .',\n",
       " ', r(J),p ≤m such that DISPLAYFORM5 Moreover, a critical point in K I×J exists if and only if there exists such C, V , L 1 that DISPLAYFORM6 Other entries of A 1 X < 0.To further illustrate, we consider a special case where the nonlinear network has one unit in the hidden layer, i.e., d 1 = 1, in which case A 1 and A 2 are row and column vectors, respectively.',\n",
       " 'Then, the entire parameter space can be partitioned into disjoint cones taking the form of K I×J , and I = {1} is the only nontrivial choice.',\n",
       " 'We obtain the following result from Proposition 6.Proposition 7 (Characterization of critical points).',\n",
       " 'Consider L N with d 1 = 1 and any J ⊂ {1, . . .',\n",
       " ', m}. Then, any nonzero critical point of L N within K {1}×J can be necessarily and sufficiently characterized by an 1 ∈ R 1×d0 , a block unit vector v ∈ R d2×1 and a scalar c ∈ R such that DISPLAYFORM7 Specifically, v is a unit vector that is supported on the entries corresponding to the same singular value of Σ J .',\n",
       " 'Moreover, a nonzero critical point in K {1}×J exists if and only if there exist such c, v, 1 that satisfy DISPLAYFORM8 DISPLAYFORM9 We note that Proposition 7 characterizes both the existence and the forms of critical points of L N over the entire parameter space for nonlinear networks with a single hidden unit.',\n",
       " 'The condition in eq. FORMULA24 is guaranteed because P ker(v) = 0 for v = 0.To further understand Proposition 7, suppose that there exists a critical point in K {1}×J with v being supported on the entries that correspond to the i-th singular value of Σ J .',\n",
       " 'Then, Proposition 1 implies that DISPLAYFORM10 In particular, the critical point achieves the local minimum DISPLAYFORM11 .',\n",
       " 'This is because in this case the critical point is full rank with an optimal order, and hence corresponds to the global minimum of the linear network in eq. (9).',\n",
       " 'Since the singular values of Σ J may vary with the choice of J, L N may achieve different local minima in different cones.',\n",
       " 'Thus, local minimum that is not global minimum can exist for L N .',\n",
       " 'The following proposition concludes this fact by considering a concrete example.',\n",
       " 'Proposition 8.',\n",
       " 'For one-hidden-layer nonlinear neural networks with ReLU activation function, there exists local minimum that is not global minimum, and there also exists local maximum.',\n",
       " 'FORMULA13 and FORMULA19 hold if c −1 (v) 1,: ≥ 0, ( 1 ) 1,: < 0.',\n",
       " 'Similarly to the previous case, choosing c = 1, v = (1, 0) , 1 = (−1, 0) yields a local minimum that achieves the function value L n = 2.',\n",
       " 'Hence, local minimum that is not global minimum does exist.',\n",
       " 'Moreover, in the cone K I×J with I = {1}, J = ∅, the function L N remains to be the constant 5 2 , and all points in this cone are local minimum or local maximum.',\n",
       " 'Thus, the landscape of the loss function of nonlinear networks is very different from that of the loss function of linear networks.',\n",
       " 'In this paper, we provide full characterization of the analytical forms of the critical points for the square loss function of three types of neural networks, namely, shallow linear networks, deep linear networks, and shallow ReLU nonlinear networks.',\n",
       " 'We show that such analytical forms of the critical points have direct implications on the values of the corresponding loss functions, achievement of global minimum, and various landscape properties around these critical points.',\n",
       " 'As a consequence, the loss function for linear networks has no spurious local minimum, while such point does exist for nonlinear networks with ReLU activation.',\n",
       " 'In the future, it is interesting to further explore nonlinear neural networks.',\n",
       " 'In particular, we wish to characterize the analytical form of critical points for deep nonlinear networks and over the full parameter space.',\n",
       " 'Such results will further facilitate the understanding of the landscape properties around these critical points.',\n",
       " 'Notations: For any matrix M , denote vec(M ) as the column vector formed by stacking its columns.',\n",
       " 'Denote the Kronecker product as \"⊗\".',\n",
       " 'Then, the following useful relationships hold for any dimension compatible matrices M , U , V , W : DISPLAYFORM0 DISPLAYFORM1 DISPLAYFORM2 DISPLAYFORM3 Recall that a point DISPLAYFORM4 DISPLAYFORM5 We first prove eqs. (1) and (2) .',\n",
       " 'DISPLAYFORM6 Next, we derive the form of A 2 .',\n",
       " 'Recall the full singular value decomposition Σ = U ΛU , where Λ is a diagonal matrix with distinct singular values σ 1 > . . .',\n",
       " '> σ r > 0 and multiplicities m 1 , . . .',\n",
       " ', m r , respectively.',\n",
       " 'We also assume that there arem number of zero singular values in Λ. Using the fact that P col(A2) = U P col(U A2) U , the last equality in eq. (26) reduces to DISPLAYFORM7 By the multiplicity pattern of the singular values in Λ, P col(U A2) must be block diagonal.',\n",
       " 'Specifically, we can write P col(U A2) = diag( P 1 , . . .',\n",
       " ', P r , P), where P i ∈ R mi×mi and P ∈ Rm ×m .Also, since P col(U A2) is a projection, P 1 , . . . , P r , P must all be projections.',\n",
       " 'Note that P col(U A2) has rank rank(A 2 ), and suppose that P 1 , . . .',\n",
       " ', P r , P have ranks p 1 , . . .',\n",
       " ', p r ,p, respectively.',\n",
       " 'Then, we must have p i ≤ m i for i = 1, . . .',\n",
       " ', r,p ≤m and r i=1 p i +p = rank(A 2 ).',\n",
       " 'Also, note that each projection can be expressed as P i = V i V i with V i ∈ R mi×pi , V ∈ Rm ×p consisting of orthonormal columns.',\n",
       " 'Hence, we can write P col(U A2) = V V where V = diag(V 1 , . . .',\n",
       " ', V r , V ).',\n",
       " 'We then conclude that P col(A2) = U P col(U A2) U = U V V U .',\n",
       " 'Thus, A 2 has the same column space as U V , and there must exist an invertible matrix DISPLAYFORM8 Then, plugging A † 2 = C −1 V U into eq. (25) yields the desired form of A 1 .We now prove eq. (3).',\n",
       " 'Note that the above proof is based on the equations DISPLAYFORM9 Hence, the forms of A 1 , A 2 in eqs. (1) and (2) need to further satisfy ∇ A2 L = 0.',\n",
       " 'By eq. FORMULA19 and the form of A 2 , we obtain that DISPLAYFORM10 This expression, together with the form of A 1 in eq. (1), implies that DISPLAYFORM11 where (i) uses the fact that X † XX = X , (ii) uses the fact that the block pattern of V is compatible with the multiplicity pattern of the singular values in Λ, and hence V V ΛV = ΛV .',\n",
       " 'On the other hand, we also obtain that DISPLAYFORM12 Thus, to satisfy ∇ A2 L = 0 in eq. FORMULA12 , we require that DISPLAYFORM13 which is equivalent to DISPLAYFORM14 Lastly, note that (I − U V (U V ) ) = P col(U V ) ⊥ , and (I − V V ) = P ker(V ) , which concludes the proof.',\n",
       " 'By expansion we obtain that L = DISPLAYFORM0 .',\n",
       " 'Consider any (A 1 , A 2 ) that satisfies eq. FORMULA4 , we have shown that such a point also satisfies eq. (27), which further yields that DISPLAYFORM1 where (i) follows from the fact that Tr( P col(A2) Σ P col(A2) ) = Tr( P col(A2) Σ), and (ii) uses the fact that P col(A2) = U P col(U A2) U .',\n",
       " 'In particular, a critical point (A 1 , A 2 ) satisfies eq. (28).',\n",
       " 'Moreover, using the form of the critical point A 2 = U V C, eq. FORMULA20 further becomes DISPLAYFORM2 where (i) is due to P col(V C) = P col(V ) = V V , and (ii) utilizes the block pattern of V and the multiplicity pattern of Λ that are specified in Theorem 1.',\n",
       " '(1): Consider a critical point (A 1 , A 2 ) with the forms given by Theorem 1.',\n",
       " 'By choosing L 1 = 0, the condition in eq. FORMULA4 is guaranteed.',\n",
       " 'Then, we can specify a critical point with any V that satisfies the block pattern specified in Theorem 1, i.e., we can choose any p i , i = 1, . . .',\n",
       " ', r,p such that p i ≤ m i for i = 1, . . .',\n",
       " ', r,p ≤m and DISPLAYFORM0 m i , the global minimum value is achieved by a full rank A 2 with rank(A 2 ) = min{d 2 , d 1 } and DISPLAYFORM1 That is, the singular values are selected in a decreasing order to minimize the function value.(2): If (A 2 , A 1 ) is a global minimizer and min{d y , d} > r i=1 m i , the global minimum can be achieved by choosing p i = m i for all i = 1, . . .',\n",
       " ', r andp ≥ 0.',\n",
       " 'In particular, we do not need a full rank A 2 to achieve the global minimum.',\n",
       " 'For example, we can choose rank(A 2 ) = r i=1 m i < min{d y , d} with p i = m i for all i = 1, . . .',\n",
       " ', r andp = 0.',\n",
       " 'We first prove item 1.',\n",
       " 'Consider a non-optimal-order critical point (A 1 , A 2 ).',\n",
       " 'By Theorem 1, we can write A 2 = U V C where V = [diag(V 1 , . . .',\n",
       " ', V r , V ), 0] and V i , i = 1, . . .',\n",
       " ', r, V consist of orthonormal columns.',\n",
       " 'Define the orthonormal block diagonal matrix Since (A 1 , A 2 ) is a non-optimal-order critical point, there exists 1 ≤ i < j ≤ r such that p i < m i and p j > 0.',\n",
       " 'Then, consider the following perturbation of U S for some > 0.',\n",
       " 'DISPLAYFORM0 DISPLAYFORM1 with which we further define the perturbation matrix A 2 = M S V C. Also, let the perturbation matrix A 1 be generated by eq. (1) with U ← M and V ← S V .',\n",
       " 'Note that with this construction, ( A 1 , A 2 ) satisfies eq. (25), which further implies eq. (27) for ( A 1 , A 2 ), i.e., A 2 A 1 X = P col( A2) Y X † X. Thus, eq. (28) holds for the point ( A 1 , A 2 ), and we obtain that DISPLAYFORM2 where the last equality uses the fact that S ΛS = Λ, as can be observed from the block pattern of S and the multiplicity pattern of Λ. Also, by the construction of M and the form of S V , a careful calculation shows that only the i, j-th diagonal elements of P col(S U M S V ) have changed, i.e., DISPLAYFORM3 As the index i, j correspond to the singular values σ i , σ j , respectively, and σ i > σ j , one obtain that DISPLAYFORM4 Thus, the construction of the point ( A 2 , A 1 ) achieves a lower function value for any > 0.',\n",
       " 'Letting → 0 and noticing that M is a perturbation of U S, the point ( A 2 , A 1 ) can be in an arbitrary neighborhood of (A 2 , A 1 ).',\n",
       " 'Lastly, note that rank( A 2 ) = rank(A 2 ).',\n",
       " 'This completes the proof of item 1.Next, we prove item 2.',\n",
       " 'Consider an optimal-order critical point (A 1 , A 2 ).',\n",
       " 'Then, A 2 must be non-full rank, since otherwise a full rank A 2 with optimal order corresponds to a global minimizer by Proposition 2.',\n",
       " 'Since there exists some k ≤ r such that 0] .',\n",
       " 'Using this expression, eq. (1) yields that DISPLAYFORM5 DISPLAYFORM6 We now specify our perturbation scheme.',\n",
       " 'Recalling the orthonormal matrix S defined in eq. (29).',\n",
       " 'Then, we consider the following matrices for some 1 , 2 > 0 DISPLAYFORM7 For this purpose, we need to utilize the condition of critical points in eq. (3), which can be equivalently expressed as DISPLAYFORM8 (ii) ⇔ (CL 1 ) (rank(A2)+1):d1,: XY (I − U S :,1:(q−1) (U S :,1:(q−1) ) ) = 0where (i) follows by taking the transpose and then simplifying, and (ii) uses the fact that V = SS V = S :,1:(q−1) in the case of optimal-order critical point.',\n",
       " 'Calculating the function value at ( A 1 , A 2 ), we obtain that DISPLAYFORM9 .',\n",
       " 'We next simplify the above three trace terms using eq. (31).',\n",
       " 'For the first trace term, observe that DISPLAYFORM10 2 Tr(S :,q ΛS :,q ) where (i) follows from eq. (31) as S :,q is orthogonal to the columns of S :,1:(q−1) .',\n",
       " 'For the second trace term, we obtain that DISPLAYFORM11 = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ) + 2Tr( 1 2 U S :,q S :,q ΛSS V diag (U V diag ) ) (i) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ) + 2Tr( 1 2 σ k U S :,q e q S V diag (U V diag ) )(ii) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ), where (i) follows from S :,q ΛS = σ k e q , and (ii) follows from e q S V diag = 0.',\n",
       " 'For the third trace term, we obtain that 2Tr(P Y ) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY ) + 2Tr( 1 2 U S :,q (U S :,q ) Σ) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY ) + 2Tr( 1 2 S :,q ΛS :,q ).Combining the expressions for the three trace terms above, we conclude that Consider a critical point (A 1 , . . .',\n",
       " ', A ) so that eq. FORMULA4',\n",
       " 'Observe that the product matrix A ( ,2) is equivalent to the class of matrices B 2 ∈ R min{d ,...,d2}×d1 .Consider a critical point (B 2 , A 1 ) of the shallow linear network L :=',\n",
       " 'The proof is similar to that for shallow linear networks.',\n",
       " 'Consider a deep-non-optimal-order critical point (A 1 , . . .',\n",
       " ', A ), and define the orthonormal block matrix S k using the blocks of V k in a similar way as eq. (29).',\n",
       " 'Then, A (l,k+2) takes the form A (l,k+2) = U k S k S k V k C k .',\n",
       " 'Since A (l,k+2) is of non-optimal order, there exists i < j < r(k) such that p i (k) < m i (k) and p j (k) > 0.',\n",
       " 'Thus, we perturb the j-th column of U k S k to be , and denote the resulting matrix as M k .Then, we perturb A to be A = M k (U k S k ) A so that A A ( −1,k+2) = M k S k V k C k .',\n",
       " 'Moreover, we generate A k+1 by eq. (4) with U k ← M k , V k ← S k V k .',\n",
       " 'Note that such construction satisfies eq. (32), and hence also satisfies eq. (34), which further yields that DISPLAYFORM0 With the above equation, the function value at this perturbed point is evaluated as DISPLAYFORM1 Then, a careful calculation shows that only the i, j-th diagonal elements of DISPLAYFORM2 have changed, and are Now consider a deep-optimal-order critical point (A 1 , . . .',\n",
       " ', A ).',\n",
       " 'Note that with A ( −2,1) fixed to be a constant, the deep linear network reduces to a shallow linear network with parameters (A , A −1 ).',\n",
       " 'Since (A , A −1 ) is not a non-global minimum critical point of this shallow linear network and A is of optimal-order, we can apply the perturbation scheme in the proof of Proposition 3 to identify a perturbation ( A , A −1 ) with rank( A ) = rank(A ) + 1 that achieves a lower function value.',\n",
       " 'Consider any point in X D .',\n",
       " 'Since A ( ,1) X = 0, we can scale the nonzero row, say, the i-th row (A ) i,: A ( −1,1) X properly in the same way as that in the proof of Proposition 3 to increase the function value.',\n",
       " 'Lastly, item 1 and item 2 imply that every local minimum is a global minimum for these two types of critical points.',\n",
       " 'Moreover, combining items 1,2 and 3, we conclude that every critical point of these two types in X D is a saddle point.',\n",
       " 'The backpropagation (BP) algorithm is often thought to be biologically implausible in the brain.',\n",
       " 'One of the main reasons is that BP requires symmetric weight matrices in the feedforward and feedback pathways.',\n",
       " 'To address this “weight transport problem” (Grossberg, 1987), two biologically-plausible algorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax BP’s weight symmetry requirements and demonstrate comparable learning capabilities to that of BP on small datasets.',\n",
       " 'However, a recent study by Bartunov et al. (2018) finds that although feedback alignment (FA) and some variants of target-propagation (TP) perform well on MNIST and CIFAR, they perform significantly worse than BP on ImageNet.',\n",
       " 'Here, we additionally evaluate the sign-symmetry (SS) algorithm (Liao et al., 2016), which differs from both BP and FA in that the feedback and feedforward weights do not share magnitudes but share signs.',\n",
       " 'We examined the performance of sign-symmetry and feedback alignment on ImageNet and MS COCO datasets using different network architectures (ResNet-18 and AlexNet for ImageNet; RetinaNet for MS COCO).',\n",
       " 'Surprisingly, networks trained with sign-symmetry can attain classification performance approaching that of BP-trained networks.',\n",
       " 'These results complement the study by Bartunov et al. (2018) and establish a new benchmark for future biologically-plausible learning algorithms on more difficult datasets and more complex architectures.',\n",
       " 'Deep learning models today are highly successful in task performance, learning useful representations, and even matching representations in the brain BID26 BID24 .',\n",
       " 'However, it remains a contentious issue whether these models reflect how the brain learns.',\n",
       " \"Core to the problem is the fact that backpropagation, the learning algorithm underlying most of today's deep networks, is difficult to implement in the brain given what we know about the brain's hardware BID2 however, see Hinton 2007) .\",\n",
       " 'One main reason why backpropagation seems implausible in the brain is that it requires sharing of feedforward and feedback weights.',\n",
       " 'Since synapses are unidirectional in the brain, feedforward and feedback connections are physically distinct.',\n",
       " 'Requiring them to shared their weights, even as weights are adjusted during learning, seems highly implausible.',\n",
       " 'One approach to addressing this issue is to relax the requirement for weight-symmetry in error backpropagation.',\n",
       " 'Surprisingly, when the feedback weights share only the sign but not the magnitude of the feedforward weights BID16 or even when the feedback weights are random (but fixed) BID17 , they can still guide useful learning in the network, with performance comparable to and sometimes even better than performance of backpropagation, on datasets such as MNIST and CIFAR.',\n",
       " 'Here, we refer to these two algorithms, respectively, as \"sign-symmetry\" and \"feedback alignment.\"',\n",
       " 'Since weight symmetry in backpropagation is required for accurately propagating the derivative of the loss function through layers, the success of asymmetric feedback algorithms indicates that learning can be supported even by inaccurate estimation of the error derivative.',\n",
       " 'In feedback alignment, the authors propose that the feedforward weights learn to align with the random feedback weights, thereby allowing feedback to provide approximate yet useful learning signals BID17 .However, a recent paper by BID0 finds that feedback alignment and a few other biologically-plausible algorithms, including variants of target propagation, do not generalize to larger and more difficult problems such as ImageNet BID4 ) and perform much worse than backpropagation.',\n",
       " 'Nevertheless, the specific conditions Bartunov et al. tested are somewhat restrictive.',\n",
       " 'They only tested locally-connected networks (i.e., weight sharing is not allowed among convolution filters at different spatial locations), a choice that is motivated by biological plausibility but in practice limits the size of the network (without weight sharing, each convolutional layer needs much more memory to store its weights), making it unclear whether poor performance was attributable solely to the algorithm, or to the algorithm on those architectures.1 Second, Bartunov et al. did not test sign-symmetry, which may be more powerful than feedback alignment since signsymmetric feedback weights may carry more information about the feedforward weights than the random feedback weights used in feedback alignment.',\n",
       " 'In this work, we re-examine the performance of sign-symmetry and feedback alignment on ImageNet and MS COCO datasets using standard ConvNet architectures (i.e., ResNet-18, AlexNet, and RetinaNet).',\n",
       " 'We find that sign-symmetry can in fact train networks on both tasks, achieving similar performance to backpropagation on ImageNet and reasonable performance on MS COCO.',\n",
       " 'In addition, we test the use of backpropagation exclusively in the last layer while otherwise using feedback alignment, hypothesizing that in the brain, the classifier layer may not be a fully-connected layer and may deliver the error signal through some other unspecified mechanism.',\n",
       " 'Such partial feedback alignment can achieve better performance (relative to backpropagation) than in BID0 .',\n",
       " 'Taken together, these results extend previous findings and indicate that existing biologicallyplausible learning algorithms remain viable options both for training artificial neural networks and for modeling how learning can occur in the brain.',\n",
       " 'Consider a layer in a feedforward neural network.',\n",
       " 'Let x i denote the input to the i th neuron in the layer and y j the output of the j th neuron.',\n",
       " 'Let W denote the feedforward weight matrix and W ij the connection between input x i and output y j .',\n",
       " 'Let f denote the activation function.',\n",
       " 'Then, Equation 1 describes the computation in the feedforward step.',\n",
       " 'Now, let B denote the feedback weight matrix and B ij the feedback connection between output y j and input x i , and let f denote the derivative of the activation function f .',\n",
       " 'Given the objective function E, the error gradient ∂E ∂xi calculated in the feedback step is described by Equation 2.',\n",
       " 'DISPLAYFORM0 DISPLAYFORM1 Standard backpropagation requires B = W .',\n",
       " 'Sign-symmetry BID16 relaxes the above symmetry requirement by letting B = sign(W ), where sign(·) is the (elementwise) sign function.',\n",
       " \"Feedback alignment BID17 uses a fixed random matrix as the feedback weight matrix B. Lillicrap et al. showed that through training, W is adjusted such that on average, e T W Be > 0, where e is the error in the network's output.\",\n",
       " 'This condition implies that the error correction signal Be lies within 90• of e T W , the error calculated by standard backpropagation.',\n",
       " 'We implement both algorithms in PyTorch for convolutional and fully-connected layers and post the code at https://github.com/willwx/sign-symmetry.',\n",
       " 'We trained ResNet-18 BID6 on ImageNet using 5 different training settings: 1) backpropagation; 2) sign-symmetry for convolutional layers and backpropagation for the last, fully-connected layer; 3) sign-symmetry for all (convolutional and fully-connected) layers; 4) feedback alignment for convolutional layers and backpropagation for the fully-connected layer; and 5) feedback alignment for all (convolutional and fully-connected) layers.',\n",
       " 'In sign-symmetry, at each backward step, feedback weights were taken as the signs of the feedforward weights, scaled by the same scale λ used to initialize that layer.',\n",
       " '2 In feedback alignment, feedback weights were initialized once at the beginning as random variables from the same distribution used to initialize that layer.',\n",
       " 'For backpropagation, standard training parameters were used (SGD with learning rate 0.1, momentum 0.9, and weight decay 10 −4 ).',\n",
       " 'For ResNet-18 with other learning algorithms, we used SGD with learning rate 0.05 3 , while momentum and weight decay remain unchanged.',\n",
       " 'For AlexNet with all learning algorithms, standard training parameters were used (SGD with learning rate 0.01, momentum 0.9, and weight decay 5 × 10 −4 ).',\n",
       " 'We used a version of AlexNet BID13 , as used in torchvision) which we slightly modified to add batch normalization BID9 before every nonlinearity and consequently removed dropout.',\n",
       " 'For all experiments, we used a batch size of 256, a learning rate decay of 10-fold every 10 epochs, and trained for 50 epochs.',\n",
       " 'BID12 .',\n",
       " 'Sign-symmetry performed nearly as well as backpropagation, while feedback alignment performed better than previously reported when backpropagation was used to train the last layer.',\n",
       " 'In all cases, the network was able to learn ( FIG0 , TAB0 ).',\n",
       " 'Remarkably, sign-symmetry only slightly underperformed backpropagation in this benchmark large dataset, despite the fact that signsymmetry does not accurately propagate either the magnitude or the sign of the error gradient.',\n",
       " 'Hence, this result is not predicted by the performance of signSGD BID1 , where weight updates use the sign of the gradients, but gradients are still calculate accurately; or XNORNet BID22 , where both feedforward and feedback weights are binary but symmetrical, so error backpropagation is still accurate.',\n",
       " 'An intuitive explanation for this performance is that the skip-connections in ResNet help prevent the degradation of the gradient being passed through many layers of sign-symmetric feedback.',\n",
       " 'However, sign-symmetry also performed similarly well to backpropagation in a (modified) AlexNet architecture, which did not contain skip connections.',\n",
       " 'Therefore, skip-connections alone do not explain the performance of sign-symmetry.',\n",
       " 'In addition, although its performance was considerably worse, feedback alignment was still able to guide better learning in the network than reported by BID0 Figure 3 ) if we use backpropagation in the last layer.',\n",
       " 'This condition is not unreasonable since, in the brain, the classifier layer is likely not a soft-max classifier and may deliver error signals by a different mechanism.',\n",
       " 'We also tested using backpropagation exclusively for the last layer in a network otherwise trained with sign-symmetry, but the effect on the performance was minimal.',\n",
       " 'One possibility why sign-symmetry performed better than feedback alignment is that in sign-symmetry, the feedback weight always tracks the sign of the feedforward weight, which may reduce the burden on the feedforward weight to learn to align with the feedback weight.',\n",
       " 'Finally, in BID16 , Batch-Manhattan (BM) SGD was proposed as a way to stabilize training with asymmetric feedback algorithms.',\n",
       " 'In our experience, standard SGD consistently worked better than BM for sign-symmetry, but BM may improve results for feedback alignment.',\n",
       " 'We have not comprehensively characterized the effects of BM since many factors like learning rate can affect the outcome.',\n",
       " 'Future experiments are needed to draw stronger conclusions.',\n",
       " 'Besides the ImageNet classification task, we examined the performance of sign-symmetry on the MS COCO object detection task.',\n",
       " 'Object detection is more complex than classification and might therefore require more complicated network architecture in order to achieve high accuracy.',\n",
       " 'Thus, in this experiment we assessed the effectiveness of sign-symmetry in training networks that were more complicated and difficult to optimize.',\n",
       " 'We trained the state-of-the-art object detection network RetinaNet proposed by BID18 on the COCO trainval35k split, which consists of 80k images from train and 35k random images from the 40k-image val set.',\n",
       " 'RetinaNet comprises a ResNet-FPN backbone, a classification subnet, and a bounding box regressing subnet.',\n",
       " 'The network was trained with three different training settings: 1) backpropagation for all layers; 2) backpropagation for the last layer in both subnets and sign-symmetry for rest of the layers; 3) backpropagation for the last layer in both subnets and feedback alignment for rest of the layers.',\n",
       " 'We used a backbone ResNet-18 pretrained on ImageNet to initialize the network.',\n",
       " 'In all the experiments, the network was trained with SGD with an initial learning rate of 0.01, momentum of 0.9, and weight decay of 0.0001.',\n",
       " 'We trained the network for 40k iterations with 8 images in each minibatch.',\n",
       " 'The learning rate was divided by 10 at iteration 20k.',\n",
       " 'The results on COCO are similar to those on ImageNet, although the performance gap between SS and BP on COCO is slightly more prominent FIG1 .',\n",
       " 'A number of factors could have potentially contributed to this result.',\n",
       " 'We followed the Feature Pyramid Network (FPN) architecture design choices, optimizers, and hyperparameters reported by BID18 ; these choices are all optimized for use with backpropagation instead of sign-symmetry.',\n",
       " 'Hence, the results here represent a lowerbound on the performance of sign-symmetry for training networks on the COCO dataset.',\n",
       " 'We ran a number of analyses to understand how sign-symmetry guides learning.',\n",
       " 'BID17 show that with feedback alignment, the alignment angles between feedforward and feedback weights gradually decrease because the feedforward weights learn to align with the feedback weights.',\n",
       " 'We asked whether the same happens in sign-symmetry by computing alignment angles as in BID17 :',\n",
       " 'For every pair of feedforward and feedback weight matrices, we flattened the matrices into vectors and computed the angle between the vectors.',\n",
       " 'Interestingly, we found that during training, the alignment angles decreased for the last 3 layers but increased for the other layers ( Figure 3a) .',\n",
       " 'In comparison, in the backpropagation-trained network (where sign(W ) was not used in any way), the analogous alignment angle between W and sign(W ) increased for all layers.',\n",
       " 'One possible explanation for the increasing trend is that as the training progresses, the feedforward weights tend to become sparse.',\n",
       " 'Geometrically, this means that feedforward vectors become more aligned to the standard basis vectors and less aligned with the feedback weight vectors, which always lie on a diagonal by construction.',\n",
       " 'This explanation is consistent with the similarly increasing trend of the average kurtosis of the feedforward weights (Figure 3b ), which indicates that values of the weights became more dispersed during training.',\n",
       " 'Since the magnitudes of the feedforward weights were discarded when calculating the error gradients, we also looked at how sign-symmetry affected the size of the trained weights.',\n",
       " 'Sign-symmetry and backpropagation resulted in weights with similar magnitudes (Figure 3c ).',\n",
       " 'More work is needed to elucidate how sign-symmetry guides efficient learning in the network.',\n",
       " 'Our results indicate that biologically-plausible learning algorithms, specifically sign-symmetry and feedback alignment, are able to learn on ImageNet.',\n",
       " 'This finding seemingly conflicts with the findings by BID0 .',\n",
       " 'Why do we come to such different conclusions?First, Bartunov et al. did not test sign-symmetry, which is expected to be more powerful than feedback alignment, because it is a special case of feedback alignment that allows feedback weights to have additional information about feedforward weights.',\n",
       " 'Indeed, on ImageNet, the performance of sign-symmetry approached that of backpropagation and exceeded the performance of feedback alignment by a wide margin.',\n",
       " 'Another reason may be that instead of using standard ConvNets on ImageNet, Bartunov et al. only tested locally-connected networks.',\n",
       " 'While the later is a more biologically plausible architecture, in practice, it is limited in size by the need to store separate weights Figure 3 : a, During training with sign-symmetry, alignment angles between feedforward weights W and feedback weights sign(W ) decreased in the last 3 layers but increased in early layers, whereas during training with backpropagation, the analogous alignment angles increased for all layers and were overall larger.',\n",
       " 'b, Kurtosis of the feedforward weight matrices increased during training.',\n",
       " 'c, The magnitudes of weights trained by sign-symmetry were similar to those trained by backpropagation.',\n",
       " 'Line and shading, mean ± std for epoch 50.for each spatial location.',\n",
       " 'This reduced model capacity creates a bottleneck that may affect the performance of feedback alignment (see Lillicrap et al., 2016, Supplementary Note 9) .',\n",
       " 'Finally, the performance of feedback alignment also benefited from the use of backpropagation in the last layer in our conditions.',\n",
       " 'A major reason why backpropagation is considered implausible in the brain is that it requires exact symmetry of physically distinct feedforward and feedback pathways.',\n",
       " 'Sign-symmetry and feedback alignment address this problem by relaxing this tight coupling of weights between separate pathways.',\n",
       " 'Feedback alignment requires no relation at all between feedforward and feedback weights and simply depends on learning to align the two.',\n",
       " 'Hence, it can be easily realized in the brain (for example, see Lillicrap et al., 2016, Supplementary Figure 3) .',\n",
       " 'However, empirically, we and others have found its performance to be not ideal on relatively challenging problems.',\n",
       " 'Sign-symmetry, on the other hand, introduces a mild constraint that feedforward and feedback connections be \"antiparallel\": They need to have opposite directions but consistent signs.',\n",
       " 'This can be achieved in the brain with two additional yet plausible conditions: First, the feedforward and feedback pathways must be specifically wired in this antiparallel way.',\n",
       " 'This can be achieved by using chemical signals to guide specific targeting of axons, similar to how known mechanisms for specific wiring operate in the brain BID20 BID8 .',\n",
       " 'One example scheme of how this can be achieved is shown in Figure 4 .',\n",
       " 'While the picture in Figure 4a is complex, most of the complexity comes from the fact that units in a ConvNet produce inconsistent outputs (i.e., both positive and negative).',\n",
       " 'If the units are consistent (i.e., producing exclusively positive or negative outputs), the picture simplifies to Figure 4b .',\n",
       " 'Neurons in the brain are observed to be consistent, as stated by the so-called \"Dale\\'s Law\" BID3 BID25 .',\n",
       " 'Hence, this constraint would have to be incorporated at some point in any biologically plausible network, and remains an important direction for future work.',\n",
       " 'We want to remark that Figure 4 is meant to indicate the relative ease of wiring sign-symmetry in the brain (compared to, e.g., wiring a network capable of weight transport), not that the brain is known to be wired this way.',\n",
       " 'Nevertheless, it represents a hypothesis that is falsifiable by experimental data, potentially in the near future.',\n",
       " 'Related, a second desideratum is that weights should not change sign during training.',\n",
       " 'While our current setting for sign-symmetry removes weight magnitude transport, it still implicitly relies on \"sign transport.\"',\n",
       " 'However, in the brain, the sign of a connection weight depends on the type of the 4 A paper from last year examined connectivity patterns within tissue sizes of approx.',\n",
       " '500 microns and axon lengths of approx.',\n",
       " '250 microns BID23 ; recent progress (fueled by deep learning) can trace axons longer than 1 mm , although the imaging of large brain volumes is still limiting.',\n",
       " 'In comparison, in mice, adjacent visual areas (corresponding to stages of visual processing) are 0.5-several mms apart BID19 , while in primates it is tens of millimeters.',\n",
       " 'Thus, testing the reality of sign-symmetric wiring is not quite possible today but potentially soon to be.',\n",
       " 'presynaptic neuron-e.g., glutamatergic (excitatory) or GABAergic (inhibitory)-a quality that is intrinsic to and stable for each neuron given existing evidence.',\n",
       " 'Hence, if sign-symmetry is satisfied initially-for example, through specific wiring as just described-it will be satisfied throughout learning, and \"sign transport\" will not be required.',\n",
       " 'Thus, evaluating the capacity of sign-fixed networks to learn is another direction for future work.',\n",
       " 'Figure 4: The specific wiring required for sign-symmetric feedback can be achieved using axonal guidance by specific receptor-ligand recognition.',\n",
       " 'Assume that an axon carrying ligand L X will only synapse onto a downstream neuron carrying the corresponding receptor R X .',\n",
       " 'By expressing receptors and ligands in an appropriate pattern, an antiparallel wiring pattern can be established that supports sign-symmetric feedback.',\n",
       " 'a, An example scheme.',\n",
       " 'In this scheme, one inconsistent unit (i.e., a unit that produce both positive and negative outputs) in the network is implemented by three consistent biological neurons, so that each synapse is exclusively positive or negative.',\n",
       " 'n input neurons orthogonal ligand-receptor pairs is sufficient to implement all possible connection patterns.',\n",
       " 'b, An example scheme for implementing a signsymmetric network with consistent units.',\n",
       " 'Only 2 orthogonal ligand-receptor pairs are needed to implement all possible connectivities in this case.',\n",
       " 'These schemes represent falsifiable hypotheses, although they do not exclude other possible implementations.',\n",
       " 'Another element of unclear biological reality, common to feedback alignment and sign-symmetry, is that the update of a synaptic connection (i.e., weight) between two feedforward neurons (A to B) depends on the activity in a third, feedback neuron C, whose activation represents the error of neuron B. One way it can be implemented biologically is for neuron C to connect to B with a constant and fixed weight.',\n",
       " \"When C changes its value due to error feedback, it will directly induce a change of B's electric potential and thus of the postsynaptic potential of the synapse between A and B, which might lead to either Long-term Potentiation (LTP) or Long-term Depression (LTD) of synapse A-B.Biological plausibility of ResNet has been previously discussed by BID14 , claiming that ResNet corresponds to an unrolled recurrent network in the visual cortex.\",\n",
       " 'However, it is unclear yet how backpropagation through time can be implemented in the brain.',\n",
       " 'Biological plausibility of batch normalization has been discussed in BID15 , where they addressed the issues with online learning (i.e., one sample at a time, instead of minibatch), recurrent architecture and consistent training and testing normalization statistics.',\n",
       " 'Other biological constraints include removing weight-sharing in convolutional layers as in BID0 , incorporating temporal dynamics as in BID17 , using realistic spiking neurons, addressing the sample inefficiency general to deep learning, etc.',\n",
       " 'We believe that these are important yet independent issues to the problem of weight transport and that by removing the latter, we have taken a meaningful step toward biological plausibility.',\n",
       " 'Nevertheless, many steps remain in the quest for a truly plausible, effective, and empirically-verified model of learning in the brain.',\n",
       " 'Recent work shows that biologically-plausible learning algorithms do not scale to challenging problems such as ImageNet.',\n",
       " 'We evaluated sign-symmetry and re-evaluated feedback alignment on their effectiveness training ResNet and AlexNet on ImageNet and RetinaNet on MS COCO.',\n",
       " 'We find that 1) sign-symmetry performed nearly as well as backpropagation on ImageNet, 2) slightly modified feedback alignment performed better than previously reported, and 3) both algorithms had reasonable performance on MS COCO with minimal hyperparameter tuning.',\n",
       " 'Taken together, these results indicate that biologically-plausible learning algorithms, in particular sign-symmetry, remain promising options for training artificial neural networks and modeling learning in the brain.',\n",
       " 'We introduce the 2-simplicial Transformer, an extension of the Transformer which includes a form of higher-dimensional attention generalising the dot-product attention, and uses this attention to update entity representations with tensor products of value vectors.',\n",
       " 'We show that this architecture is a useful inductive bias for logical reasoning in the context of deep reinforcement learning.\\n',\n",
       " 'Deep learning contains many differentiable algorithms for computing with learned representations.',\n",
       " 'These representations form vector spaces, sometimes equipped with additional structure.',\n",
       " 'A recent example is the Transformer (Vaswani et al., 2017) in which there is a vector space V of value vectors and an inner product space H of query and key vectors.',\n",
       " 'This structure supports a kind of messagepassing, where a value vector v j ∈ V derived from entity j is propagated to update an entity i with weight q i · k j , where q i ∈ H is a query vector derived from entity i, k j ∈ H is a key vector derived from entity j, and the inner product on H is written as a dot product.',\n",
       " 'The Transformer therefore represents a relational inductive bias, where a relation from entity j to entity i is perceived to the extent that q i · k j is large and positive.',\n",
       " 'However, the real world has structure beyond entities and their direct relationships: for example, the three blocks in Figure 1 are arranged in such a way that if either of the supporting blocks is removed, the top block will fall.',\n",
       " 'This is a simple 3-way relationship between entities i, j, k that is complex to represent as a system of 2-way relationships.',\n",
       " 'It is natural to make the hypothesis that such higher-order relationships are essential to extracting the full predictive power of data, across many domains.',\n",
       " 'In accordance with this hypothesis, we introduce a generalisation of the Transformer architecture, the 2-simplicial Transformer, which incorporates both 2-and 3-way interactions.',\n",
       " 'Mathematically, the key observation is that higher-order interactions between entities can be understood using algebras.',\n",
       " \"This is nothing but Boole's insight (Boole, 1847) which set in motion the development of modern logic.\",\n",
       " 'In our situation, an appropriate algebra is the Clifford algebra Cl(H) of the space H of queries and keys, which contains that space H ⊆ Cl(H) and in which queries and keys can be multiplied.',\n",
       " 'To represent a 3-way interaction we map each entity i to a triple (p i , l k ) using a natural continuous function η : Cl(H) −→ R associated to the Z-grading of Cl(H).',\n",
       " 'This scalar measures how strongly the network perceives a 3-way interaction involving i, j, k. In summary, the 2-simplicial Transformer learns how to represent entities in its environment as vectors v ∈ V , and how to transform those entities to queries and (pairs of) keys in H, so that the signals provided by the scalars q i · k j and η(p i l 1 j l 2 k ) are informative about higher-order structure in the environment.',\n",
       " 'As a toy example of higher-order structure, we consider the reinforcement learning problem in a variant of the BoxWorld environment from (Zambaldi et al., 2019) .',\n",
       " 'The original BoxWorld is played on a rectangular grid populated by keys and locked boxes of varying colours, with the goal being to open the box containing the \"Gem\".',\n",
       " 'In our variant of the BoxWorld environment, bridge BoxWorld, the agent must use two keys simultaneously to obtain the Gem; this structure in the environment creates many 3-way relationships between entities, including for example the relationship between the locked boxes j, k providing the two keys and the Gem entity i.',\n",
       " 'This structure in the environment is fundamentally logical in nature, and encodes a particular kind of conjunction; see Appendix I.',\n",
       " 'The architecture of our deep reinforcement learning agent largely follows (Zambaldi et al., 2019) and the details are given in Section 4.',\n",
       " 'The key difference between our simplicial agent and the relational agent of (Zambaldi et al., 2019) is that in place of a standard Transformer block we use a 2-simplicial Transformer block.',\n",
       " 'Our experiments show that the simplicial agent confers an advantage over the relational agent as an inductive bias in our reasoning task.',\n",
       " 'Motivation from neuroscience for a simplicial inductive bias for abstract reasoning is contained in Appendix J.',\n",
       " 'Our use of tensor products of value vectors is inspired by the semantics of linear logic in vector spaces (Girard, 1987; Mellis, 2009; Clift & Murfet, 2017; Wallbridge, 2018) in which an algorithm with multiple inputs computes on the tensor product of those inputs, but this is an old idea in natural language processing, used in models including the second-order RNN (Giles et al., 1989; Pollack, 1991; Goudreau et al., 1994; Giles et al., 1991) , multiplicative RNN (Sutskever et al., 2011; Irsoy & Cardie, 2015) , Neural Tensor Network (Socher et al., 2013 ) and the factored 3-way Restricted Boltzmann Machine (Ranzato et al., 2010) , see Appendix A. Tensors have been used to model predicates in a number of neural network architectures aimed at logical reasoning (Serafini & Garcez, 2016; Dong et al., 2019) .',\n",
       " 'The main novelty in our model lies in the introduction of the 2-simplicial attention, which allows these ideas to be incorporated into the Transformer architecture.',\n",
       " 'In this section we first review the definition of the ordinary Transformer block and then explain the 2-simplicial Transformer block.',\n",
       " 'We distinguish between the Transformer architecture which contains a word embedding layer, an encoder and a decoder (Vaswani et al., 2017) , and the Transformer block which is the sub-model of the encoder that is repeated.',\n",
       " 'The fundamental idea, of propagating information between nodes using weights that depend on the dot product of vectors associated to those nodes, comes ultimately from statistical mechanics via the Hopfield network (Appendix B).',\n",
       " 'The ordinary and 2-simplicial Transformer blocks define operators on sequences e 1 , . . .',\n",
       " ', e N of entity representations.',\n",
       " 'Strictly speaking the entities are indices 1 ≤ i ≤ N but we sometimes identify the entity i with its representation e i .',\n",
       " 'The space of entity representations is denoted V , while the space of query, key and value vectors is denoted H. We use only the vector space structure on V , but H = R d is an inner product space with the usual dot product pairing (h, h ) → h · h and in defining the 2-simplicial Transformer block we will use additional algebraic structure on H, including the \"multiplication\" tensor B : H ⊗ H −→ H of (10) (used to propagate tensor products of value vectors) and the Clifford algebra of H (used to define the 2-simplicial attention).',\n",
       " 'In the first step of the standard Transformer block we generate from each entity e i a tuple of vectors via a learned linear transformation E : V −→ H ⊕3 .',\n",
       " 'These vectors are referred to respectively as query, key and value vectors and we write',\n",
       " 'Stated differently,',\n",
       " 'In the second step we compute a refined value vector for each entity',\n",
       " 'Finally, the new entity representation e i is computed by the application of a feedforward network g θ , layer normalisation and a skip connection',\n",
       " 'Remark 2.1.',\n",
       " 'In the introduction we referred to the idea that a Transformer model learns representations of relations.',\n",
       " 'To be more precise, these representations are heads, each of which determines an independent set of transformations W Q , W K , W V which extract queries, keys and values from entities.',\n",
       " 'Thus a head determines not only which entities are related (via W Q , W K ) but also what information to transmit between them (via W V ).',\n",
       " 'In multiple-head attention with K heads, there are K channels along which to propagate information between every pair of entities, each of dimension dim(H)/K. More precisely, we choose a decomposition H = H 1 ⊕ · · · ⊕ H K so that',\n",
       " 'and write',\n",
       " 'To compute the output of the attention, we take a direct sum of the value vectors propagated along every one of these K channels, as in the formula',\n",
       " 'In combinatorial topology the canonical one-dimensional object is the 1-simplex (or edge) j −→ i.',\n",
       " 'Since the standard Transformer model learns representations of relations, we refer to this form of attention as 1-simplicial attention.',\n",
       " 'The canonical two-dimensional object is the 2-simplex (or triangle) which we may represent diagrammatically in terms of indices i, j, k as',\n",
       " 'In the 2-simplicial Transformer block, in addition to the 1-simplicial contribution, each entity e i is updated as a function of pairs of entities e j , e k using the tensor product of value vectors u j ⊗ u k and a probability distribution derived from a scalar triple product p i , l 1 j , l 2 k in place of the scalar product q i · k j .',\n",
       " 'This means that we associate to each entity e i a four-tuple of vectors via a learned linear transformation E : V −→ H ⊕4 , denoted',\n",
       " 'We still refer to p i as the query, l 1 i , l 2 i as the keys and u i as the value.',\n",
       " 'Stated differently,',\n",
       " 'whose square is a polynomial in the pairwise dot products',\n",
       " 'This scalar triple product has a simple geometric interpretation in terms of the volume of the tetrahedron with vertices 0, a, b, c. To explain, recall that the triangle spanned by two unit vectors a, b in R 2 has an area A which can be written in terms of the dot product of a and b. In three dimensions, the analogous formula involves the volume V of the tetrahedron with vertices given by unit vectors a, b, c, and the scalar triple product as shown in Figure 2 .',\n",
       " 'In general, given nonzero vectors a, b, c letâ,b,ĉ denote unit vectors in the same directions.',\n",
       " 'Then we can by Lemma C.10(v) factor out the length in the scalar triple product',\n",
       " 'Figure 2: The geometry of 1-and 2-simplicial attention.',\n",
       " 'Left: the dot product in terms of the area A in R 2 .',\n",
       " 'Right: the triple product in terms of the volume V in R 3 .',\n",
       " 'so that a general scalar triple product can be understood in terms of the vector norms and configurations of three points on the 2-sphere.',\n",
       " 'One standard approach to calculating volumes of such tetrahedrons is the cross product which is only defined in three dimensions.',\n",
       " 'Since the space of representations H is high dimensional the natural framework for the triple scalar product a, b, c is instead the Clifford algebra of H (see Appendix C).',\n",
       " 'For present purposes, we need to know that a, b, c attains its minimum value (which is zero) when a, b, c are pairwise orthogonal, and attains its maximum value (which is a b c ) if and only if {a, b, c} is linearly dependent (Lemma C.10).',\n",
       " 'Using the number p i , l',\n",
       " 'k as a measure of the degree to which entity i is attending to (j, k), or put differently, the degree to which the network predicts the existence of a 2-simplex (i, j, k), the update rule for the entities when using purely 2-simplicial attention is',\n",
       " 'where B : H ⊗ H −→ H is a learned linear transformation.',\n",
       " 'Although we do not impose any further constraints, the motivation here is to equip H with the structure of an algebra; in this respect we model conjunction by multiplication, an idea going back to Boole (Boole, 1847) .',\n",
       " 'We compute multiple-head 2-simplicial attention in the same way as in the 1-simplicial case.',\n",
       " 'To combine 1-simplicial heads (that is, ordinary Transformer heads) and 2-simplicial heads we use separate inner product spaces H 1 , H 2 for each simplicial dimension, so that there are learned linear transformations',\n",
       " '⊕4 and the queries, keys and values are extracted from an entity e i according to',\n",
       " 'The update rule (for a single head in each simplicial dimension) is then:',\n",
       " 'If there are K 1 heads of 1-simplicial attention and K 2 heads of 2-simplicial attention, then (11) is modified in the obvious way using',\n",
       " 'Without the additional layer normalisation on the output of the 2-simplicial attention we find that training is unstable.',\n",
       " 'The natural explanation is that these outputs are constructed from polynomials of higher degree than the 1-simplicial attention, and thus computational paths that go through the 2-simplicial attention will be more vulnerable to exploding or vanishing gradients.',\n",
       " 'The time complexity of 1-simplicial attention as a function of the number of entities is O(N 2 ) while the time complexity of 2-simplicial attention is O(N 3 ) since we have to calculate the attention for every triple (i, j, k) of entities.',\n",
       " 'For this reason we consider only triples (i, j, k) where the base of the 2-simplex (j, k) is taken from a set of pairs predicted by the ordinary attention, which we view as the primary locus of computation.',\n",
       " 'More precisely, we introduce in addition to the N entities (now referred to as standard entities) a set of M virtual entities e N +1 , . . .',\n",
       " ', e N +M .',\n",
       " 'These virtual entities serve as a \"scratch pad\" onto which the iterated ordinary attention can write representations, and we restrict j, k to lie in the range N < j, k ≤ N + M so that only value vectors obtained from virtual entities are propagated by the 2-simplicial attention.',\n",
       " 'With virtual entities the update rule is for',\n",
       " 'and for',\n",
       " 'The updated representation e i is computed from v i , e i using (12) as before.',\n",
       " 'Observe that the virtual entities are not used to update the standard entities during 1-simplicial attention and the 2-simplicial attention is not used to update the virtual entities; instead the second summand in (14) involves the vector u i = W U e i , which adds recurrence to the update of the virtual entities.',\n",
       " 'After the attention phase the virtual entities are discarded.',\n",
       " 'The method for updating the virtual entities is similar to the role of the memory nodes in the relational recurrent architecture of (Santoro et al., 2018) , the master node in (Gilmer et al., 2017, §5.2) and memory slots in the Neural Turing Machine (Graves et al., 2014) .',\n",
       " 'The update rule has complexity O(N M 2 ) and so if we take M to be of order √ N we get the desired complexity O(N 2 ).',\n",
       " 'The environment in our reinforcement learning problem is a variant of the BoxWorld environment from (Zambaldi et al., 2019) .',\n",
       " 'The standard BoxWorld environment is a rectangular grid in which are situated the player (a dark gray tile) and a number of locked boxes represented by a pair of horizontally adjacent tiles with a tile of colour x, the key colour, on the left and a tile of colour y, the lock colour, on the right.',\n",
       " 'There is also one loose key in each episode, which is a coloured tile not initially adjacent to any other coloured tile.',\n",
       " 'All other tiles are blank (light gray) and are traversable by the player.',\n",
       " 'The rightmost column of the screen is the inventory, which fills from the top and contains keys that have been collected by the player.',\n",
       " 'The player can pick up any loose key by walking over it.',\n",
       " 'In order to open a locked box, with key and lock colours x, y, the player must step on the lock while in possession of a copy of y, in which case one copy of this key is removed from the inventory and replaced by a key of colour x.',\n",
       " 'The goal is to attain a white key, referred to as the Gem (represented by a white square) as shown in the sample episode of Figure 3 .',\n",
       " 'In this episode, there is a loose pink key (marked 1) which can be used to open one of two locked boxes, obtaining in this way either key 5 or key 2 1 .',\n",
       " 'The correct choice is 2, since this leads via the sequence of keys 3, 4 to the Gem.',\n",
       " 'Some locked boxes, if opened, provide keys that are not useful for attaining the Gem.',\n",
       " 'Since each key may only be used once, opening such boxes means the episode is rendered unsolvable.',\n",
       " 'Such boxes are called distractors.',\n",
       " 'An episode ends when the player either obtains the Gem (with a reward of +10) or opens a distractor box (reward −1).',\n",
       " 'Opening any non-distractor box, or picking up a loose key, garners a reward of +1.',\n",
       " 'The solution length is the number of locked boxes (including the one with the Gem) in the episode on the path from the loose key to the Gem.',\n",
       " 'Our variant of the BoxWorld environment, bridge BoxWorld, is shown in Figure 4 .',\n",
       " 'In each episode two keys are now required to obtain the Gem, and there are therefore two loose keys on the board.',\n",
       " 'To obtain the Gem, the player must step on either of the lock tiles with both keys in the inventory, at which point the episode ends with the usual +10 reward.',\n",
       " 'Graphically, Gems with multiple locks are denoted with two vertical white tiles on the left, and the two lock tiles on the right.',\n",
       " 'Two solution 1 The agent sees only the colours of tiles, not the numbers which are added here for exposition.',\n",
       " 'paths (of the same length) leading to each of the locks on the Gem are generated with no overlapping colours, beginning with two loose keys.',\n",
       " 'In episodes with multiple locks we do not consider distractor boxes of the old kind; instead there is a new type of distractor that we call a bridge.',\n",
       " 'This is a locked box whose lock colour is taken from one solution branch and whose key colour is taken from the other branch.',\n",
       " 'Opening the bridge renders the puzzle unsolvable.',\n",
       " 'An episode ends when the player either obtains the Gem (reward +10) or opens the bridge (reward −1).',\n",
       " 'Opening a box other than the bridge, or picking up a loose key, has a reward of +1 as before.',\n",
       " 'In this paper we consider episodes with zero or one bridge (the player cannot fail to solve an episode with no bridge).',\n",
       " 'Standard BoxWorld is straightforward for an agent to solve using relational reasoning, because leaves on the solution graph can be identified (their key colour appears only once on the board) and by propagating this information backwards along the arrows on the solution graph, an agent can identify distractors.',\n",
       " 'Bridge BoxWorld emphasises reasoning about 3-way relationships (or 2-simplices).',\n",
       " 'The following 2-simplex motifs',\n",
       " 'appear in all solution graphs where a pair of boxes (α, β) is a source if they have the same lock colour but distinct key colours, and a sink if they have the same key colour but distinct lock colours (the 2-simplex leading to the Gem being an example).',\n",
       " 'If α, β is a source or a sink then either α is the bridge or β is the bridge.',\n",
       " 'If the agent can observe both a source and a sink then it can locate the bridge.',\n",
       " 'It is less clear how to identify bridges using iterated relational reasoning, because every path in the solution graph eventually reaches the Gem.',\n",
       " 'Our baseline relational agent is modeled closely on (Zambaldi et al., 2019) except that we found that a different arrangement of layer normalisations worked better in our experiments, see Remark 4.1.',\n",
       " 'The code for our implementation of both agents is available online (Clift et al., 2019) .',\n",
       " 'In the following we describe the network architecture of both the relational and simplicial agent; we will note the differences between the two models as they arise.',\n",
       " \"The input to the agent's network is an RGB image, represented as a tensor of shape\",\n",
       " 'where R is the number of rows and C the number of columns (the C + 1 is due to the inventory).',\n",
       " 'This tensor is divided by 255 and then passed through a 2 × 2 convolutional layer with 12 features, and then a 2 × 2 convolutional layer with 24 features.',\n",
       " 'Both activation functions are ReLU and the padding on our convolutional layers is \"valid\" so that the output has shape [R − 2, C − 1, 24].',\n",
       " 'We then multiply by a weight matrix of shape 24 × 62 to obtain a tensor of shape [R − 2, C − 1, 62].',\n",
       " 'Each feature vector has concatenated to it a twodimensional positional encoding, and then the result is reshaped into a tensor of shape [N, 64] where N = (R − 2)(C − 1) is the number of Transformer entities.',\n",
       " 'This is the list (e 1 , . . .',\n",
       " ', e N ) of entity representations e i ∈ V = R 64 .',\n",
       " 'In the case of the simplicial agent, a further two learned embedding vectors e N +1 , e N +2 are added to this list; these are the virtual entities.',\n",
       " 'So with M = 0 in the case of the relational agent and M = 2 for the simplicial agent, the entity representations form a tensor of shape [N + M, 64].',\n",
       " 'This tensor is then passed through two iterations of the Transformer block (either purely 1-simplicial in the case of the relational agent, or including both 1 and 2-simplicial attention in the case of the simplicial agent).',\n",
       " 'In the case of the simplicial agent the virtual entities are then discarded, so that in both cases we have a sequence of entities e 1 , . . .',\n",
       " ', e N .',\n",
       " 'Inside each block are two feedforward layers separated by a ReLU activation with 64 hidden nodes; the weights are shared between iterations of the Transformer block.',\n",
       " 'In the 2-simplicial Transformer block the input tensor, after layer normalisation, is passed through the 2-simplicial attention and the result (after an additional layer normalisation) is concatenated to the output of the 1-simplicial attention heads before being passed through the feedforward layers.',\n",
       " 'The pseudo-code for the ordinary and 2-simplicial Transformer blocks are:',\n",
       " 'd e f t r a n s f o r m e r b l o c k ( e ) : x = LayerNorm ( e ) a = 1 S i m p l i c i a l A t t e n t i o n ( x ) b = D e n s e L a y e r 1 ( a ) c = D e n s e L a y e r 2 ( b ) r = Add ( [ e , c ] ) e p r i m e = LayerNorm ( r ) r e t u r n e p r i m e d e f s i m p l i c i a l t r a n s f o r m e r b l o c k ( e ) : x = LayerNorm ( e ) a1 = 1 S i m p l i c i a l A t t e n t i o n ( x ) a2 = 2 S i m p l i c i a l A t t e n t i o n ( x ) a2n = LayerNorm ( a2 ) a c = C o n c a t e n a t e ( [ a1 , a2n ] ) b = D e n s e L a y e r 1 ( a c ) c = D e n s e L a y e r 2 ( b ) r = Add ( [ e , c ] ) e p r i m e = LayerNorm ( r ) r e t u r n e p r i m e',\n",
       " 'Our implementation of the standard Transformer block is based on an implementation in Keras from (Mavreshko, 2019) .',\n",
       " 'In both the relational and simplicial agent, the space V of entity representations has dimension 64 and we denote by H 1 , H 2 the spaces of 1-simplicial and 2-simplicial queries, keys and values.',\n",
       " 'In both the relational and simplicial agent there are two heads of 1-simplicial attention,',\n",
       " 'In the simplicial agent there is a single head of 2-simplicial attention with dim(H 2 ) = 48 and two virtual entities.',\n",
       " 'The output of the Transformer blocks is a tensor of shape [N, 64] .',\n",
       " 'To this final entity tensor we apply max-pooling over the entity dimension, that is, we compute a vector v ∈ R 64 by the rule v i = max 1≤j≤N (e j ) i for 1 ≤ i ≤ 64.',\n",
       " 'This vector v is then passed through four fully-connected layers with 256 hidden nodes and ReLU activations.',\n",
       " 'The output of the final fully-connected layer is multiplied by one 256 × 4 weight matrix to produce logits for the actions (left, up, right and down) and another 256 × 1 weight matrix to produce the value function.',\n",
       " 'Remark 4.1.',\n",
       " 'There is wide variation in the layer normalisation in Transformer models, compare (Vaswani et al., 2017; Child et al., 2019; Zambaldi et al., 2019) .',\n",
       " 'In (Zambaldi et al., 2019) layer normalisation occurs in two places: on the concatenation of the Q, K, V matrices, and on the output of the feedforward network g θ .',\n",
       " 'We keep this second normalisation but move the first from after the linear transformation E of (1) to before this linear transformation, so that it is applied directly to the incoming entity representations.',\n",
       " 'This ordering gave the best performant relational model in our experiments, with our results diverging even further if a direct comparison to the (Zambaldi et al., 2019) architecture was used.',\n",
       " 'The training of our agents uses the implementation in Ray RLlib (Liang et al., 2018) of the distributed off-policy actor-critic architecture IMPALA of (Espeholt et al., 2018) with optimisation algorithm RMSProp.',\n",
       " 'The hyperparameters for IMPALA and RMSProp are given in Table 1 of Appendix E. Following (Zambaldi et al., 2019) and other recent work in deep reinforcement learning, we use RMSProp with a large value of the hyperparameter ε = 0.1.',\n",
       " 'As we explain in Appendix G, this is effectively RMSProp with smoothed gradient clipping.',\n",
       " 'First we verified that our implementation of the relational agent solves the BoxWorld environment (Zambaldi et al., 2019) with a solution length sampled from [1, 5] and number of distractors sampled from [0, 4] on a 9 × 9 grid.',\n",
       " 'After training for 2.35 × 10 9 timesteps our implementation solved over 93% of puzzles (regarding the discrepancy with the reported sample complexity in (Zambaldi et al., 2019) see Appendix D).',\n",
       " 'Next we trained the relational and simplicial agent on bridge BoxWorld, under the following conditions: half of the episodes contain a bridge, the solution length is uniformly sampled from [1, 3] (both solution paths are of the same length), colours are uniformly sampled from a set of 20 colours and the boxes and loose keys are arranged randomly on a 7 × 9 grid, under the constraint that the box containing the Gem does not occur in the rightmost column or bottom row, and keys appear only in positions (y, x) = (2r, 3c − 1) for 1 ≤ r ≤ 3, 1 ≤ c ≤ 3.',\n",
       " 'The starting and ending point of the bridge are uniformly sampled with no restrictions (e.g. the bridge can involve the colours of the loose keys and locks on the Gem) but the lock colour is always on the top solution path.',\n",
       " 'There is no curriculum and no cap on timesteps per episode.',\n",
       " 'We trained four independent trials of both agents to either 5.5 × 10 9 timesteps or convergence, whichever came first.',\n",
       " 'In Figure 6 we give the mean and standard deviation of these four trials, showing a clear advantage of the simplicial agent.',\n",
       " 'We make some remarks about performance comparisons taking into account the fact that the relational agent is simpler (and hence faster to execute) than the simplicial agent in Appendix D. The training runs for the relational and simplicial agents are shown in Figure 9 and Figure 10 of Appendix F, together with analysis and visualization of the 1-and 2-simplicial attention in specific examples.',\n",
       " 'In the reported experiments we use only two Transformer blocks; we performed two trials of a relational agent using four Transformer blocks, but after 5.5 × 10 9 timesteps neither trial exceeded the 0.85 plateau in terms of fraction solved.',\n",
       " 'Our overall results therefore suggest that the 2-simplicial Transformer is more powerful than the standard Transformer, with its performance not matched by adding greater depth.',\n",
       " 'This is further supported by the fact on a time-adjusted basis, the 2-simplicial model still converges faster than the ordinary model; see Figure 8 of Appendix D.',\n",
       " 'We analyse the simplicial agent to establish that it has learned to use the 2-simplicial attention, and to provide some intuition for why 2-simplices are useful; additional details are in Appendix F. The analysis is complicated by the fact that our 2 × 2 convolutional layers (of which there are two) are not padded, so the number of entities processed by the Transformer blocks is (R − 2)(C − 1) where the original game board is R × C and there is an extra column for the inventory (here R is the number of rows).',\n",
       " 'This means there is not a one-to-one correspondence between game board tiles and entities; for example, all the experiments reported in Figure 6 are on a 7 × 9 board, so that there are N = 40 Transformer entities which can be arranged on a 5 × 8 grid (information about this grid is passed to the Transformer blocks via the positional encoding).',\n",
       " 'Nonetheless we found that for trained agents there is a strong relation between a tile in position (y, x) and the Transformer entity with index',\n",
       " 'This correspondence is presumed in the following analysis, and in our visualisations.',\n",
       " 'Displayed in Figure 7 are attention distributions for simplicial agent A of Figure 10 .',\n",
       " 'The four images in the top right show the ordinary attention of the virtual entities in the first iteration of the simplicial Transformer block: in the first head, the first virtual entity attends strongly to a particular lock, while the second head of the second virtual entity attends strongly to the corresponding key.',\n",
       " 'Shown at the bottom of Figure 7 is the 2-simplicial attention in the second iteration of the simplicial Transformer block.',\n",
       " 'The columns are query entities i and rows are key entity pairs (j, k) in lexicographic order (1, 1), (1, 2), (2, 1), (2, 2).',\n",
       " 'Entity 17 is the top lock on the Gem, 25 is the bottom lock on the Gem, 39 is the player.',\n",
       " 'We may therefore infer, from our earlier description of the ordinary attention of the virtual entities, that the agent \"perceives\" the 2-simplex with query entity 25 as shown.',\n",
       " 'In general we observe that the top and bottom locks on the Gem, the player, and the entities 7, 15 associated to the inventory often have a non-generic 2-simplicial attention, which strongly suggests that the simplicial agent has learned to use 2-simplices in a meaningful way.',\n",
       " 'Figure 7: Visualization of 2-simplicial attention in step 18 of an episode.',\n",
       " 'On general grounds one might expect that in the limit of infinite experience, any reinforcement learning agent with a sufficiently deep neural network will be able to solve any environment, in-cluding those like bridge BoxWorld that involve higher-order relations between entities.',\n",
       " 'In practice, however, we do not care about the infinite computation limit.',\n",
       " 'In the regime of bounded computation it is reasonable to introduce biases towards learning representations of structures that are found in a wide range of environments that we consider important.',\n",
       " 'We argue that higher-order relations between entities are an important example of such structures, and that the 2-simplicial Transformer is a natural inductive bias for 3-way interactions between entities.',\n",
       " 'We have given preliminary evidence for the utility of this bias by showing that in the bridge BoxWorld environment the simplicial agent has better performance than a purely relational agent, and that this performance involves in a meaningful way the prediction of 3-way interactions (or 2-simplices).',\n",
       " 'We believe that simplicial Transformers may be useful for any problem in which higher-order relations between entities are important.',\n",
       " 'The long history of interactions between logic and algebra is a natural source of inspiration for the design of inductive biases in deep learning.',\n",
       " \"In this paper we have exhibited one example: Boole's idea, that relationships between entities can be modeled by multiplication in an algebra, may be realised in the context of deep learning as an augmentation to the Transformer architecture using Clifford algebras of spaces of representations.\",\n",
       " 'The Transformer model and descendents such as the Universal Transformer (Dehghani et al., 2019) can be viewed as general units for computing with learned representations; in this sense they have a similar conceptual role to the Neural Turing Machine (NTM) (Graves et al., 2014) and Differentiable Neural Computer (Graves et al., 2016) .',\n",
       " 'As pointed out in (Dehghani et al., 2019, §4) one can view the Transformer as a block of parallel RNNs (one for each entity) which update their hidden states at each time step by attending to the sequence of hidden states of the other RNNs at the previous step.',\n",
       " 'We expand on those remarks here in order to explain the connection between the 2-simplicial Transformer and earlier work in the NLP literature, which is written in terms of RNNs.',\n",
       " 'We consider a NTM with content-based addressing only and no sharpening.',\n",
       " 'The core of the NTM is an RNN controller with update rule',\n",
       " 'where W, U, b are weight matrices, x is the current input symbol, h is the previous hidden state, h is the next hidden state and M is the output of the memory read head',\n",
       " 'where there are N memory slots containing M 1 , . . .',\n",
       " 'M N , q is a query generated from the hidden state of the RNN by a weight matrix q = Zh, and',\n",
       " 'We omit the mechanism for writing to the memory here, since it is less obvious how that relates to the Transformer; see (Graves et al., 2014, §3.2) .',\n",
       " 'Note that while we can view M j as the \"hidden state\" of memory slot j, the controller\\'s hidden state and the hidden states of the memory slots play asymmetric roles, since the former is updated with a feedforward network at each time step, while the latter is not.',\n",
       " 'The Transformer with shared transition functions between layers is analogous to a NTM with this asymmetry removed: there is no longer a separate recurrent controller, and every memory slot is updated with a feedforward network in each timestep.',\n",
       " 'To explain, view the entity representations e 1 , . . .',\n",
       " ', e N of the Transformer as the hidden states of N parallel RNNs.',\n",
       " 'The new representation is',\n",
       " 'where the attention term is',\n",
       " 'and q i = Ze i is a query vector obtained by a weight matrix from the hidden state, the k j = Ke j are key vectors and v j = V e j is the value vector.',\n",
       " 'Note that in the Transformer the double role of M j in the NTM has been replaced by two separate vectors, the key and value, and the cosine similarity K[−, −] has been replaced by the dot product.',\n",
       " 'Having now made the connection between the Transformer and RNNs, we note that the second-order RNN (Giles et al., 1989; Pollack, 1991; Goudreau et al., 1994; Giles et al., 1991) and the similar multiplicative RNN (Sutskever et al., 2011; Irsoy & Cardie, 2015) have in common that the update rule for the hidden state of the RNN involves a term V (x ⊗ h) which is a linear function of the tensor product of the current input symbol x and the current hidden state h. One way to think of this is that the weight matrix V maps inputs x to linear operators on the hidden state.',\n",
       " 'In (Socher et al., 2013) the update rule contains a term V (e 1 ⊗ e 2 ) where e 1 , e 2 are entity vectors, and this is directly analogous to our construction.',\n",
       " 'The continuous Hopfield network (Hopfield, 1982) (MacKay, 2003, Ch.42) with N nodes updates in each timestep a sequence of vectors',\n",
       " 'by the rules',\n",
       " 'for some parameter η.',\n",
       " 'The Transformer block may therefore be viewed as a refinement of the Hopfield network, in which the three occurrences of entity vectors in (19) are replaced by query, key and value vectors W Q e i , W K e j , W V e j respectively, the nonlinearity is replaced by a feedforward network with multiple layers, and the dynamics are stabilised by layer normalisation.',\n",
       " 'The initial representations e i also incorporate information about the underlying lattice, via the positional embeddings.',\n",
       " 'The idea that the structure of a sentence acts to transform the meaning of its parts is due to Frege (Frege, 1892) and underlies the denotational semantics of logic.',\n",
       " 'From this point of view the Transformer architecture is an inheritor both of the logical tradition of denotational semantics, and of the statistical mechanics tradition via Hopfield networks.',\n",
       " 'The volume of an n-simplex in R n with vertices at 0, v 1 , . . .',\n",
       " ', v n is',\n",
       " 'which is 1 n!',\n",
       " 'times the volume of the n-dimensional parallelotope which shares n edges with the nsimplex.',\n",
       " 'In our applications the space of representations H is high dimensional, but we wish to speak of the volume of k-simplices for k < dim(H) and use those volumes to define the coefficients of our simplicial attention.',\n",
       " 'The theory of Clifford algebras (Hestenes, 2002 ) is one appropriate framework for such calculations.',\n",
       " 'Let H be an inner product space with pairing (v, w)',\n",
       " '→ v ·',\n",
       " 'w. The Clifford algebra Cl(H) is the associative unital R-algebra generated by the vectors v ∈ H with relations vw + wv = 2(v · w) · 1 .',\n",
       " 'The canonical k-linear map H −→ Cl(H) is injective, and since v 2 = v 2 · 1 in Cl(H), any nonzero vector v ∈ H is a unit in the Clifford algebra.',\n",
       " 'While as an algebra Cl(H) is only Z 2 -graded, there is nonetheless a Z-grading of the underlying vector space which can be defined as follows: let {e i } n i=1 be an orthonormal basis of H, then the set',\n",
       " 'is a basis for Cl(H), with m ranging over the set {0, . . .',\n",
       " ', n}. If we assign the basis element e i1 · · · e im the degree m, then this determines a Z-grading [−] k of the Clifford algebra which is easily checked to be independent of the choice of basis.',\n",
       " 'Definition C.1.',\n",
       " '[A] k denotes the homogeneous component of A ∈ Cl(H) of degree k.',\n",
       " 'There is an operation on elements of the Clifford algebra called reversion in geometric algebra (Hestenes, 2002, p.45 ) which arises as follows: the opposite algebra Cl(H) op admits a k-linear map j : H −→ Cl(H) op with j(v) = v which satisfies j(v)j(w) + j(w)j(v) = 2(v · w) · 1, and so by the universal property there is a unique morphism of algebras',\n",
       " 'op which restricts to the identity on H.',\n",
       " '. .',\n",
       " ', v k ∈ H and (−) † is homogeneous of degree zero with respect to the Z-grading.',\n",
       " 'Using this operation we can define the magnitude (Hestenes, 2002, p.46) of any element of the Clifford algebra.',\n",
       " 'and in particular for v ∈ H we have |v| = v .',\n",
       " 'Lemma C.4.',\n",
       " 'Set n = dim(H).',\n",
       " 'Then for A ∈ Cl(H) we have',\n",
       " 'Proof.',\n",
       " 'See (Hestenes, 2002 , Chapter 2 (1.33)).',\n",
       " 'Example C.5.',\n",
       " 'For a, b, c ∈ H the lemma gives',\n",
       " 'Remark C.6.',\n",
       " 'Given vectors v 1 , . . .',\n",
       " ', v k ∈ H the wedge product v 1 ∧ · ·',\n",
       " '· ∧ v k is an element in the exterior algebra H. Using the chosen basis B we can identify the underlying vector space of Cl(H) with H and using this identification (set',\n",
       " 'where S k is the permutation group on k letters.',\n",
       " 'That is, the top degree piece of v 1 · · · v k in Cl(H) is always the wedge product.',\n",
       " 'It is then easy to check that the squared magnitude of this wedge product is',\n",
       " 'The term in the innermost bracket is the determinant of the k × k submatrix with columns j = (j 1 , . . .',\n",
       " ', j k ) and in the special case where k = n = dim(H) we see that the squared magnitude is just the square of the determinant of the matrix (λ ij ) 1≤i,j≤n .',\n",
       " 'The wedge product of k-vectors in H can be thought of as an oriented k-simplex, and the magnitude of this wedge product in the Clifford algebra computes the volume.',\n",
       " 'Definition C.7.',\n",
       " 'The volume of a k-simplex in H with vertices 0, v 1 , . . .',\n",
       " ', v k is',\n",
       " 'Definition C.8.',\n",
       " 'Given v 1 , . . .',\n",
       " ', v k ∈ H the k-fold unsigned scalar product is',\n",
       " 'By Lemma C.4 and (21) we have',\n",
       " 'which gives the desired generalisation of the equations in Figure 2 .',\n",
       " 'Example C.9.',\n",
       " 'For k = 2 the unsigned scalar product is the absolute value of the dot product, a, b = |a · b|.',\n",
       " 'For k = 3 we obtain the formulas of Definition 2.2, from which it is easy to check that a, b, c = a b c cos 2 θ ab + cos 2 θ bc + cos 2 θ ac − 2 cos θ ab cos θ ac cos θ bc (26) where θ ac , θ ab , θ ac are the angles between a, b, c. The geometry of the three-dimensional case is more familiar: if dim(H) = 3 then |[abc] 3 | is the absolute value of the determinant by (22), so that Vol 3 =',\n",
       " 'With these formulas in mind the geometric content of the following lemma is clear:',\n",
       " '(ii) If the v i are all pairwise orthogonal then v 1 , . . .',\n",
       " ', v k = 0.',\n",
       " '(iii) The set {v 1 , . . .',\n",
       " ', v k } is linearly dependent if and only if v 1 , . . .',\n",
       " ',',\n",
       " '(v) For λ 1 , . . .',\n",
       " ', λ k ∈ R, we have For more on simplicial methods in the context of geometric algebra see (Sobczyk, 1992; Macdonald, 2017 The experiments in the original BoxWorld paper (Zambaldi et al., 2019) contain an unreported cap on timesteps per episode (an episode horizon) of 120 timesteps (Raposo, 2019).',\n",
       " 'We have chosen to run our experiments without an episode horizon, and since this means our reported sample complexities diverge substantially from the original paper (some part of which it seems reasonable to attribute to the lack of horizon) it is necessary to justify this choice.',\n",
       " 'When designing an architecture for deep reinforcement learning the goal is to reduce the expected generalisation error (Goodfellow et al., 2016 , §8.1.1) with respect to some class of similar environments.',\n",
       " 'Although this class is typically difficult to specify and is often left implicit, in our case the class includes a range of visual logic puzzles involving spatial navigation, which can be solved without memory 2 .',\n",
       " 'A learning curriculum undermines this goal, by making our expectations of generalisation conditional on the provision of a suitable curriculum, whose existence for a given member of the problem class may not be clear in advance.',\n",
       " 'The episode horizon serves as a de facto curriculum, since early in training it biases the distribution of experience rollouts towards the initial problems that an agent has to solve (e.g. learning to pick up the loose key).',\n",
       " 'In order to avoid compromising our ability to expect generalisation to similar puzzles which do not admit such a useful curriculum, we have chosen not to employ an episode horizon.',\n",
       " 'Fortunately, the relational agent performs well even without a curriculum on the original BoxWorld, as our results show.',\n",
       " 'In Figure 6 of Section 5, the horizontal axis was environment steps.',\n",
       " 'However, since the simplicial agent has a more complex model, each environment step takes longer to execute and the gradient descent steps are slower.',\n",
       " 'In a typical experiment run on the GCP configuration, the training throughput of the relational agent is 1.9 × 10 4 environment frames per second (FPS) and that of the simplicial agent is 1.4 × 10 4 FPS.',\n",
       " 'The relative performance gap decreases as the GPU memory and the number of IMPALA workers are increased, and this is consistent with the fact that the primary performance difference appears to be the time taken to compute the gradients (35ms vs 80ms).',\n",
       " 'In Figure 8 we give the time-adjusted performance of the simplicial agent (the graph for the relational agent is as before) where the x-axis of the graph of the simplicial agent is scaled by 1.9/1.4.',\n",
       " 'In principle there is no reason for a significant performance mismatch: the 2-simplicial attention can be run in parallel to the ordinary attention (perhaps with two iterations of the 1-simplicial attention per iteration of the 2-simplicial attention) so that with better engineering it should be possible to reduce this gap.',\n",
       " '2 The bridge is the unique box both of whose colours appear three times on the board.',\n",
       " 'However, this is not a reliable strategy for detecting bridges for an agent without memory, because once the agent has collected some of the keys on the board, some of the colours necessary to make this deduction may no longer be present.',\n",
       " 'Our experiments involve only a small number of virtual entities, and a small number of iterations of the Transformer block: it is possible that for large numbers of virtual entities and iterations, our choices of layer normalisation are not optimal.',\n",
       " 'Our aim was to test the viability of the simplicial Transformer starting with the minimal configuration, so we have also not tested multiple heads of 2-simplicial attention.',\n",
       " 'Deep reinforcement learning is notorious for poor reproducibility (Henderson et al., 2017) , and in an attempt to follow the emerging best practices we are releasing our agent and environment code, trained agent weights, and training notebooks (Clift et al., 2019) .',\n",
       " 'The training runs for the relational and simplicial agents are shown in Figure 9 and Figure 10 respectively.',\n",
       " 'In this Appendix we provide further details relating to the analysis of the attention of the trained simplicial agent in Section 6.',\n",
       " 'Across our four trained simplicial agents, the roles of the virtual entities and heads vary: the following comments are all in the context of the best simplicial agent (simplicial agent A of Figure 10 ) but we observe similar patterns in the other trials.',\n",
       " 'The standard entities are now indexed by 0 ≤ i ≤ 39 and virtual entities by i = 40, 41.',\n",
       " 'In the first iteration of the 2-simplicial Transformer block, the first 1-simplicial head appears to propagate information about the inventory.',\n",
       " 'At the beginning of an episode the attention of each standard entity is distributed between entities 7, 15, 23, 31 (the entities in the rightmost column), it concentrates sharply on 7 (the entity closest to the first inventory slot) after the acquisition of the first loose key, and sharply on 7, 15 after the acquisition of the second loose key.',\n",
       " 'The second 1-simplicial head seems to acquire the meaning described in (Zambaldi et al., 2019) , where tiles of the same colour attend to one another.',\n",
       " 'A typical example is shown in Figure 11 .',\n",
       " 'The video of this episode is available online (Clift et al., 2019) .',\n",
       " 'Figure 11 : Visualisation of 1-simplicial attention in first Transformer block, between standard entities in heads one and two.',\n",
       " 'The vertical axes on the second and third images are the query index 0 ≤ i ≤ 39, the horizontal axes are the key index 0 ≤ j ≤ 39.',\n",
       " 'The standard entities are updated using 2-simplices in the first iteration of the 2-simplicial Transformer block, but this is not interesting as initially the virtual entities are learned embedding vectors, containing no information about the current episode.',\n",
       " 'So we restrict our analysis to the 2-simplicial attention in the second iteration of the Transformer block.',\n",
       " 'For the analysis, it will be convenient to organise episodes of bridge BoxWorld by their puzzle type, which is the tuple (a, b, c) where 1 ≤ a ≤ 3 is the solution length, 1 ≤ b ≤ a is the bridge source and a + 1 ≤ c ≤ 2a is the bridge target, with indices increasing with the distance from the gem.',\n",
       " 'The episodes in Figures 4 and 7 have type (3, 2, 5 ).',\n",
       " 'Figure 12: Visualisation of the 2-simplicial attention in the second Transformer block in step 13 of an episode of puzzle type (3, 3, 5) .',\n",
       " 'Entity 1 is the top lock on the Gem, 15 is associated with the inventory, 36 is the lock directly below the player.',\n",
       " 'Shown is a 2-simplex with target 15.',\n",
       " 'Figure 13: Visualisation of the 2-simplicial attention in the second Transformer block in step 29 of an episode of puzzle type (3, 3, 5) .',\n",
       " 'Entity 7 is associated with the inventory, 17 is the player.',\n",
       " 'Shown is a 2-simplex with target 17.',\n",
       " 'To give more details we must first examine the content of the virtual entities after the first iteration, which is a function of the 1-simplicial attention of the virtual entities in the first iteration.',\n",
       " 'In Figures  7, 12 , 13 we show these attention distributions multiplied by the pixels in the region [1, R − 2] × [1, C − 1] of the original board, in the second and third columns of the second and third rows.',\n",
       " 'Let f 1 = e 40 and f 2 = e 41 denote the initial representations of the first and second virtual entities, before the first iteration.',\n",
       " 'We use the index z ∈ {1, 2} to stand for a virtual entity.',\n",
       " 'In the first iteration the representations are updated by (14) to',\n",
       " 'where the sum is over all entities α, the a z α are the attention coefficients of the first 1-simplicial head and the coefficients b z α are the attention of the second 1-simplicial head.',\n",
       " 'Writing 0 1 , 0 2 for the zero vector in H 1 1 , H 1 2 respectively, this can be written as',\n",
       " 'For a query entity i the vector propagated by the 2-simplicial part of the second iteration has the following terms, where',\n",
       " 'Here A i j,k is the 2-simplicial attention with logits p i , l',\n",
       " ') is the ith column in our visualisations of the 2-simplicial attention, so in the situation of Figure 7 with i = 25 we have A 25 1,2 ≈ 1 and hence the output of the 2-simplicial head used to update the entity representation of the bottom lock on the Gem is approximately B(f 1 ⊗ f 2 ).',\n",
       " 'If we ignore the layer normalisation, feedforward network and skip connection in (30) then f 1 ≈ v 1 ⊕ 0 2 and f 2 ≈ 0 1 ⊕ v 0 so that the output of the 2-simplicial head with target i = 25 is approximately',\n",
       " '(32) Following Boole (Boole, 1847) and Girard (Girard, 1987)',\n",
       " 'it is natural to read the \"product\" (32) as a conjunction (consider together the entity 1 and the entity 0) and the sum in (31) as a disjunction.',\n",
       " 'An additional layer normalisation is applied to this vector, and the result is concatenated with the incoming information for entity 25 from the 1-simplicial attention, before all of this is passed through (12) to form e 25 .',\n",
       " 'Given that the output of the 2-simplicial head is the only nontrivial difference between the simplicial and relational agent (with a transformer depth of two, the first 2-simplicial Transformer block only updates the standard entities with information from embedding vectors) the performance differences reported in Figure 6 suggest that this output is informative about avoiding bridges.',\n",
       " 'In the training curves of the agents of Figure 9 and Figure 10 we observe a common plateau at a win rate of 0.85.',\n",
       " 'In Figure 14 we show the per-puzzle win rate of simplicial agent A and relational agent A, on (1, 1, 2) puzzles.',\n",
       " 'These graphs make clear that the transition of both agents to the plateau at 0.85 is explained by solving the (1, 1, 2) type (and to a lesser degree by progress on all puzzle types with b = 1).',\n",
       " 'In Figure 14 and Figure 15 we give the per-puzzle win rates for a small sample of other puzzle types.',\n",
       " 'Shown are the mean and standard deviation of 100 runs across various checkpoints of simplicial agent A and relational agent A.',\n",
       " 'As originally presented in (Tieleman & Hinton, 2012 ) the optimisation algorithm RMSProp is a mini-batch version of Rprop, where instead of dividing by a different number in every mini-batch 3, 3, 5), (3, 3, 6) .',\n",
       " '(namely, the absolute value of the gradient) we force this number to be similar for adjacent minibatches by keeping a moving average of the square of the gradient.',\n",
       " 'In more detail, one step Rprop is computed by the algorithm',\n",
       " 'κ is the learning rate, x i is a weight, g i is the associated gradient and ε is a small constant (the TensorFlow default value is 10 −10 ) added for numerical stability.',\n",
       " 'The idea of Rprop is to update weights using only the sign of the gradient: every weight is updated by the same absolute amount κ in each step, with only the sign g i / √ r i = g i /|g i | of the update varying with i. The algorithm',\n",
       " 'RMSprop was introduced as a refinement of Rprop:',\n",
       " 'p is the decay rate (in our experiments the value is 0.99).',\n",
       " 'Clearly Rprop is the p → 0 limit of RMSprop.',\n",
       " 'For further background see (Goodfellow et al., 2016, §8.5',\n",
       " 'In recent years there has been a trend in the literature towards using RMSprop with large values of the hyperparameter ε.',\n",
       " 'For example in (Zambaldi et al., 2019) RMSProp is used with ε = 0.1, which is also one of the range of values in (Espeholt et al., 2018, (Jaderberg et al., 2017) .',\n",
       " 'This \"large ε RMSProp\" seems to have originated in (Szegedy et al., 2016, §8) .',\n",
       " 'To understand what large ε RMSProp is doing, let us rewrite the algorithm as',\n",
       " 'where S is the sigmoid S(u) = u/ √ 1 + u 2 which asymptotes to 1 as u → +∞ and is wellapproximated by the identity function for small u.',\n",
       " 'We see a new multiplicative factor S( r i /ε) in the optimisation algorithm.',\n",
       " 'Note that √ r i is a moving average of |g i |.',\n",
       " 'Recall the original purpose of Rprop was to update weights using only the sign of the gradient and the learning rate, namely κg i / √',\n",
       " 'r i .',\n",
       " 'The new S factor in the above reinserts the size of the gradient, but scaled by the sigmoid to be in the unit interval.',\n",
       " 'In the limit ε → 0 we squash the outputs of the sigmoid up near 1 and the standard conceptual description of RMSProp applies.',\n",
       " 'But as ε → 1 the sigmoid S( √ r i ) has the effect that for large stable gradients we get updates of size κ and for small stable gradients we get updates of the same magnitude as the gradient.',\n",
       " 'In conclusion, large ε RMSprop is a form of RMSprop with smoothed gradient clipping (Goodfellow et al., 2016, §10.11.1) .',\n",
       " 'It is no simple matter to define logical reasoning nor to recognise when an agent (be it an animal or a deep reinforcement learning agent) is employing such reasoning (Mackintosh, 2019; Barrett et al., 2018) .',\n",
       " 'We therefore begin by returning to Aristotle, who viewed logic as the study of general patterns by which one could distinguish valid and invalid forms of philosophical argumentation; this study having as its purpose the production of strategies for winning such argumentation games (Aristotle, 1984; Smith, 2019; Spade & Hintikka, 2019) .',\n",
       " 'In this view, logic involves',\n",
       " '• two players with one asserting the truth of a proposition and attempting to defend it, and the latter asserting its falsehood and attempting to refute it, and an • observer attempting to learn the general patterns which are predictive of which of the two players will win such a game given some intermediate state.',\n",
       " 'Suppose we observe over a series of games 4 that a player is following an explicit strategy which has been distilled from general patterns observed in a large distribution of games, and that by following this strategy they almost always win.',\n",
       " 'A component of that explicit strategy can be thought of as logical reasoning to the degree that it consists of rules that are independent of the particulars of the game (Aristotle, 1984, §11.25) .',\n",
       " 'The problem of recognising logical reasoning in behaviour is therefore twofold: the strategy employed by a player is typically implicit, and even if we can recognise explicit components of the strategy, in practice there is not always a clear way to decide which rules are domain-specific.',\n",
       " 'In mathematical logic the idea of argumentation games has been developed into a theory of mathematical proof as strategy in the game semantics of linear logic (Hyland, 1997) where one player (the prover) asserts a proposition G and the other player (the refuter) interrogates this assertion.',\n",
       " 'Published as a conference paper at ICLR 2020 Consider a reinforcement learning problem (Sutton & Barto, 2018) in which the deterministic environment encodes G together with a multiset of hypotheses Γ which are sufficient to prove G. Such a pair is called a sequent and is denoted Γ G. The goal of the agent (in the role of prover) is to synthesise a proof of G from Γ through a series of actions.',\n",
       " \"The environment (in the role of refuter) delivers a positive reward if the agent succeeds, and a negative reward if the agent's actions indicate a commitment to a line of proof which cannot possibly succeed.\",\n",
       " 'Consider a deep reinforcement learning agent with a policy network parametrised by a vector of weights w ∈ R D and a sequence of full-episode rollouts of this policy in the environment, each of which either ends with the agent constructing a proof (prover wins) or failing to construct a proof (refuter wins) with the sequent Γ G being randomly sampled in each episode.',\n",
       " \"Viewing these episodes as instances of an argumentation game, the goal of Aristotle's observer is to learn from this data to predict, given an intermediate state of some particular episode, which actions by the prover will lead to success (proof) or failure (refutation).\",\n",
       " \"As the reward is correlated with success and failure in this sense, the goal of the observer may be identified with the training objective of the action-value network underlying the agent's policy, and we may identify the triple player, opponent, observer with the triple agent, environment and optimisation process.\",\n",
       " 'If this process succeeds, so that the trained agent wins in almost every episode, then by definition the weights w are an implicit strategy for proving sequents Γ G.',\n",
       " 'This leads to the question: is the deep reinforcement learning agent parametrised by w performing logical reasoning?',\n",
       " \"We would have no reason to deny that logical reasoning is present if we were to find, in the weights w and dynamics of the agent's network, an isomorphic image of an explicit strategy that we recognise as logically correct.\",\n",
       " 'In general, however, it seems more useful to ask to what degree the behaviour is governed by logical reasoning, and thus to what extent we can identify an approximate homomorphic image in the weights and dynamics of a logically correct explicit strategy.',\n",
       " 'Ultimately this should be automated using \"logic probes\" along the lines of recent developments in neural network probes (Alain & Bengio, 2016; Koh & Liang, 2017; Nguyen et al., 2016; Shrikumar et al., 2017; Simonyan et al., 2013) .',\n",
       " \"The design of the BoxWorld environment was intended to stress the planning and reasoning components of an agent's policy (Zambaldi et al., 2019, p.2) and for this reason it is the underlying logical structure of the environment that is of central importance.\",\n",
       " 'To explain the logical structure of BoxWorld and bridge BoxWorld we introduce the following notation: given a colour c, we use C to stand for the proposition that a key of this colour is obtainable.',\n",
       " 'Each episode expresses its own set of basic facts, or axioms, about obtainability.',\n",
       " 'For instance, a loose key of colour c gives C as an axiom, and a locked box requiring a key of colour c in order to obtain a key of colour d gives an axiom that at first glance appears to be the implication C −→ D of classical logic.',\n",
       " 'However, since a key may only be used once, this is actually incorrect; instead the logical structure of this situation is captured by the linear implication C D of linear logic (Girard, 1987) .',\n",
       " 'With this understood, each episode of the original BoxWorld provides in visual form a set of axioms Γ such that a strategy for obtaining the Gem is equivalent to a proof of Γ G in intuitionistic linear logic, where G stands for the proposition that the Gem is obtainable.',\n",
       " 'There is a general correspondence in logic between strategies and proofs which we recall in Appendix I.',\n",
       " 'To describe the logical structure of bridge BoxWorld we need to encode the fact that two keys (say a green key and a blue key) are required to obtain the Gem.',\n",
       " 'Once again, it is the linear conjunction ⊗ of linear logic (also called the tensor product) rather than the conjunction of classical logic that properly captures the semantics.',\n",
       " 'The axioms Γ encoded in an episode of bridge BoxWorld contain a single formula of the form X 1 ⊗ X 2 G where x 1 , x 2 are the colours of the keys on the Gem, and again a strategy is equivalent to a proof of Γ G. In conclusion, the logical structure of the original BoxWorld consists of a fragment of linear logic containing only the connective , while bridge BoxWorld captures a slightly larger fragment containing and ⊗.',\n",
       " 'Next we explain the correspondence between agent behaviour in bridge BoxWorld and proofs in linear logic.',\n",
       " 'For an introduction to linear logic tailored to the setting of games see (Martens, 2015, Ch.2) .',\n",
       " 'Recall that to each colour c we have associated a proposition C which can be read as \"the key of colour c is obtainable\".',\n",
       " 'If a box β appears in an episode of bridge BoxWorld (this includes loose in the sentence \"There was a cat and he liked to sleep\").',\n",
       " 'These representations of relations take the form of query and key vectors governing the passing of messages between entities; messages update entity representations over several rounds of computation until the final representations reflect not just the meaning of words but also their context in a sentence.',\n",
       " 'There is some evidence that the geometry of these final representations serve to organise word representations in a syntax tree, which could be seen as the appropriate analogue to two-dimensional space in the context of language (Hewitt & Manning, 2019) .',\n",
       " 'The Transformer may therefore be viewed as an inductive bias for learning structural representations which are graphs, with entities as vertices and relations as edges.',\n",
       " 'While a graph is a discrete mathematical object, there is a naturally associated topological space which is obtained by gluing 1-simplices (copies of the unit interval) indexed by edges along 0-simplices (points) indexed by vertices.',\n",
       " 'There is a general mathematical notion of a simplicial set which is a discrete structure containing a set of n-simplices for all n ≥ 0 together with an encoding of the incidence relations between these simplices.',\n",
       " 'Associated to each simplicial set is a topological space, obtained by gluing together vertices, edges, triangles (2-simplices), tetrahedrons (3-simplices), and so on, according to the instructions contained in the simplicial set.',\n",
       " 'Following the aforementioned works in neuroscience (Constantinescu et al., 2016; Epstein et al., 2017; Behrens et al., 2018; Bellmund et al., 2018; Whittington et al., 2018; Liu et al., 2019) and their emphasis on spatial structure, it is natural to ask if a simplicial inductive bias for learning structural representations can facilitate abstract reasoning.',\n",
       " 'This question partly motivated the developments in this paper.',\n",
       " 'We present Tensor-Train RNN (TT-RNN), a novel family of neural sequence architectures for multivariate forecasting in environments with nonlinear dynamics.',\n",
       " 'Long-term forecasting in such systems is highly challenging, since there exist long-term temporal dependencies, higher-order correlations and sensitivity to error propagation.',\n",
       " 'Our proposed tensor recurrent architecture addresses these issues by learning the nonlinear dynamics directly using higher order moments and high-order state transition functions.',\n",
       " 'Furthermore, we decompose the higher-order structure using the tensor-train (TT) decomposition to reduce the number of parameters while preserving the model performance.',\n",
       " 'We theoretically establish the approximation properties of Tensor-Train RNNs for general sequence inputs, and such guarantees are not available for usual RNNs.',\n",
       " 'We also demonstrate significant long-term prediction improvements over general RNN and LSTM architectures on a range of simulated environments with nonlinear dynamics, as well on real-world climate and traffic data.',\n",
       " 'One of the central questions in science is forecasting: given the past history, how well can we predict the future?',\n",
       " 'In many domains with complex multivariate correlation structures and nonlinear dynamics, forecasting is highly challenging since the system has long-term temporal dependencies and higher-order dynamics.',\n",
       " 'Examples of such systems abound in science and engineering, from biological neural network activity, fluid turbulence, to climate and traffic systems (see FIG0 ).',\n",
       " 'Since current forecasting systems are unable to faithfully represent the higher-order dynamics, they have limited ability for accurate long-term forecasting.',\n",
       " 'Therefore, a key challenge is accurately modeling nonlinear dynamics and obtaining stable long-term predictions, given a dataset of realizations of the dynamics.',\n",
       " 'Here, the forecasting problem can be stated as follows: how can we efficiently learn a model that, given only few initial states, can reliably predict a sequence of future states over a long horizon of T time-steps?',\n",
       " 'Common approaches to forecasting involve linear time series models such as auto-regressive moving average (ARMA), state space models such as hidden Markov model (HMM), and deep neural networks.',\n",
       " 'We refer readers to a survey on time series forecasting by BID2 and the references therein.',\n",
       " 'A recurrent neural network (RNN), as well as its memory-based extensions such as the LSTM, is a class of models that have achieved good performance on sequence prediction tasks from demand forecasting BID5 to speech recognition BID15 and video analysis BID9 .',\n",
       " 'Although these methods can be effective for short-term, smooth dynamics, neither analytic nor data-driven learning methods tend to generalize well to capturing long-term nonlinear dynamics and predicting them over longer time horizons.',\n",
       " 'To address this issue, we propose a novel family of tensor-train recurrent neural networks that can learn stable long-term forecasting.',\n",
       " 'These models have two key features: they 1) explicitly model the higher-order dynamics, by using a longer history of previous hidden states and high-order state interactions with multiplicative memory units; and 2) they are scalable by using tensor trains, a structured low-rank tensor decomposition that greatly reduces the number of model parameters, while mostly preserving the correlation structure of the full-rank model.',\n",
       " 'In this work, we analyze Tensor-Train RNNs theoretically, and also experimentally validate them over a wide range of forecasting domains.',\n",
       " 'Our contributions can be summarized as follows:• We describe how TT-RNNs encode higher-order non-Markovian dynamics and high-order state interactions.',\n",
       " 'To address the memory issue, we propose a tensor-train (TT) decomposition that makes learning tractable and fast.• We provide theoretical guarantees for the representation power of TT-RNNs for nonlinear dynamics, and obtain the connection between the target dynamics and TT-RNN approximation.',\n",
       " 'In contrast, no such theoretical results are known for standard recurrent networks.•',\n",
       " 'We validate TT-RNNs on simulated data and two real-world environments with nonlinear dynamics (climate and traffic).',\n",
       " 'Here, we show that TT-RNNs can forecast more accurately for significantly longer time horizons compared to standard RNNs and LSTMs.',\n",
       " 'Forecasting Nonlinear Dynamics Our goal is to learn an efficient model f for sequential multivariate forecasting in environments with nonlinear dynamics.',\n",
       " 'Such systems are governed by dynamics that describe how a system state x t ∈ R d evolves using a set of nonlinear differential equations: DISPLAYFORM0 where ξ i can be an arbitrary (smooth) function of the state x t and its derivatives.',\n",
       " 'Continous time dynamics are usually described by differential equations while difference equations are employed for discrete time.',\n",
       " 'In continuous time, a classic example is the first-order Lorenz attractor, whose realizations showcase the \"butterfly-effect\", a characteristic set of double-spiral orbits.',\n",
       " 'In discretetime, a non-trivial example is the 1-dimensional Genz dynamics, whose difference equation is: DISPLAYFORM1 where x t denotes the system state at time t and c, w are the parameters.',\n",
       " 'Due to the nonlinear nature of the dynamics, such systems exhibit higher-order correlations, long-term dependencies and sensitivity to error propagation, and thus form a challenging setting for learning.',\n",
       " 'Given a sequence of initial states x 0 . . .',\n",
       " 'x t , the forecasting problem aims to learn a model f DISPLAYFORM2 that outputs a sequence of future states x t+1 . . .',\n",
       " 'x T .',\n",
       " 'Hence, accurately approximating the dynamics ξ is critical to learning a good forecasting model f and accurately predicting for long time horizons.',\n",
       " 'First-order Markov Models In deep learning, common approaches for modeling dynamics usually employ first-order hidden-state models, such as recurrent neural networks (RNNs).',\n",
       " 'An RNN with a single RNN cell recursively computes the output y t from a hidden state h t using: DISPLAYFORM3 where f is the state transition function, g is the output function and θ are model parameters.',\n",
       " 'An RNN only considers the most recent hidden state in its state transition function.',\n",
       " 'A common parametrization scheme for (4) is a nonlinear activation function applied to a linear map of x t and h t−1 as: LSTMs BID8 and GRUs BID3 .',\n",
       " 'For instance, LSTM cells use a memory-state, which mitigate the \"exploding gradient\" problem and allow RNNs to propagate information over longer time horizons.',\n",
       " 'Although RNNs are very expressive, they compute h t only using the previous state h t−1 and input x t .',\n",
       " 'Such models do not explicitly model higher-order dynamics and only implicitly model long-term dependencies between all historical states h 0 . . .',\n",
       " 'h t , which limits their forecasting effectiveness in environments with nonlinear dynamics.',\n",
       " 'DISPLAYFORM4',\n",
       " 'To effectively learn nonlinear dynamics, we propose Tensor-Train RNNs, or TT-RNNs, a class of higher-order models that can be viewed as a higher-order generalization of RNNs.',\n",
       " 'We developed TT-RNNs with two goals in mind: explicitly modeling 1) L-order Markov processes with L steps of temporal memory and 2) polynomial interactions between the hidden states h · and x t .First, we consider longer \"history\": we keep length L historic states: DISPLAYFORM0 where f is an activation function.',\n",
       " 'In principle, early work BID7 has shown that with a large enough hidden state size, such recurrent structures are capable of approximating any dynamics.',\n",
       " 'Second, to learn the nonlinear dynamics ξ efficiently, we also use higher-order moments to approximate the state transition function.',\n",
       " 'We construct a higher-order transition tensor by modeling a degree P polynomial interaction between hidden states.',\n",
       " 'Hence, the TT-RNN with standard RNN cell is defined by: DISPLAYFORM1 where α index the hidden dimension, i · index historic hidden states and P is the polynomial degree.',\n",
       " 'Here, we defined the L-lag hidden state as: DISPLAYFORM2 We included the bias unit 1 to model all possible polynomial expansions up to order P in a compact form.',\n",
       " 'The TT-RNN with LSTM cell, or \"TLSTM\", is defined analogously as: DISPLAYFORM3 where • denotes the Hadamard product.',\n",
       " 'Note that the bias units are again included.',\n",
       " 'TT-RNN serves as a module for sequence-to-sequence (Seq2Seq) framework BID18 , which consists of an encoder-decoder pair (see FIG1 ).',\n",
       " 'We use tensor-train recurrent cells both the encoder and decoder.',\n",
       " 'The encoder receives the initial states and the decoder predicts x t+1 , . . .',\n",
       " ', x T .',\n",
       " 'For each timestep t, the decoder uses its previous prediction y t as an input.',\n",
       " 'Unfortunately, due to the \"curse of dimensionality\", the number of parameters in W α with hidden size H grows exponentially as O(HL P ), which makes the high-order model prohibitively large to train.',\n",
       " 'To overcome this difficulty, we utilize tensor networks to approximate the weight tensor.',\n",
       " 'Such networks encode a structural decomposition of tensors into low-dimensional components and have been shown to provide the most general approximation to smooth tensors BID11 .',\n",
       " 'The most commonly used tensor networks are linear tensor networks (LTN), also known as tensor-trains in numerical analysis or matrix-product states in quantum physics BID12 .A tensor train model decomposes a P -dimensional tensor W into a network of sparsely connected low-dimensional tensors DISPLAYFORM0 DISPLAYFORM1 as depicted in Figure ( 3).',\n",
       " 'When r 0 = r P = 1 the {r d } are called the tensor-train rank.',\n",
       " 'With tensortrain, we can reduce the number of parameters of TT-RNN from (HL + 1) P to (HL + 1)R 2 P , with R = max d r d as the upper bound on the tensor-train rank.',\n",
       " 'Thus, a major benefit of tensor-train is that they do not suffer from the curse of dimensionality, which is in sharp contrast to many classical tensor decompositions, such as the Tucker decomposition.',\n",
       " 'A significant benefit of using tensor-trains is that we can theoretically characterize the representation power of tensor-train neural networks for approximating high-dimensional functions.',\n",
       " 'We do so by analyzing a class of functions that satisfies some regularity condition.',\n",
       " 'For such functions, tensor-train decompositions preserve weak differentiability and yield a compact representation.',\n",
       " 'We combine this property with neural network estimation theory to bound the approximation error for TT-RNN with one hidden layer in terms of: 1) the regularity of the target function f , 2) the dimension of the input space, 3) the tensor train rank and 4) the order of the tensor.',\n",
       " 'In the context of TT-RNN, the target function f (x), with x = s ⊗ . . .',\n",
       " '⊗ s, describes the state transitions of the system dynamics, as in (6).',\n",
       " 'Let us assume that f (x) is a Sobolev function: f ∈ H k µ , defined on the input space I = I 1 × I 2 × · · ·',\n",
       " 'I d , where each I i is a set of vectors.',\n",
       " 'The space H k µ is defined as the functions that have bounded derivatives up to some order k and are L µ -integrable: DISPLAYFORM0 where D (i) f is the i-th weak derivative of f and µ ≥ 0.',\n",
       " '1 Any Sobolev function admits a Schmidt decomposition: DISPLAYFORM1 , where {λ} are the eigenvalues and {γ}, {φ} are the associated eigenfunctions.',\n",
       " 'Hence, we can decompose the target function f ∈ H k µ as: DISPLAYFORM2 where DISPLAYFORM3 We can truncate (13) to a low dimensional subspace (r < ∞), and obtain the functional tensor-train (FTT) approximation of the target function f : DISPLAYFORM4 In practice, TT-RNN implements a polynomial expansion of the state s as in (6), using powers [s, s ⊗2 , · · · , s ⊗p ] to approximate f T T , where p is the degree of the polynomial.',\n",
       " 'We can then bound the approximation error using TT-RNN, viewed as a one-layer hidden neural network: 1 A weak derivative generalizes the derivative concept for (non)-differentiable functions and is implicitly defined as: DISPLAYFORM5 DISPLAYFORM6 is the size of the state space, r is the tensor-train rank and p is the degree of high-order polynomials i.e., the order of tensor.',\n",
       " 'For the full proof, see the Appendix.',\n",
       " 'From this theorem we see: 1) if the target f becomes smoother, it is easier to approximate and 2) polynomial interactions are more efficient than linear ones in the large rank region: if the polynomial order increases, we require fewer hidden units n.',\n",
       " 'This result applies to the full family of TT-RNNs, including those using vanilla RNN or LSTM as the recurrent cell, as long as we are given a state transitions (x t , s t ) → s t+1 (e.g. the state transition function learned by the encoder).',\n",
       " 'We validated the accuracy and efficiency of TT-RNN on one synthetic and two real-world datasets, as described below; Detailed preprocessing and data statistics are deferred to the Appendix.',\n",
       " 'Genz dynamics The Genz \"product peak\" (see FIG3 a) is one of the Genz functions BID6 , which are often used as a basis for high-dimensional function approximation.',\n",
       " 'In particular, BID1 used them to analyze tensor-train decompositions.',\n",
       " 'We generated 10, 000 samples of length 100 using (2) with w = 0.5, c = 1.0 and random initial points.',\n",
       " 'Traffic The traffic data (see FIG3 b) of Los Angeles County highway network is collected from California department of transportation http://pems.dot.ca.gov/. The prediction task is to predict the speed readings for 15 locations across LA, aggregated every 5 minutes.',\n",
       " 'After upsampling and processing the data for missing values, we obtained 8, 784 sequences of length 288.Climate The climate data (see FIG3 c) is collected from the U.S. Historical Climatology Network (USHCN) (http://cdiac.ornl.gov/ftp/ushcn_daily/).',\n",
       " 'The prediction task is to predict the daily maximum temperature for 15 stations.',\n",
       " 'The data spans approximately 124 years.',\n",
       " 'After preprocessing, we obtained 6, 954 sequences of length 366.',\n",
       " 'Experimental Setup To validate that TT-RNNs effectively perform long-term forecasting task in (3), we experiment with a seq2seq architecture with TT-RNN using LSTM as recurrent cells (TLSTM).',\n",
       " 'For all experiments, we used an initial sequence of length t 0 as input and varied the forecasting horizon T .',\n",
       " 'We trained all models using stochastic gradient descent on the length-T sequence regression loss L(y,ŷ) = T t=1 ||ŷ t − y t || 2 2 , where y t = x t+1 ,ŷ t are the ground truth and model prediction respectively.',\n",
       " 'For more details on training and hyperparameters, see the Appendix.',\n",
       " 'We compared TT-RNN against 2 set of natural baselines: 1st-order RNN (vanilla RNN, LSTM), and matrix RNNs (vanilla MRNN, MLSTM), which use matrix products of multiple hidden states without factorization BID14 ).',\n",
       " 'We observed that TT-RNN with RNN cells outperforms vanilla RNN and MRNN, but using LSTM cells performs best in all experiments.',\n",
       " 'We also evaluated the classic ARIMA time series model and observed that it performs ∼ 5% worse than LSTM.Long-term Accuracy For traffic, we forecast up to 18 hours ahead with 5 hours as initial inputs.',\n",
       " 'For climate, we forecast up to 300 days ahead given 60 days of initial observations.',\n",
       " 'For Genz dynamics, we forecast for 80 steps given 5 initial steps.',\n",
       " 'All results are averages over 3 runs.',\n",
       " 'We now present the long-term forecasting accuracy of TLSTM in nonlinear systems.',\n",
       " 'FIG4 shows the test prediction error (in RMSE) for varying forecasting horizons for different datasets.',\n",
       " 'We can see that TLSTM notably outperforms all baselines on all datasets in this setting.',\n",
       " 'In particular, TLSTM is more robust to long-term error propagation.',\n",
       " 'We observe two salient benefits of using TT-RNNs over the unfactorized models.',\n",
       " 'First, MRNN and MLSTM can suffer from overfitting as the number of weights increases.',\n",
       " 'Second, on traffic, unfactorized models also show considerable instability in their long-term predictions.',\n",
       " 'These results suggest that tensor-train neural networks learn more stable representations that generalize better for long-term horizons.',\n",
       " 'To get intuition for the learned models, we visualize the best performing TLSTM and baselines in FIG5 for the Genz function \"corner-peak\" and the statetransition function.',\n",
       " 'We can see that TLSTM can almost perfectly recover the original function, while LSTM and MLSTM only correctly predict the mean.',\n",
       " 'These baselines cannot capture the dynamics fully, often predicting an incorrect range and phase for the dynamics.',\n",
       " 'In FIG6 we show predictions for the real world traffic and climate dataset.',\n",
       " 'We can see that the TLSTM corresponds significantly better with ground truth in long-term forecasting.',\n",
       " 'As the ground truth time series is highly chaotic and noisy, LSTM often deviates from the general trend.',\n",
       " 'While both MLSTM and TLSTM can correctly learn the trend, TLSTM captures more detailed curvatures due to the inherent high-order structure.',\n",
       " 'Speed Performance Trade-off We now investigate potential trade-offs between accuracy and computation.',\n",
       " 'FIG7 displays the validation loss with respect to the number of steps, for the best performing models on long-term forecasting.',\n",
       " 'We see that TT-RNNs converge significantly faster than other models, and achieve lower validation-loss.',\n",
       " 'This suggests that TT-RNN has a more efficient representation of the nonlinear dynamics, and can learn much faster as a result.',\n",
       " 'Hyper-parameter Analysis The TLSTM model is equipped with a set of hyper-parameters, such as tensor-train rank and the number of lags.',\n",
       " 'We perform a random grid search over these hyperparameters and showcase the results in Table 1 .',\n",
       " 'In the top row, we report the prediction RMSE for the largest forecasting horizon w.r.t tensor ranks for all the datasets with lag 3.',\n",
       " 'When the rank is too low, the model does not have enough capacity to capture non-linear dynamics.',\n",
       " 'when the rank is too high, the model starts to overfit.',\n",
       " 'In the bottom row, we report the effect of changing lags (degree of orders in Markovian dynamics).',\n",
       " 'For each setting, the best r is determined by cross-validation.',\n",
       " 'For different forecasting horizon, the best lag value also varies.',\n",
       " 'We have also evaluated TT-RNN on long-term forecasting for chaotic dynamics, such as the Lorenz dynamics (see FIG8 ).',\n",
       " 'Such dynamics are highly sensitive to input perturbations: two close points can move exponentially far apart under the dynamics.',\n",
       " 'This makes long-term forecasting highly challenging, as small errors can lead to catastrophic longterm errors.',\n",
       " 'FIG8 shows that TT-RNN can predict up to T = 40 steps into the future, but diverges quickly beyond that.',\n",
       " 'We have found no state-of-the-art prediction model is stable in this setting.',\n",
       " 'Classic work in time series forecasting has studied auto-regressive models, such as the ARMA or ARIMA model BID2 , which model a process x(t) linearly, and so do not capture nonlinear dynamics.',\n",
       " 'Our method contrasts with this by explicitly modeling higher-order dependencies.',\n",
       " 'Using neural networks to model time series has a long history.',\n",
       " 'More recently, they have been applied to room temperature prediction, weather forecasting, traffic prediction and other domains.',\n",
       " 'We refer to BID13 for a detailed overview of the relevant literature.',\n",
       " 'From a modeling perspective, BID7 ) considers a high-order RNN to simulate a deterministic finite state machine and recognize regular grammars.',\n",
       " 'This work considers a second order mapping from inputs x(t) and hidden states h(t) to the next state.',\n",
       " 'However, this model only considers the most recent state and is limited to two-way interactions.',\n",
       " 'BID17 proposes multiplicative RNN that allow each hidden state to specify a different factorized hidden-to-hidden weight matrix.',\n",
       " 'A similar approach also appears in BID14 , but without the factorization.',\n",
       " 'Our method can be seen as an efficient generalization of these works.',\n",
       " 'Moreover, hierarchical RNNs have been used to model sequential data at multiple resolutions, e.g. to learn both short-term and long-term human behavior BID20 .Tensor methods have tight connections with neural networks.',\n",
       " 'For example, BID4 shows convolutional neural networks have equivalence to hierarchical tensor factorizations.',\n",
       " 'BID10 BID19 employs tensor-train to compress large neural networks and reduce the number of weights.',\n",
       " 'BID19 forms tensors from reshaping inputs and decomposes the input-output weights.',\n",
       " 'Our model forms tensors from high-order hidden states and decomposes the hidden-output weights.',\n",
       " 'BID16 propose to parameterizes the supervised learning models with matrix-product states for image classification.',\n",
       " 'This work however, to the best of our knowledge, is the first work to consider tensor networks in RNNS for sequential prediction tasks for learning in environments with nonlinear dynamics.',\n",
       " 'In this work, we considered forecasting under nonlinear dynamics.',\n",
       " 'We propose a novel class of RNNs -TT-RNN.',\n",
       " 'We provide approximation guarantees for TT-RNN and characterize its representation power.',\n",
       " 'We demonstrate the benefits of TT-RNN to forecast accurately for significantly longer time horizon in both synthetic and real-world multivariate time series data.',\n",
       " 'As we observed, chaotic dynamics still present a significant challenge to any sequential prediction model.',\n",
       " 'Hence, it would be interesting to study how to learn robust models for chaotic dynamics.',\n",
       " 'In other sequential prediction settings, such as natural language processing, there does not (or is not known to) exist a succinct analytical description of the data-generating process.',\n",
       " 'It would be interesting to further investigate the effectiveness of TT-RNNs in such domains as well.',\n",
       " 'We provide theoretical guarantees for the proposed TT-RNN model by analyzing a class of functions that satisfy some regularity condition.',\n",
       " 'For such functions, tensor-train decompositions preserve weak differentiability and yield a compact representation.',\n",
       " 'We combine this property with neural network estimation theory to bound the approximation error for TT-RNN with one hidden layer, in terms of: 1) the regularity of the target function f , 2) the dimension of the input space, and 3) the tensor train rank.',\n",
       " 'In the context of TT-RNN, the target function f (x) with x = s ⊗ . . .',\n",
       " '⊗ s, is the system dynamics that describes state transitions, as in (6).',\n",
       " 'Let us assume that f (x) is a Sobolev function: f ∈ H k µ , defined on the input space I = I 1 × I 2 × · · ·',\n",
       " 'I d , where each I i is a set of vectors.',\n",
       " 'The space H k µ is defined as the set of functions that have bounded derivatives up to some order k and are L µ -integrable: DISPLAYFORM0 where D (i) f is the i-th weak derivative of f and µ ≥ 0.',\n",
       " 'Any Sobolev function admits a Schmidt decomposition: DISPLAYFORM0 , where {λ} are the eigenvalues and {γ}, {φ} are the associated eigenfunctions.',\n",
       " 'Hence, we can decompose the target function f ∈ H k µ as: DISPLAYFORM1 where DISPLAYFORM2 We can truncate Eqn 13 to a low dimensional subspace (r < ∞), and obtain the functional tensor-train (FTT) approximation of the target function f : DISPLAYFORM3 .FTT approximation in Eqn 13 projects the target function to a subspace with finite basis.',\n",
       " 'And the approximation error can be bounded using the following Lemma: Lemma 7.1 (FTT Approximation BID1 ).',\n",
       " 'Let f ∈ H k µ be a Hölder continuous function, defined on a bounded domain I = I 1 × · · · ×',\n",
       " 'I d ⊂ R d with exponent α > 1/2, the FTT approximation error can be upper bounded as DISPLAYFORM4 for r ≥ 1 and DISPLAYFORM5 Lemma 7.1 relates the approximation error to the dimension d, tensor-train rank r,and the regularity of the target function k. In practice, TT-RNN implements a polynomial expansion of the input states s, using powers [s, s ⊗2 , · · · , s ⊗p ] to approximate f T T , where p is the degree of the polynomial.',\n",
       " 'We can further use the classic spectral approximation theory to connect the TT-RNN structure with the degree of the polynomial, i.e., the order of the tensor.',\n",
       " 'Let DISPLAYFORM6 Given a function f and its polynomial expansion P T T , the approximation error is therefore bounded by: 2 A weak derivative generalizes the derivative concept for (non)-differentiable functions and is implicitly defined as: DISPLAYFORM7 Where p is the order of tensor and r is the tensor-train rank.',\n",
       " 'As the rank of the tensor-train and the polynomial order increase, the required size of the hidden units become smaller, up to a constant that depends on the regularity of the underlying dynamics f .',\n",
       " 'We trained all models using the RMS-prop optimizer and employed a learning rate decay of 0.8 schedule.',\n",
       " 'We performed an exhaustive search over the hyper-parameters for validation.',\n",
       " 'TAB3 reports the hyper-parameter search range used in this work.',\n",
       " 'For all datasets, we used a 80% − 10% − 10% train-validation-test split and train for a maximum of 1e 4 steps.',\n",
       " 'We compute the moving average of the validation loss and use it as an early stopping criteria.',\n",
       " 'We also did not employ scheduled sampling, as we found training became highly unstable under a range of annealing schedules.',\n",
       " 'Genz Genz functions are often used as basis for evaluating high-dimensional function approximation.',\n",
       " 'In particular, they have been used to analyze tensor-train decompositions BID1 .',\n",
       " 'There are in total 7 different Genz functions.',\n",
       " '(1) g 1 (x) = cos(2πw + cx), (2) DISPLAYFORM0 2 π|x−w| (6) DISPLAYFORM1 For each function, we generated a dataset with 10, 000 samples using FORMULA1 with w = 0.5 and c = 1.0 and random initial points draw from a range of [−0.1, 0.1].Traffic We use the traffic data of Los Angeles County highway network collected from California department of transportation http://pems.dot.ca.gov/. The dataset consists of 4 month speed readings aggregated every 5 minutes .',\n",
       " 'Due to large number of missing values (∼ 30%) in the raw data, we impute the missing values using the average values of non-missing entries from other sensors at the same time.',\n",
       " 'In total, after processing, the dataset covers 35 136, time-series.',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = [sentence for article in Xtrain['source'] for sentence in article]\n",
    "bag_size = len(bag)\n",
    "bag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "for paragraph in Xtrain['source']:\n",
    "    sentences = [\n",
    "        sentence for sentence in paragraph if sentence != ''\n",
    "    ]\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1:\n",
    "        start = random.randint(0, num_sentences-2)\n",
    "        # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "        if random.random() >= 0.5:\n",
    "            # this is IsNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)\n",
    "        else:\n",
    "            index = random.randint(0, bag_size-1)\n",
    "            # this is NotNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(bag[index])\n",
    "            label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Spectral methods, stemming from a CNN formulation for graphs BID11 , include different approximations of spectral graph convolutions BID16 BID28 adaptive convolution filters BID34 , or attention mechanisms BID45 Embedding approaches have been suggesting for handling bag-of-words representations BID48 and general node attributes such as text or continuous features BID18 .\n",
      "---\n",
      "Method ScoreReal data 11.24 ± 0.16 WGAN 3.82 ± 0.06 MIX + WGAN BID2 4.04 ± 0.07 Improved-GAN (Salimans et al., 2016) 4.36 ± 0.04 ALI BID7 5.34 ± 0.05 DCGAN (Radford et al., 2015) 6.40 ± 0.05Proposed method 4.53 ± 0.04 Table 2 : Inception scores on CIFAR-10 dataset.that uses similar network architecture and training method.\n",
      "\n",
      "1\n",
      "We find that although the datasets are from different domains, the architecture searched on one performs comparable on the other.\n",
      "---\n",
      "In order to provide results on future video prediction problems we describe a simple modification to DVD-GAN to facilitate the added conditioning.\n",
      "\n",
      "0\n",
      "In addition to these, a random prediction model is provided for reference.\n",
      "---\n",
      "This method simply outputs a uniform random value in [0, 1] as the likelihood of a link between any pair of given vertices (u, v).For the case of undirected graphs we use the usual definitions of the heuristics (see Appendix A 1 ) and for directed graphs we restrict our analysis to either the in-neighbourhood ( i (u)) or the outneighbourhood ( o (u)) of the nodes u 2 V .Node to edge embedding Unlike for the abovementioned LP heuristics where the output can be directly used for link prediction, for NE methods this is generally not the case.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(22, 25):\n",
    "    print(label[i])\n",
    "    print(sentence_a[i] + '\\n---')\n",
    "    print(sentence_b[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt',\n",
    "                   max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1016,  1012,  ...,     0,     0,     0],\n",
       "        [  101,  6897, 20228,  ...,     0,     0,     0],\n",
       "        [  101,  2057,  2191,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 19090,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  3602,  2008,  ...,     0,     0,     0],\n",
       "        [  101,  2925,  2147,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.next_sentence_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 15, 19, 21, 26],\n",
       " [1, 13, 14, 17, 18, 19, 21, 23, 31, 38, 44, 47, 49, 51, 57, 58, 61, 74]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1016,  1012,  ...,     0,     0,     0],\n",
       "        [  101,   103, 20228,  ...,     0,     0,     0],\n",
       "        [  101,  2057,  2191,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 19090,   103,  ...,     0,     0,     0],\n",
       "        [  101,   103,  2008,  ...,     0,     0,     0],\n",
       "        [  101,  2925,  2147,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OurDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\liana\\AppData\\Local\\Temp/ipykernel_20332/541448751.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████| 7/7 [06:08<00:00, 52.68s/it, loss=2.68]\n",
      "Epoch 1: 100%|██████████| 7/7 [05:40<00:00, 48.68s/it, loss=10.4]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optimizer.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test training with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'SysEexbRb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20332/485515818.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mknn_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'SysEexbRb'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(Xtrain, ytrain)\n",
    "\n",
    "knn_pred = knn.predict(Xtest)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(ytest, knn_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37833eaa7c79fc29fc64cdd65cef9244dd84f1f67a5ba8cd87f16f157512cb2c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
