{"cells":[{"cell_type":"markdown","metadata":{},"source":["## ðŸ¤—Transformers - Generating Articles from Paper's Abstracts using T5 Model\n","This notebook uses T5 model - A Sequence to Sequence model fully capable to perform any text to text tasks. What does it mean - It means that T5 model can take any input text and convert it into any output text. Such Text to Text conversion is useful in NLP tasks like language translation, summarization etc.\n","\n","In this notebook, we will take paper's abstracts as our input text and paper's title as output text and feed it to T5 model. So,let's dive in...\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["We will install dependencies and work with latest stable pytorch 1.6"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install -U simpletransformers  "]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import os, psutil  \n","\n","def cpu_stats():\n","    pid = os.getpid()\n","    py = psutil.Process(pid)\n","    memory_use = py.memory_info()[0] / 2. ** 30\n","    return 'memory GB:' + str(np.round(memory_use, 2))"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'memory GB:2.29'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["cpu_stats()"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["import json\n","\n","data_file = '../dataset/arxiv-metadata-oai-snapshot.json'\n","\n","def get_metadata():\n","    with open(data_file, 'r') as f:\n","        for line in f:\n","            yield line"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Title: Calculation of prompt diphoton production cross sections at Tevatron and\n","  LHC energies\n","\n","Abstract:   A fully differential calculation in perturbative quantum chromodynamics is\n","presented for the production of massive photon pairs at hadron colliders. All\n","next-to-leading order perturbative contributions from quark-antiquark,\n","gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n","all-orders resummation of initial-state gluon radiation valid at\n","next-to-next-to-leading logarithmic accuracy. The region of phase space is\n","specified in which the calculation is most reliable. Good agreement is\n","demonstrated with data from the Fermilab Tevatron, and predictions are made for\n","more detailed tests with CDF and DO data. Predictions are shown for\n","distributions of diphoton pairs produced at the energy of the Large Hadron\n","Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\n","boson are contrasted with those produced from QCD processes at the LHC, showing\n","that enhanced sensitivity to the signal can be obtained with judicious\n","selection of events.\n","\n","Ref: Phys.Rev.D76:013009,2007\n"]}],"source":["metadata = get_metadata()\n","for paper in metadata:\n","    paper_dict = json.loads(paper)\n","    print('Title: {}\\n\\nAbstract: {}\\nRef: {}'.format(paper_dict.get('title'), paper_dict.get('abstract'), paper_dict.get('journal-ref')))\n","#     print(paper)\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["**We will take last 5 years ArXiv papers (2016-2021) due to Kaggle'c compute limits**"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["(22705, 22705, 22705)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["titles = []\n","abstracts = []\n","years = []\n","metadata = get_metadata()\n","for paper in metadata:\n","    paper_dict = json.loads(paper)\n","    ref = paper_dict.get('journal-ref')\n","    try:\n","        year = int(ref[-4:]) \n","        if 2010 < year < 2016:\n","            years.append(year)\n","            titles.append(paper_dict.get('title'))\n","            abstracts.append(paper_dict.get('abstract'))\n","    except:\n","        pass \n","\n","len(titles), len(abstracts), len(years)"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The World as Evolving Information</td>\n","      <td>This paper discusses the benefits of describ...</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A unified analysis of the reactor neutrino pro...</td>\n","      <td>We present in this article a detailed quanti...</td>\n","      <td>2013</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Heat Equations and the Weighted $\\bar\\partial$...</td>\n","      <td>The purpose of this article is to establish ...</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The KATRIN sensitivity to the neutrino mass an...</td>\n","      <td>The aim of the KArlsruhe TRItium Neutrino ex...</td>\n","      <td>2011</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Penguin-mediated B_(d,s)-&gt;VV decays and the Bs...</td>\n","      <td>In this letter, we propose three different s...</td>\n","      <td>2011</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  \\\n","0                  The World as Evolving Information   \n","1  A unified analysis of the reactor neutrino pro...   \n","2  Heat Equations and the Weighted $\\bar\\partial$...   \n","3  The KATRIN sensitivity to the neutrino mass an...   \n","4  Penguin-mediated B_(d,s)->VV decays and the Bs...   \n","\n","                                            abstract  year  \n","0    This paper discusses the benefits of describ...  2012  \n","1    We present in this article a detailed quanti...  2013  \n","2    The purpose of this article is to establish ...  2012  \n","3    The aim of the KArlsruhe TRItium Neutrino ex...  2011  \n","4    In this letter, we propose three different s...  2011  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["papers = pd.DataFrame({\n","    'title': titles,\n","    'abstract': abstracts,\n","    'year': years\n","})\n","papers.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["del titles, abstracts, years"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'memory GB:0.13'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["cpu_stats()"]},{"cell_type":"markdown","metadata":{},"source":[" **We will use `simpletransformers` library to train a T5 model**"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["import logging\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n"]},{"cell_type":"markdown","metadata":{},"source":["**Simpletransformers implementation of T5 model expects a data to be a dataframe with 3 columns:**\n","`<prefix>, <input_text>, <target_text>`\n","* `<prefix>`: A string indicating the task to perform. (E.g. \"question\", \"stsb\")\n","* `<input_text>`: The input text sequence (we will use Paper's abstract as `input_text`  )\n","* `<target_text`: The target sequence (we will use Paper's title as `output_text` )\n","    \n","    \n"," You can read about the data format:  https://github.com/ThilinaRajapakse/simpletransformers#t5-transformer"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["papers = papers[['title','abstract']]\n","papers.columns = ['target_text', 'input_text']\n","papers = papers.dropna()"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["eval_df = papers.sample(frac=0.2, random_state=101)\n","train_df = papers.drop(eval_df.index)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["((18164, 2), (4541, 2))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape, eval_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import logging\n","\n","import pandas as pd\n","from simpletransformers.t5 import T5Model\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n","\n","train_df['prefix'] = \"summarize\"\n","eval_df['prefix'] = \"summarize\"\n","\n","\n","model_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"max_seq_length\": 512,\n","    \"train_batch_size\": 16,\n","    \"num_train_epochs\": 4,\n","}\n","\n","# Create T5 Model\n","# model = T5Model(model_name=\"t5-small\", model_type=\"t5\", args=model_args, use_cuda=True)\n","\n","import pickle\n","\n","model = pickle.load(open('../models/title-generator-t5-arxiv-16-4.pkl', 'rb'))\n","\n","# Train T5 Model on new task\n","model.train_model(train_df)\n","\n","# Evaluate T5 Model on new task\n","results = model.eval_model(eval_df)\n","\n","# Predict with trained T5 model\n","#print(model.predict([\"convert: four\"]))"]},{"cell_type":"markdown","metadata":{},"source":["**We will training out T5 model with very bare minimum `num_train_epochs=4`, `train_batch_size=16` to  fit into Kaggle's compute limits**"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n","  0%|          | 0/18164 [00:27<?, ?it/s]\n"]}],"source":["import logging\n","\n","import pandas as pd\n","from simpletransformers.t5 import T5Model\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n","\n","train_df['prefix'] = \"summarize\"\n","eval_df['prefix'] = \"summarize\"\n","\n","\n","model_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"max_seq_length\": 512,\n","    \"train_batch_size\": 16,\n","    \"num_train_epochs\": 4,\n","}\n","\n","# Create T5 Model\n","model = T5Model(model_name=\"t5-small\", model_type=\"t5\", args=model_args, use_cuda=True)\n","\n","# Train T5 Model on new task\n","model.train_model(train_df)\n","\n","# Evaluate T5 Model on new task\n","results = model.eval_model(eval_df)\n","\n","# Predict with trained T5 model\n","#print(model.predict([\"convert: four\"]))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from torch import cuda\n","cuda.is_available()"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["{'eval_loss': 2.1558538724017398}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"markdown","metadata":{},"source":["## And We're Done ! \n","**Let's see how our model performs in generating paper's titles**"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\E\\anaconda3\\envs\\slide-gen\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3426: FutureWarning: \n","`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n","`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n","your targets.\n","\n","Here is a short example:\n","\n","model_inputs = tokenizer(src_texts, ...)\n","with tokenizer.as_target_tokenizer():\n","    labels = tokenizer(tgt_texts, ...)\n","model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n","For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n","\n","  warnings.warn(formatted_warning, FutureWarning)\n","Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.00it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.94s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Actual Title: Integral Hodge conjecture for Fermat varieties\n","Predicted Title: ['Lattice of Hodge cycles']\n","Actual Abstract: ['summarize:   We describe an algorithm which verifies whether linear algebraic cycles of\\nthe Fermat variety generate the lattice of Hodge cycles. A computer\\nimplementation of this confirms the integral Hodge conjecture for quartic and\\nquintic Fermat fourfolds. Our algorithm is based on computation of the list of\\nelementary divisors of both the lattice of linear algebraic cycles, and the\\nlattice of Hodge cycles written in terms of vanishing cycles, and observing\\nthat these two lists are the same.\\n']\n"]}],"source":["random_num = 350\n","actual_title = eval_df.iloc[random_num]['target_text']\n","actual_abstract = [\"summarize: \"+eval_df.iloc[random_num]['input_text']]\n","predicted_title = model.predict(actual_abstract)\n","\n","print(f'Actual Title: {actual_title}')\n","print(f'Predicted Title: {predicted_title}')\n","print(f'Actual Abstract: {actual_abstract}')\n"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.50it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.96s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Actual Title: Construction of genuine multipartite entangled states\n","Predicted Title: ['A Novel Product for Real Multipartite Entanglement']\n","Actual Abstract: ['summarize:   Genuine multipartite entanglement is of great importance in quantum\\ninformation, especially from the experimental point of view. Nevertheless, it\\nis difficult to construct genuine multipartite entangled states systematically,\\nbecause the genuine multipartite entanglement is unruly. We propose another\\nproduct based on the Kronecker product in this paper. The Kronecker product is\\na common product in quantum information with good physical interpretation. We\\nmainly investigate whether the proposed product of two genuine multipartite\\nentangled states is still a genuine entangled one. We understand the\\nentanglement of the proposed product better by characterizing the entanglement\\nof the Kronecker product. Then we show the proposed product is a genuine\\nmultipartite entangled state in two cases. The results provide a systematical\\nmethod to construct genuine multipartite entangled states of more parties.\\n']\n"]}],"source":["random_num = 478\n","actual_title = eval_df.iloc[random_num]['target_text']\n","actual_abstract = [\"summarize: \"+eval_df.iloc[random_num]['input_text']]\n","predicted_title = model.predict(actual_abstract)\n","\n","print(f'Actual Title: {actual_title}')\n","print(f'Predicted Title: {predicted_title}')\n","print(f'Actual Abstract: {actual_abstract}')"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.47it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.86s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Actual Title: Automating Motion Correction in Multishot MRI Using Generative\n","  Adversarial Networks\n","Predicted Title: ['GAN: Generative Adversarial Network for Multishot Magnetic Resonance Imaging']\n","Actual Abstract: ['summarize:   Multishot Magnetic Resonance Imaging (MRI) has recently gained popularity as\\nit accelerates the MRI data acquisition process without compromising the\\nquality of final MR image. However, it suffers from motion artifacts caused by\\npatient movements which may lead to misdiagnosis. Modern state-of-the-art\\nmotion correction techniques are able to counter small degree motion, however,\\ntheir adoption is hindered by their time complexity. This paper proposes a\\nGenerative Adversarial Network (GAN) for reconstructing motion free\\nhigh-fidelity images while reducing the image reconstruction time by an\\nimpressive two orders of magnitude.\\n']\n"]}],"source":["random_num = 999\n","actual_title = eval_df.iloc[random_num]['target_text']\n","actual_abstract = [\"summarize: \"+eval_df.iloc[random_num]['input_text']]\n","predicted_title = model.predict(actual_abstract)\n","\n","print(f'Actual Title: {actual_title}')\n","print(f'Predicted Title: {predicted_title}')\n","print(f'Actual Abstract: {actual_abstract}')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["actual_abstract = [\"summarize: \"+\"\"\"Rococo Rococo (/rÉ™ËˆkoÊŠkoÊŠ/, also US: /ËŒroÊŠkÉ™ËˆkoÊŠ/), less commonly Roccoco or Late Baroque, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and trompe-l'Å“il frescoes to create surprise and the illusion of motion and drama. 8][9] In the late 17th and early 18th century rocaille became the term for a kind of decorative motif or ornament that appeared in the late Style Louis XIV, in the form of a seashell interlaced with acanthus leaves.\"\"\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(model.predict(actual_abstract))"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle.dump(model, open('../models/title-generator.pkl', 'wb'))"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["loaded_model = pickle.load(open('../models/title-generator-t5-arxiv-16-4.pkl', 'rb'))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\E\\anaconda3\\envs\\slide-gen\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3426: FutureWarning: \n","`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n","`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n","your targets.\n","\n","Here is a short example:\n","\n","model_inputs = tokenizer(src_texts, ...)\n","with tokenizer.as_target_tokenizer():\n","    labels = tokenizer(tgt_texts, ...)\n","model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n","For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n","\n","  warnings.warn(formatted_warning, FutureWarning)\n","Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.72s/it]\n"]},{"data":{"text/plain":["['Rococo Rococo: A Novel Design and a Novel Design']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["loaded_model.predict(actual_abstract)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00, 10.34it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:15<00:00,  4.29it/s]\n"]},{"data":{"text/plain":["['Industri',\n"," 'Al Train al Train',\n"," 'Prog ing Prog ing Prog ing Prog ing Prog',\n"," 'Ramme of ramme of ramme of',\n"," 'Fered by fered by fered by fered by fered by',\n"," 'Facing the Facc Fac',\n"," 'ulty of ulty of ulty of',\n"," 'Computin Computin',\n"," 'In g and Infrared',\n"," 'Formatio',\n"," 'Technological n Technological n Technological',\n"," 'logy, Tu Tu logy, Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu',\n"," 'Abdudu nku Abdu Abdu nku Abdu Abdu',\n"," 'Rahman Rahman',\n"," \"Universit's Universit'es Universit'e\",\n"," 'ity Coll Coll Coll Coll',\n"," 'Ege (TAR): a ege (TAR)',\n"," 'UC Theorems',\n"," 'Main obstructor ob',\n"," 'jective jective jive',\n"," 'I',\n"," 'ndustria ndustria',\n"," 'Traini l traini',\n"," 'ng progr ng progr ng progr ng prog',\n"," 'Amme isotropic and amme isotropic',\n"," 'Proviate Proviant Proviant Proviant',\n"," 'De stude em es em es em',\n"," 'nts with nts with nts',\n"," 'Practic practicum',\n"," 'Al train',\n"," 'Oppospos oppos oppos oppos oppos oppos',\n"," 'Rtunitie rtunitie',\n"," 'One s s s a s a s',\n"," 'Or more: A note on the number of adobes',\n"," 'The',\n"," 'Followin followin',\n"," 'G areas in g areas',\n"," 'We belgian eigente eigen eigen eigen',\n"," 'Ieve wit wit',\n"," 'Extinction of ex-ex ex ex ex ex ex ex ex ex ex ex ex',\n"," 'Pert guido guido guido pert guis',\n"," 'Dance an a',\n"," 'Experimentation of experimentation d experimentation',\n"," 'Censoredence of ence of ence of ence of',\n"," 'Your estrangement a tuomo',\n"," 'Or, or, or',\n"," 'Ganisatisati ganisatisati',\n"," 'On, our planetary counterparts on, our planetary counterpart',\n"," 'Students',\n"," 'Acquiring the acquitter of willac will acquit',\n"," 'Quire re re re re re re re re',\n"," 'Levant p p p p p p p p',\n"," 'Rractical ractical ractical',\n"," 'Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills Skills',\n"," 'Exercissing with and expelling expective expees',\n"," 'Riminice w effrce w ef',\n"," 'hich wou hich wou hich wou hich wo',\n"," 'Vacuum vasculature vasculature',\n"," 'tudos tudos tudos',\n"," 'o the stt st tst o st',\n"," \"Udents ltudos l'es l'\",\n"," 'Ater in the ater in a aer in a aer in',\n"," 'Their worry worry',\n"," 'Rking li rking li',\n"," 'Fe fe fe fe.']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["loaded_model.predict(\"Industrial Training Programme offered by the Faculty of Computing and Information Technology, Tunku Abdul Rahman University College (TAR UC) The main objective of the industrial training programme is to provide students with practical training opportunities in one or more of the following areas . We believe with the expert guidance and experience of your esteemed organisation, our students will acquire relevant practical skills and experience which would be valuable to the students later in their working life .\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.97it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.09s/it]\n"]},{"data":{"text/plain":["['The Venetian Commodes']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["actual_abstract = [\"summarize: \"+\"\"\"Venetian commodes imitated the curving lines and carved ornament of the French rocaille, but with a particular Venetian variation; the pieces were painted, often with landscapes or flowers or scenes from Guardi or other painters, or Chinoiserie, against a blue or green background, matching the colours of the Venetian school of painters whose work decorated the salons. 24] Ceiling of church of Santi Giovanni e Paolo in Venice, by Piazzetta (1727) Juno and Luna by Giovanni Battista Tiepolo (1735â€“45) Murano glass chandelier at the Ca Rezzonico (1758) Ballroom ceiling of the Ca Rezzonico with ceiling by Giovanni Battista Crosato (1753) In church construction, especially in the southern German-Austrian region, gigantic spatial creations are sometimes created for practical reasons alone, which, however, do not appear monumental, but are characterized by a unique fusion of architecture, painting, stucco, etc. ,.\"\"\"]\n","\n","loaded_model.predict(actual_abstract)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.95it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it]\n"]},{"data":{"text/plain":["[\"Race and Rasism in Children's Families\"]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["actual_abstract = [\"summarize: \"+\"\"\"Many adults put off talking to young children about â€˜raceâ€™ and racism until theyâ€™re five or older. Research shows that three-month-olds have racial preferences. By the age of three, children in the U.S. have negative associations of â€˜low-status racial groups. By â€˜racistâ€™ I mean that which upholds, reinforces, reproduces, or perpetuates racism.\"\"\"]\n","\n","loaded_model.predict(actual_abstract)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.02it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.32s/it]\n"]},{"data":{"text/plain":["['Rasism in the U.S.: Race and Rasism']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["actual_abstract = [\"\"\"Many adults put off talking to young children about â€˜raceâ€™ and racism until theyâ€™re five or older. Research shows that three-month-olds have racial preferences. By the age of three, children in the U.S. have negative associations of â€˜low-status racial groups. By â€˜racistâ€™ I mean that which upholds, reinforces, reproduces, or perpetuates racism.\"\"\"]\n","\n","loaded_model.predict(actual_abstract)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.45it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.94s/it]\n"]},{"data":{"text/plain":["['The Covid-19 vaccine vaccine can generate strong immune response in children']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["actual_abstract = [\"\"\"Covid-19: Worry about risk of infection, not effects of vaccine, for children, Malaysian parents told Friday, 11 Feb 2022 09:17 AM MYT A child gets his Covid-19 jab at the Ideal Convention Centre in Shah Alam January 3, 2022. â€” The two doses of the Covid-19 vaccine, when completed, can generate a strong immune response in children in that (five to 11) age group, which can prevent hospital admission and death due to Covid-19,â€ she told Bernama.\"\"\"]\n","\n","loaded_model.predict(actual_abstract)"]},{"cell_type":"markdown","metadata":{},"source":["## Retrain Using Diff Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14855/14855 [00:22<00:00, 647.40it/s] \n","INFO:simpletransformers.t5.t5_utils: Saving features into cached file cache_dir/t5-small_cached_51214855\n","INFO:simpletransformers.t5.t5_model: Training started\n","Epochs 0/4. Running Loss:    2.5037: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:25<00:00,  1.56it/s]\n","Epochs 1/4. Running Loss:    2.7283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:25<00:00,  1.56it/s]\n","Epochs 2/4. Running Loss:    1.5897: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:25<00:00,  1.55it/s]\n","Epochs 3/4. Running Loss:    1.8895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:25<00:00,  1.56it/s]\n","Epoch 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [17:43<00:00, 265.80s/it]\n","INFO:simpletransformers.t5.t5_model: Training of t5-small model complete. Saved to outputs/.\n","INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3714/3714 [00:07<00:00, 469.86it/s]\n","INFO:simpletransformers.t5.t5_utils: Saving features into cached file cache_dir/t5-small_cached_5123714\n","Running Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [00:26<00:00, 17.42it/s]\n","INFO:simpletransformers.t5.t5_model:{'eval_loss': 2.1366923239923294}\n"]}],"source":["import logging\n","\n","import pandas as pd\n","from simpletransformers.t5 import T5Model\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n","\n","train_df['prefix'] = \"summarize\"\n","eval_df['prefix'] = \"summarize\"\n","\n","\n","model_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"max_seq_length\": 512,\n","    \"train_batch_size\": 36,\n","    \"num_train_epochs\": 4,\n","}\n","\n","# Create T5 Model\n","model = T5Model(model_name=\"t5-small\", model_type=\"t5\", args=model_args, use_cuda=True)\n","\n","# Train T5 Model on new task\n","model.train_model(train_df)\n","\n","# Evaluate T5 Model on new task\n","results = model.eval_model(eval_df)\n","\n","# Predict with trained T5 model\n","#print(model.predict([\"convert: four\"]))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.67it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]\n"]},{"name":"stdout","output_type":"stream","text":["['Rococo Rococo: Roccoco, Late Baroque, and']\n"]}],"source":["actual_abstract = [\"summarize: \"+\"\"\"Rococo Rococo (/rÉ™ËˆkoÊŠkoÊŠ/, also US: /ËŒroÊŠkÉ™ËˆkoÊŠ/), less commonly Roccoco or Late Baroque, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and trompe-l'Å“il frescoes to create surprise and the illusion of motion and drama. 8][9] In the late 17th and early 18th century rocaille became the term for a kind of decorative motif or ornament that appeared in the late Style Louis XIV, in the form of a seashell interlaced with acanthus leaves.\"\"\"]\n","\n","print(model.predict(actual_abstract))"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\E\\anaconda3\\envs\\slide-gen\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3426: FutureWarning: \n","`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n","`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n","your targets.\n","\n","Here is a short example:\n","\n","model_inputs = tokenizer(src_texts, ...)\n","with tokenizer.as_target_tokenizer():\n","    labels = tokenizer(tgt_texts, ...)\n","model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n","For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n","\n","  warnings.warn(formatted_warning, FutureWarning)\n","Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.66s/it]\n"]},{"data":{"text/plain":["['The Venetian Commodes and the Renaissance']"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["actual_abstract = [\"summarize: \"+\"\"\"Venetian commodes imitated the curving lines and carved ornament of the French rocaille, but with a particular Venetian variation; the pieces were painted, often with landscapes or flowers or scenes from Guardi or other painters, or Chinoiserie, against a blue or green background, matching the colours of the Venetian school of painters whose work decorated the salons. 24] Ceiling of church of Santi Giovanni e Paolo in Venice, by Piazzetta (1727) Juno and Luna by Giovanni Battista Tiepolo (1735â€“45) Murano glass chandelier at the Ca Rezzonico (1758) Ballroom ceiling of the Ca Rezzonico with ceiling by Giovanni Battista Crosato (1753) In church construction, especially in the southern German-Austrian region, gigantic spatial creations are sometimes created for practical reasons alone, which, however, do not appear monumental, but are characterized by a unique fusion of architecture, painting, stucco, etc. ,.\"\"\"]\n","\n","model.predict(actual_abstract)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["pickle.dump(model, open('../models/title-generator-t5-arxiv-36-4.pkl', 'wb'))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14855/14855 [00:16<00:00, 923.34it/s] \n","INFO:simpletransformers.t5.t5_utils: Saving features into cached file cache_dir/t5-small_cached_51214855\n","INFO:simpletransformers.t5.t5_model: Training started\n","Epochs 0/8. Running Loss:    2.3553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:23<00:00,  1.57it/s]\n","Epochs 1/8. Running Loss:    2.2879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:07<00:00,  1.67it/s]\n","Epochs 2/8. Running Loss:    2.1958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:07<00:00,  1.67it/s]\n","Epochs 3/8. Running Loss:    2.2356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:07<00:00,  1.67it/s]\n","Epochs 4/8. Running Loss:    1.8977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:07<00:00,  1.67it/s]\n","Epochs 5/8. Running Loss:    1.6054: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:07<00:00,  1.67it/s]\n","Epochs 6/8. Running Loss:    1.7475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:07<00:00,  1.67it/s]\n","Epochs 7/8. Running Loss:    1.1424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [04:07<00:00,  1.67it/s]\n","Epoch 8 of 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [33:17<00:00, 249.74s/it]\n","INFO:simpletransformers.t5.t5_model: Training of t5-small model complete. Saved to outputs/.\n","INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3714/3714 [00:14<00:00, 257.81it/s]\n","INFO:simpletransformers.t5.t5_utils: Saving features into cached file cache_dir/t5-small_cached_5123714\n","Running Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [00:24<00:00, 18.96it/s]\n","INFO:simpletransformers.t5.t5_model:{'eval_loss': 2.2639486075729454}\n","Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.52it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["['Rococo Rococo: a classical and classical style of architecture, art and decoration']\n"]},{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.45it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.86s/it]\n"]},{"name":"stdout","output_type":"stream","text":["['The Ca Rezzonico: a Venetian Renaissance']\n"]}],"source":["import logging\n","\n","import pandas as pd\n","from simpletransformers.t5 import T5Model\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n","\n","train_df['prefix'] = \"summarize\"\n","eval_df['prefix'] = \"summarize\"\n","\n","\n","model_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"max_seq_length\": 512,\n","    \"train_batch_size\": 36,\n","    \"num_train_epochs\": 8,\n","}\n","\n","# Create T5 Model\n","model = T5Model(model_name=\"t5-small\", model_type=\"t5\", args=model_args, use_cuda=True)\n","\n","# Train T5 Model on new task\n","model.train_model(train_df)\n","\n","# Evaluate T5 Model on new task\n","results = model.eval_model(eval_df)\n","\n","# Predict with trained T5 model\n","#print(model.predict([\"convert: four\"]))\n","\n","actual_abstract = [\"summarize: \"+\"\"\"Rococo Rococo (/rÉ™ËˆkoÊŠkoÊŠ/, also US: /ËŒroÊŠkÉ™ËˆkoÊŠ/), less commonly Roccoco or Late Baroque, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and trompe-l'Å“il frescoes to create surprise and the illusion of motion and drama. 8][9] In the late 17th and early 18th century rocaille became the term for a kind of decorative motif or ornament that appeared in the late Style Louis XIV, in the form of a seashell interlaced with acanthus leaves.\"\"\"]\n","\n","print(model.predict(actual_abstract))\n","\n","actual_abstract = [\"summarize: \"+\"\"\"Venetian commodes imitated the curving lines and carved ornament of the French rocaille, but with a particular Venetian variation; the pieces were painted, often with landscapes or flowers or scenes from Guardi or other painters, or Chinoiserie, against a blue or green background, matching the colours of the Venetian school of painters whose work decorated the salons. 24] Ceiling of church of Santi Giovanni e Paolo in Venice, by Piazzetta (1727) Juno and Luna by Giovanni Battista Tiepolo (1735â€“45) Murano glass chandelier at the Ca Rezzonico (1758) Ballroom ceiling of the Ca Rezzonico with ceiling by Giovanni Battista Crosato (1753) In church construction, especially in the southern German-Austrian region, gigantic spatial creations are sometimes created for practical reasons alone, which, however, do not appear monumental, but are characterized by a unique fusion of architecture, painting, stucco, etc. ,.\"\"\"]\n","\n","print(model.predict(actual_abstract))\n","\n","pickle.dump(model, open('../models/title-generator-t5-arxiv-{}-{}.pkl'.format(model_args['train_batch_size'], model_args['num_train_epochs']), 'wb'))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14855/14855 [00:15<00:00, 961.38it/s] \n","INFO:simpletransformers.t5.t5_utils: Saving features into cached file cache_dir/t5-small_cached_51214855\n","INFO:simpletransformers.t5.t5_model: Training started\n","Epochs 0/4. Running Loss:    2.6198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [04:33<00:00,  1.70it/s]\n","Epochs 1/4. Running Loss:    2.2277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [04:29<00:00,  1.72it/s]\n","Epochs 2/4. Running Loss:    1.9162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [04:30<00:00,  1.72it/s]\n","Epochs 3/4. Running Loss:    1.7281: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [04:29<00:00,  1.72it/s]\n","Epoch 4 of 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [18:04<00:00, 271.07s/it]\n","INFO:simpletransformers.t5.t5_model: Training of t5-small model complete. Saved to outputs/.\n","INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3714/3714 [00:15<00:00, 244.44it/s]\n","INFO:simpletransformers.t5.t5_utils: Saving features into cached file cache_dir/t5-small_cached_5123714\n","Running Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [00:26<00:00, 17.55it/s]\n","INFO:simpletransformers.t5.t5_model:{'eval_loss': 2.152868740276624}\n","Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\E\\anaconda3\\envs\\slide-gen\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3426: FutureWarning: \n","`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n","`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n","your targets.\n","\n","Here is a short example:\n","\n","model_inputs = tokenizer(src_texts, ...)\n","with tokenizer.as_target_tokenizer():\n","    labels = tokenizer(tgt_texts, ...)\n","model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n","For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n","\n","  warnings.warn(formatted_warning, FutureWarning)\n","Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.18it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.99s/it]\n"]},{"name":"stdout","output_type":"stream","text":["['Rococo Rococo Rococo: a classic style of architecture, art and']\n"]},{"name":"stderr","output_type":"stream","text":["Generating outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.90it/s]\n","Decoding outputs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.92s/it]\n"]},{"name":"stdout","output_type":"stream","text":["['The commodes of the Venetian painters, the cosmosphere,']\n"]}],"source":["import logging\n","\n","import pandas as pd\n","from simpletransformers.t5 import T5Model\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n","\n","train_df['prefix'] = \"summarize\"\n","eval_df['prefix'] = \"summarize\"\n","\n","\n","model_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"max_seq_length\": 512,\n","    \"train_batch_size\": 32,\n","    \"num_train_epochs\": 4,\n","}\n","\n","# Create T5 Model\n","model = T5Model(model_name=\"t5-small\", model_type=\"t5\", args=model_args, use_cuda=True)\n","\n","# Train T5 Model on new task\n","model.train_model(train_df)\n","\n","# Evaluate T5 Model on new task\n","results = model.eval_model(eval_df)\n","\n","# Predict with trained T5 model\n","#print(model.predict([\"convert: four\"]))\n","\n","actual_abstract = [\"summarize: \"+\"\"\"Rococo Rococo (/rÉ™ËˆkoÊŠkoÊŠ/, also US: /ËŒroÊŠkÉ™ËˆkoÊŠ/), less commonly Roccoco or Late Baroque, is an exceptionally ornamental and theatrical style of architecture, art and decoration which combines asymmetry, scrolling curves, gilding, white and pastel colors, sculpted molding, and trompe-l'Å“il frescoes to create surprise and the illusion of motion and drama. 8][9] In the late 17th and early 18th century rocaille became the term for a kind of decorative motif or ornament that appeared in the late Style Louis XIV, in the form of a seashell interlaced with acanthus leaves.\"\"\"]\n","\n","print(model.predict(actual_abstract))\n","\n","actual_abstract = [\"summarize: \"+\"\"\"Venetian commodes imitated the curving lines and carved ornament of the French rocaille, but with a particular Venetian variation; the pieces were painted, often with landscapes or flowers or scenes from Guardi or other painters, or Chinoiserie, against a blue or green background, matching the colours of the Venetian school of painters whose work decorated the salons. 24] Ceiling of church of Santi Giovanni e Paolo in Venice, by Piazzetta (1727) Juno and Luna by Giovanni Battista Tiepolo (1735â€“45) Murano glass chandelier at the Ca Rezzonico (1758) Ballroom ceiling of the Ca Rezzonico with ceiling by Giovanni Battista Crosato (1753) In church construction, especially in the southern German-Austrian region, gigantic spatial creations are sometimes created for practical reasons alone, which, however, do not appear monumental, but are characterized by a unique fusion of architecture, painting, stucco, etc. ,.\"\"\"]\n","\n","print(model.predict(actual_abstract))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["pickle.dump(model, open('../models/title-generator-t5-arxiv-{}-{}.pkl'.format(model_args['train_batch_size'], model_args['num_train_epochs']), 'wb'))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":4}
